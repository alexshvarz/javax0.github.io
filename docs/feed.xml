<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://javax0.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://javax0.github.io/" rel="alternate" type="text/html" /><updated>2024-07-26T09:37:05+02:00</updated><id>https://javax0.github.io/feed.xml</id><title type="html">Java Deep, mostly Java</title><subtitle>javax0 is a technical Java oriented blog. Whenever I find something interesting, in the mood and feel the power to publish it, you will get it here. Publications are usually released on Wednesday 15:00am GMT. Earlier posts of the blog were published on Javax0 Wordpress Site at https://javax0.wordpress.com</subtitle><entry><title type="html">Better Writing with AI</title><link href="https://javax0.github.io/2024/07/26/how_i_wrote_the-llm-article.html" rel="alternate" type="text/html" title="Better Writing with AI" /><published>2024-07-26T00:00:00+02:00</published><updated>2024-07-26T00:00:00+02:00</updated><id>https://javax0.github.io/2024/07/26/how_i_wrote_the-llm-article</id><content type="html" xml:base="https://javax0.github.io/2024/07/26/how_i_wrote_the-llm-article.html">&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I wrote the &lt;a href=&quot;https://javax0.github.io/2024/07/22/llm-and-rag.html&quot;&gt;previous article&lt;/a&gt; using AI&amp;#8217;s help.
In this article, which I write the conventional way, I describe&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;what I did&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;why I did, and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;what I think about the result.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Before goin on, it is important to emphasize:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I wrote that article, it is not AI-generated.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;AI is used as a tool,; more precisely, there are many tools powered by AI techniques, but&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;they do not replace the human actors yet; whatever you create using AI or any other tool, you are responsible.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;2-how-i-wrote-the-llm-article&quot;&gt;2. How I wrote the LLM article&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As a first step, I created some handwritten notes and bullet points about what I wanted to discuss in the article.
As a very first attempt, I tried to do the article without the structure at hand, but the result was terrible.
I was deviating from the topic, so I created a long, blossoming text that would be acceptable in a live conference speech but not in a written article.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;After creating the notes, I dictated the article, walking up and down in my room and feeding the text into MacWhisperer.
I was essentially dictating the text of the article.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I have used English for 45 years, but it is not my first language.
The transcription is fine; my accent is good enough for dictation.
I can speak English in front of an audience; dictating an article&amp;#8217;s text is a different trade.
I was not content with the result.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I repeated the process in my mother tongue, Hungarian.
The result was better, but still not perfect, but I had no more options for this phase.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I copied the transcribed text into the article and asked calude.ai to clean it up.
Since it was Hungarian, I used Hungarian for the prompting, but the result is language-independent.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Claude.ai first made a short version of the article, like a one-pager, though I asked it not to shorten it.
I amended the prompt and could get as far as 70% of the original text.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Making the text shorter is acceptable to some level you can expect.
Spoken text is more verbose than one in an article.
However, 30% was too much, and I looked at some specific content that claude.ai skipped.
I asked why it skipped that part, and strangely, it fixed the text instead of answering the question.
I had to command it to answer the question and not treat it as scolding.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The explanation was reasonable, but again, it apologized and explained that it was its fault for assuming those parts were unnecessary.
And it provided a corrected full-length text, which was finally acceptable.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I could use it, but as a programmer, I wanted a workflow I could repeat without haggling with an AI.
So, I asked calue.ai to provide me with the prompt I should have asked in the first place.
It did, I tried, and it worked.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now, I had a Hungarian text that was almost perfect.
I was proofreading it and fixing some of the grammar, which was correct but smelled like a machine.
Then, I asked calude.ai to translate it into English.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I fed the translated text to Grammarly, and I fixed it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Then I asked calude.ai to translate the English into German, Spanish, and Russian.
I do not know these languages well enough to check, though.
I understand them to various levels, but the level is far from my English enhanced with Grammarly or my Hungarian.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Russian translation was a bit tricky.
Claude.ai has already translated the text to German from English, but it has started to complain that the text is too long for one session.
How about summarizing it in Russian or translating it into smaller etaps?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I told it that it had already translated the English version without question to German.
And then claude.ai said that okay, then, and it translated the text.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;My Russian-speaking colleague told me it reeks a bit of AI, but that should be okay.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It is okay because&amp;#8230;&amp;#8203; and here comes the next part:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;3-what-i-wanted-to-achieve&quot;&gt;3. What I wanted to achieve&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Writing an article is delivering information.
It takes a lot of time and effort to write one.
With the recent development of AI technologies, I started to use AI to proofread my English.
I thought I would also use it to transcribe it from spoken text.
After all, I can speak faster than I can write.
If there is something that a machine can do instead of a human, then let the machine do it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To answer the question of how to do it is engineering.
And I did what I did; here you are.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;4-conclusion-feelings&quot;&gt;4. Conclusion, Feelings&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Is the result good?
Please read the article; I linked it at the top, and you can tell.
Dictating and speaking are different from writing.
It is faster, but the style will be different.
Even in the English version, you may feel it was produced using a different method.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;At least it is a good experience playing with the bleeding edge technology.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">1. Introduction</summary></entry><entry><title type="html">Технология LLM и RAG</title><link href="https://javax0.github.io/2024/07/22/llm-and-rag-ru.html" rel="alternate" type="text/html" title="Технология LLM и RAG" /><published>2024-07-22T00:00:00+02:00</published><updated>2024-07-22T00:00:00+02:00</updated><id>https://javax0.github.io/2024/07/22/llm-and-rag-ru</id><content type="html" xml:base="https://javax0.github.io/2024/07/22/llm-and-rag-ru.html">&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;1-введение&quot;&gt;1. Введение&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Эта статья представляет собой краткое введение в технологию LLM и RAG.
Статья содержит много упрощений, которые могут понять обычные люди.
Если вы заинтересованы в более детальном изучении технологии, этой статьи будет недостаточно. Вы можете найти части, которые не совсем точны, хотя они хорошо передают суть.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;2-суть-технологии-rag&quot;&gt;2. Суть технологии RAG&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;RAG - это аббревиатура от Retrieval Augmented Generation.
Это английская аббревиатура.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Эта технология пытается дополнить приложения LLM или Large Language Model.
Цель состоит в том, чтобы иметь возможность работать с базами знаний и информацией, которых нет в самой модели большого языка.
Модель большого языка - это нейронная сеть, которая была обучена каким-то образом.
Обычно их обучают на больших объемах данных, которые находятся в свободном доступе в интернете.
В результате большие языковые модели могут общаться почти как люди.
Если мы задаем им вопрос, они могут ответить на него.
Однако им нужно узнать о том, какие данные или информация существуют внутри компании, так как это не публичные данные.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;3-ограничения-llm&quot;&gt;3. Ограничения LLM&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;LLM нельзя научить этой корпоративной информации в их текущем виде.
В настоящее время доступные приложения работают так, что разработчики создают некоторые модели.
Затем они обучают эту модель, устанавливая миллионы или миллиарды параметров с помощью обучающих данных.
Они задают вопросы, получают ответы, а затем корректируют эти параметры на основе качества ответов.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Конечно, для этого существуют программы и алгоритмы, а не делается вручную.
В текущих условиях этот процесс занимает несколько месяцев, используя энергию, необходимую небольшому городу.
Они запускают этот алгоритм тонкой настройки на тысячах машин.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;4-характеристики-моделей-llm&quot;&gt;4. Характеристики моделей LLM&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Когда это сделано, модель можно скачать и запустить на своей машине.
Сама модель представляет собой 1-2 ГБ данных.
После этого эта нейронная сеть больше не меняется; она не учится новому.
Она может научиться чему-то новому только если мы получим новую версию.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;5-применение-технологии-rag&quot;&gt;5. Применение технологии RAG&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Тем не менее, мы хотим использовать такие возможности внутри компании.
Мы хотим, чтобы эта нейронная сеть, модель LLM, давала ответ, учитывающий внутреннюю информацию нашей компании, когда мы задаем вопрос.
Мы можем сделать это так, как если бы мы делали что-то подобное с людьми.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Если кто-то приходит в компанию, и мы хотим задать им вопросы о компании, но они ничего не знают о нашей компании, мы сначала обучаем их и даем им информацию.
Они поместят эту информацию в свою нейронную сеть.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;6-принцип-работы-rag&quot;&gt;6. Принцип работы RAG&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Мы можем видеть, если они сосредоточены на работе и забывают все остальное, когда идут домой, и хранят эту специфическую для компании информацию в отдельном месте.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Это модель для LLM и RAG также.
Мы помещаем информацию, которой нет в нейронной сети LLM, отдельно в отдельную базу данных.
Если не по другой причине, мы не можем поместить ее в базу данных нейронной сети или в ее модель.
Это частная информация. Мы не знаем, как они выглядят или как они структурированы, и они не обязательно могут быть изменены в том виде, в котором они находятся в программе.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;У нас нет, можно сказать, &quot;исходного кода&quot; данных - не обязательно исходного кода программы, но оригинальной формы данных.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;7-характеристики-модели-llm&quot;&gt;7. Характеристики модели LLM&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Эта модель становится 1 ГБ через несколько шагов и представляет собой относительно небольшой набор данных.
Относительно чего это мало, но в терминах LLM это считается небольшим.
И не факт, что она все еще в состоянии, которое можно изменить.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;8-использование-векторных-баз-данных&quot;&gt;8. Использование векторных баз данных&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Если мы хотим поместить свою собственную информацию в отдельную базу данных, мы обычно используем векторную базу данных.
Векторная база данных - это специальное приложение, которое может определить расстояние между двумя фрагментами текста.
То есть, насколько они об одном и том же, и сколько у них точных ключевых слов?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;9-подготовка-базы-знаний&quot;&gt;9. Подготовка базы знаний&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Мы разрезаем доступную в компании базу знаний на куски текста.
Эти куски текста обычно длиной в тысячу символов или тысячу букв и образуют отдельные записи.
Между ними есть небольшое перекрытие, поэтому мы начинаем следующий не там, где закончился предыдущий, а немного раньше.
Это для того, чтобы иметь контекст и непрерывность в тексте.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;10-алгоритм-встраивания&quot;&gt;10. Алгоритм встраивания&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Мы помещаем каждый из этих кусков текста в базу данных и просим алгоритм встраивания присвоить ему вектор.
Вектор - это последовательность чисел.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Это похоже, например, на GPS-координаты.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;По сути, этот вектор - это пространственная координата этого текста, но это пространство не трехмерное, а очень многомерное.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;11-работа-rag-для-вопросов&quot;&gt;11. Работа RAG для вопросов&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Когда пользователь задает вопрос приложению, разработанному с технологией RAG, мы также векторизуем этот вопрос.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Мы просим систему встраивания сказать нам, где этот вопрос находится в пространстве.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Затем мы можем спросить у векторной базы данных, в которую мы поместили векторы, принадлежащие всем нашим кускам текста, какие куски текста из нашей базы знаний находятся ближе всего в пространстве к вопросу.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;12-расчет-расстояния-между-векторами&quot;&gt;12. Расчет расстояния между векторами&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Это расчет расстояния и индексирование.
Если хотите, можете рассчитать расстояние по теореме Пифагора в ортогональном векторном пространстве.
Хотя это звучит сложно, нам на самом деле не нужно с этим разбираться или знать, как это работает.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;13-характеристики-алгоритма-встраивания&quot;&gt;13. Характеристики алгоритма встраивания&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Суть в том, что этот алгоритм встраивания обычно также основан на нейронной сети.
Есть и элементарные алгоритмы встраивания, но они практически менее применимы.
Существуют более сложные системы встраивания, основанные на нейронных сетях, которые делают это в зависимости от языка.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;14-выбор-релевантных-кусков-текста&quot;&gt;14. Выбор релевантных кусков текста&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Векторная база данных сообщает нам, какие куски текста из нашей базы знаний близки к вопросу, то есть релевантны для ответа на вопрос.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;15-сборка-промпта&quot;&gt;15. Сборка промпта&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;После этого мы задаем LLM промпт, который не является оригинальным, а мы помещаем перед ним те куски текста, которые мы извлекли из нашей собственной базы знаний.
Мы не можем поместить все это в один вопрос, потому что это было бы слишком много, но мы можем включить несколько, пять, шесть, семь или даже десять из базы знаний.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Мы пишем в промпте, что это контекст, и мы хотим получить ответ в этом контексте, затем сам вопрос.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;16-резюме-процесса-rag&quot;&gt;16. Резюме процесса RAG&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Затем мы отправляем это алгоритму LLM, который читает его, делает с ним что-то и отвечает на него.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;И это все.
Весь RAG настолько прост.
Вам нужна векторная база данных; вам нужно разрезать текст.
Если кто-то понимает программирование, они знают, что это не большое дело.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Нам нужно поместить текст в обычную базу данных, чтобы мы могли восстановить его для генерации промпта.
Мы помещаем векторы в векторную базу данных, чтобы мы могли спросить, какие куски текста релевантны для данного вопроса.
Затем нам нужно уметь задавать вопросы LLM из программы и программировать стандартные интерфейсы.
Наконец, нам нужно уметь отправлять ответ обратно клиенту или пользователю, который может его прочитать.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;17-заключение&quot;&gt;17. Заключение&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;С помощью этой технологии мы создали приложение, с которым можно общаться точно так же, как с ChatGPT.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Но оно знает не только вещи большого мира до определенного момента времени, когда его обучение было завершено, но и вещи из нашей специальной базы знаний.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">1. Введение</summary></entry><entry><title type="html">Az LLM és a RAG technológia</title><link href="https://javax0.github.io/2024/07/22/llm-and-rag-hu.html" rel="alternate" type="text/html" title="Az LLM és a RAG technológia" /><published>2024-07-22T00:00:00+02:00</published><updated>2024-07-22T00:00:00+02:00</updated><id>https://javax0.github.io/2024/07/22/llm-and-rag-hu</id><content type="html" xml:base="https://javax0.github.io/2024/07/22/llm-and-rag-hu.html">&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;1-bevezetés&quot;&gt;1. Bevezetés&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ez a cikk egy rövid bevezető az LLM és a RAG technológiába.
A cikk sok egyszerűsítést tartalmaz, a célja, hogy a laikusok számára is érthető legyen.
Ha részletesebben érdekel a technológia, akkor ez a cikk nem lesz elég, sőt találhatsz benne olyan részeket amik nem teljesen pontosak, bár a lényeget jól átadják.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;2-a-rag-technológia-lényege&quot;&gt;2. A RAG technológia lényege&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Az RAG a Retrieval Augmented Generation rövidítése.
Ez egy angol betűszó.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ez a technológia próbálja kiegészíteni az LLM, azaz a Large Language Model alkalmazásokat.
A cél, hogy képesek legyenek kezelni olyan tudásbázist, olyan tudást, amely a Large Language Modelben magában nem található meg.
A Large Language Model önmagában egy olyan neurális hálózat, amit valamilyen módon tréningeztek.
Általában olyan adatokkal tréningezik, amelyek szabadon rendelkezésre állnak az interneten, igen nagy mennyiségben.
Ennek hatására a Large Language Modelek szinte emberi módon képesek kommunikálni.
Ha valamilyen kérdést felteszünk nekik, akkor erre tudnak válaszolni.
De fogalmuk sincs arról, milyen adatok vagy információk vannak egy vállalaton belül, hiszen ezek nem publikus adatok.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;3-az-llm-ek-korlátai&quot;&gt;3. Az LLM-ek korlátai&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Az LLM nem tanítható meg a mostani formában ezekre a vállalati információkra.
A jelenleg rendelkezésre álló alkalmazások úgy működnek, hogy a fejlesztők kialakítanak valamilyen modellt.
Utána trénelik ezt a modellt, több millió vagy milliárd paramétert állítanak be a tréning adatokkal.
Kérdéseket tesznek fel neki, jönnek a válaszok, és akkor a válaszok minősége alapján állítgatják ezeket a paramétereket.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Természetesen nem kézzel - erre vannak programok és algoritmusok.
Ez a folyamat néhány hónap alatt készül el a mostani viszonyok között, egy kisebb város energiaigényét felhasználva.
Sok ezer gépen futtatják ezt a finomhangoló algoritmust.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;4-az-llm-modellek-jellemzői&quot;&gt;4. Az LLM modellek jellemzői&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Amikor ez készen van, a modell letölthető és futtatható egy saját gépen.
Maga a modell 1-2 GB-nyi adatot jelent.
Ezután ez a neurális hálózat már nem változik, nem tanul meg új dolgokat.
Csak akkor tud új dolgot megtanulni, ha kapunk belőle egy új változatot.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;5-a-rag-technológia-alkalmazása&quot;&gt;5. A RAG technológia alkalmazása&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Mégis szeretnénk ezt a fajta lehetőséget egy cégen belül használni.
Azt szeretnénk, hogy ha egy kérdést felteszünk ennek a neurális hálózatnak, az LLM modellnek, akkor olyan választ adjon, ami figyelembe veszi a saját cégünk belső információit.
Ezt úgy tudjuk megtenni, mintha egy emberrel is ilyesmit csinálnánk.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ha jön valaki a céghez, és kérdéseket akarunk neki feltenni a céggel kapcsolatban, de nem tud semmit a cégünkről, akkor először megtanítjuk dolgokra, információkat adunk neki.
Ő ezeket az információkat el fogja tenni a saját neurális hálójába.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;6-a-rag-működési-elve&quot;&gt;6. A RAG működési elve&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Gondolhatjuk úgy, hogy fókuszálva a munkára, amikor hazamegy, minden mást elfelejtett, és ezeket a cégspecifikus információkat egy külön helyre rakja el.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Az LLM-nél és a RAG-nál is ez a modell.
Azokat az információkat, amik nincsenek benne az LLM neurális hálójában, külön rakjuk el egy külön adatbázisba.
Ha másért nem, azért, mert magának a neurális hálónak az adatbázisába, a modelljébe nem tudjuk beletenni.
Ezek nem publikusak, nem tudjuk, hogyan néznek ki, hogyan épülnek fel, és nem is feltétlenül módosíthatók már abban a formában, ahogyan a programban benne vannak.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Nincs meg, mondhatjuk talán így, hogy az adatok &quot;forráskódja&quot; - nem feltétlenül a program forráskódja, hanem az adatok eredeti formája.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;7-az-llm-modell-jellemzői&quot;&gt;7. Az LLM modell jellemzői&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ez a modell több lépcsőn keresztül lesz végül is egy 1 GB-os, tehát aránylag kicsinek tekinthető adathalmaz.
Relatív, hogy mi a kicsi, de egy LLM értelemben ez kicsinek tekinthető.
És nem biztos, hogy ez még olyan állapotban van, ami módosítható.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;8-vektoradatbázisok-használata&quot;&gt;8. Vektoradatbázisok használata&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ha egy külön adatbázisba akarjuk betenni azokat az információkat, amik saját információk, akkor erre úgynevezett vektoradatbázist szokás használni.
A vektoradatbázis egy speciális olyan alkalmazás, ami két szövegdarabról meg tudja mondani, hogy mennyire vannak közel egymáshoz.
Tehát mennyire szólnak ugyanarról, mennyire ugyanazok a kulcsszavak benne.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;9-a-tudásbázis-előkészítése&quot;&gt;9. A tudásbázis előkészítése&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A tudásbázist, ami a cégen belül rendelkezésre áll, felszabdaljuk szövegdarabokra.
Ezek a szövegdarabok tipikusan ezer karakter, ezer betű hosszúságúak, és ezek képeznek egy-egy rekordot.
Van közöttük egy kis átfedés, tehát nem ott kezdjük a következőt, ahol az előzőnek vége szakadt, hanem egy kicsit előbb.
Ez azért van, hogy legyen egyfajta kontextus és folyamatosság a szövegben.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;10-az-embedding-algoritmus&quot;&gt;10. Az embedding algoritmus&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Minden egyes ilyen szövegdarabot elteszünk egy adatbázisba, és megkérünk egy úgynevezett embedding algoritmust, hogy a szövegdarabhoz rendeljen hozzá egy úgynevezett vektort.
A vektor egy számsorozat.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ez hasonló ahhoz, mint például egy GPS koordináta.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Tulajdonképpen ez a vektor ennek a darab szövegnek egy térbeli koordinátája, de ez a tér nem háromdimenziós, hanem nagyon sokdimenziós.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;11-a-rag-működése-kérdések-esetén&quot;&gt;11. A RAG működése kérdések esetén&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Amikor feltesz egy kérdést a felhasználó a RAG technológiával fejlesztett alkalmazásnak, akkor ezt a kérdést is vektorizáljuk.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Megkérjük az embeddings rendszert, hogy mondja meg, hogy a térben hol helyezkedik el ez a kérdés.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;És utána a vektoradatbázistól, amibe beleraktuk az összes szövegdarabunkhoz tartozó vektorokat, meg tudjuk kérdezni, hogy melyek azok a szövegdarabok a mi tudásbázisunkból, amelyek a legközelebb vannak térben a kérdéshez.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;12-a-vektorok-közötti-távolságszámítás&quot;&gt;12. A vektorok közötti távolságszámítás&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ez egy távolságszámolás és egyfajta indexelés.
Ha úgy tetszik, Pitagorasz-tétellel lehet számolni a távolságot egy ortogonális vektor térben.
Bonyolultnak hangzik, nem is kell vele igazából foglalkozni, nem kell tudnunk, hogy ez hogyan működik.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;13-az-embedding-algoritmus-jellemzői&quot;&gt;13. Az embedding algoritmus jellemzői&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A lényeg az, hogy ez az embedding algoritmus, ami amúgy szintén egy neurális hálón szokott alapulni.
Vannak nagyon egyszerű embedding algoritmusok is, ezek praktikusan kevésbé használhatóak.
De vannak olyan bonyolultabb neurális hálók, amik ezt megteszik, nyelvtől függően.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;14-a-releváns-szövegdarabok-kiválasztása&quot;&gt;14. A releváns szövegdarabok kiválasztása&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A vektoradatbázis megmondja, hogy melyek azok a szövegdarabok a mi tudásbázisunkból, amelyek közel vannak a kérdéshez, vagyis relevánsak a kérdés megválaszolásához.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;15-a-prompt-összeállítása&quot;&gt;15. A prompt összeállítása&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ezek után az LLM-től mi egy olyan promptot kérdezünk, ami nem az eredeti prompt, hanem elé betesszük azokat a szövegdarabokat, amelyeket kiszedtünk a saját tudásbázisunkból.
Az egészet nem tehetjük be egy kérdésbe, mert az túl sok lenne, de néhányat, ötöt, hatot, hetet, vagy akár tizet be tudunk tenni a tudásbázisból.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Beleírjuk a promptba, hogy ez egy kontextus, és a választ ebben a kontextusban szeretnénk megkapni, majd magát a kérdést.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;16-a-rag-folyamat-összefoglalása&quot;&gt;16. A RAG folyamat összefoglalása&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Utána ezt elküldjük az LLM algoritmusnak, ami ezt elolvassa, csinál vele valamit, megválaszolja.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;És tulajdonképpen ez az egész RAG ennyire egyszerű.
Kell hozzá egy vektoradatbázis, föl kell darabolnunk a szöveget.
Ha valaki ért a programozáshoz, az tudja, hogy ez nem egy olyan nagy dolog.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Bele kell tenni egy normál adatbázisba magát a szöveget, hogy magát a szöveget a prompt gyártásához vissza tudjuk állítani.
Beletesszük a vektorokat a vektoradatbázisba, hogy meg tudjuk kérdezni, hogy melyik a releváns szövegdarabok egy adott kérdéshez.
Utána egy programból föl kell tudnunk tenni a kérdést az LLM-nek, standard interfészeket kell tudni programozni.
Végül a választ vissza kell tudni küldeni az ügyfélnek, felhasználónak, aki ezt el tudja olvasni.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;17-összegzés&quot;&gt;17. Összegzés&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;És ezzel a technológiával elő tudtunk állítani egy olyan alkalmazást, amelyikkel ugyanúgy lehet csetelni, mint a ChatGPT-vel.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;De nem csak a nagyvilág dolgait tudja egy adott időpillanatig, amikor is lezárták a tréningét, hanem tudja azokat a dolgokat is, amik a mi speciális tudásbázisunkban vannak benne.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">1. Bevezetés</summary></entry><entry><title type="html">Tecnología LLM y RAG</title><link href="https://javax0.github.io/2024/07/22/llm-and-rag-es.html" rel="alternate" type="text/html" title="Tecnología LLM y RAG" /><published>2024-07-22T00:00:00+02:00</published><updated>2024-07-22T00:00:00+02:00</updated><id>https://javax0.github.io/2024/07/22/llm-and-rag-es</id><content type="html" xml:base="https://javax0.github.io/2024/07/22/llm-and-rag-es.html">&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;1-introducción&quot;&gt;1. Introducción&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Este artículo es una breve introducción a la tecnología LLM y RAG.
El artículo contiene muchas simplificaciones que las personas no especializadas pueden entender.
Si estás interesado en la tecnología con más detalle, este artículo no será suficiente. Puedes encontrar partes que no son completamente precisas, aunque transmiten bien la esencia.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;2-la-esencia-de-la-tecnología-rag&quot;&gt;2. La esencia de la tecnología RAG&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;RAG es un acrónimo de Retrieval Augmented Generation (Generación Aumentada por Recuperación).
Es un acrónimo en inglés.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Esta tecnología intenta complementar las aplicaciones LLM o Large Language Model (Modelo de Lenguaje Grande).
El objetivo es poder manejar bases de conocimiento e información que no se encuentran en el propio Modelo de Lenguaje Grande.
El Modelo de Lenguaje Grande es una red neuronal que ha sido entrenada de alguna manera.
Usualmente se entrenan con grandes cantidades de datos que están disponibles libremente en línea.
Como resultado, los Modelos de Lenguaje Grande pueden comunicarse de una manera casi humana.
Si les hacemos una pregunta, pueden responderla.
Sin embargo, necesitan aprender sobre qué datos o información existen dentro de una empresa, ya que estos no son datos públicos.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;3-limitaciones-de-los-llm&quot;&gt;3. Limitaciones de los LLM&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Los LLM no pueden ser enseñados esta información corporativa en su forma actual.
Actualmente, las aplicaciones disponibles funcionan cuando los desarrolladores crean algunos modelos.
Luego, entrenan este modelo, estableciendo millones o miles de millones de parámetros con datos de entrenamiento.
Hacen preguntas, obtienen respuestas y luego ajustan estos parámetros basándose en la calidad de las respuestas.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Por supuesto, hay programas y algoritmos para esto, no se hace a mano.
En las condiciones actuales, este proceso tarda unos meses en completarse utilizando los requisitos energéticos de una pequeña ciudad.
Ejecutan este algoritmo de ajuste fino en miles de máquinas.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;4-características-de-los-modelos-llm&quot;&gt;4. Características de los modelos LLM&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Cuando está listo, el modelo se puede descargar y ejecutar en tu máquina.
El modelo en sí representa 1-2 GB de datos.
Después de esto, esta red neuronal ya no cambia; no aprende cosas nuevas.
Solo puede aprender algo nuevo si obtenemos una nueva versión.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;5-aplicación-de-la-tecnología-rag&quot;&gt;5. Aplicación de la tecnología RAG&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Sin embargo, queremos usar este tipo de capacidad dentro de una empresa.
Queremos que esta red neuronal, el modelo LLM, dé una respuesta que tenga en cuenta la información interna de nuestra empresa cuando hacemos una pregunta.
Podemos hacer esto como si estuviéramos haciendo algo similar con humanos.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Si alguien viene a la empresa, y queremos hacerle preguntas sobre la empresa, pero no saben nada sobre nuestra empresa, primero les enseñamos cosas y les damos información.
Ellos pondrán esta información en su red neuronal.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;6-principio-de-funcionamiento-de-rag&quot;&gt;6. Principio de funcionamiento de RAG&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Podemos ver si se enfocan en el trabajo y olvidan todo lo demás cuando se van a casa, y mantienen esta información específica de la empresa en un lugar separado.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Este es el modelo para LLM y RAG también.
Ponemos la información que no está en la red neuronal del LLM por separado en una base de datos separada.
Si no por otra razón, no podemos ponerla en la base de datos de la red neuronal o en su modelo.
Estos son privados. No sabemos cómo se ven o cómo están estructurados, y no necesariamente son modificables en la forma en que están en el programa.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;No tenemos, podríamos decir, el &quot;código fuente&quot; de los datos - no necesariamente el código fuente del programa, sino la forma original de los datos.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;7-características-del-modelo-llm&quot;&gt;7. Características del modelo LLM&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Este modelo se convierte en 1 GB a través de varios pasos y es un conjunto de datos relativamente pequeño.
Es relativo a lo que es pequeño, pero en términos de LLM, esto se considera pequeño.
Y no es seguro que todavía esté en un estado que pueda ser modificado.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;8-uso-de-bases-de-datos-vectoriales&quot;&gt;8. Uso de bases de datos vectoriales&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Si queremos poner nuestra propia información en una base de datos separada, normalmente usamos una base de datos vectorial.
Una base de datos vectorial es una aplicación especial que puede determinar la distancia entre dos piezas de texto.
Entonces, ¿cuánto tratan sobre lo mismo y cuántas son las palabras clave exactas?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;9-preparación-de-la-base-de-conocimientos&quot;&gt;9. Preparación de la base de conocimientos&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Cortamos la base de conocimientos disponible dentro de la empresa en piezas de texto.
Estas piezas de texto típicamente tienen mil caracteres o mil letras de largo y forman registros individuales.
Hay un poco de superposición entre ellos, así que no empezamos el siguiente donde terminó el anterior, sino un poco antes.
Esto es para tener contexto y continuidad en el texto.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;10-el-algoritmo-de-incrustación&quot;&gt;10. El algoritmo de incrustación&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ponemos cada una de estas piezas de texto en una base de datos y le pedimos a un algoritmo de incrustación que le asigne un vector.
El vector es una secuencia de números.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Es similar a, por ejemplo, coordenadas GPS.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Esencialmente, este vector es una coordenada espacial de este texto, pero este espacio no es tridimensional sino muy multidimensional.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;11-operación-rag-para-preguntas&quot;&gt;11. Operación RAG para preguntas&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Cuando un usuario dirige una pregunta a una aplicación desarrollada con tecnología RAG, también vectorizamos esta pregunta.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Le pedimos al sistema de incrustación que nos diga dónde se encuentra esta pregunta en el espacio.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Luego, podemos preguntarle a la base de datos vectorial, en la que pusimos los vectores pertenecientes a todas nuestras piezas de texto, qué piezas de texto de nuestra base de conocimientos están más cerca en el espacio de la pregunta.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;12-cálculo-de-distancia-entre-vectores&quot;&gt;12. Cálculo de distancia entre vectores&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Es un cálculo de distancia e indexación.
Si quieres, puedes calcular la distancia con el teorema de Pitágoras en un espacio vectorial ortogonal.
Aunque suena complicado, realmente no necesitamos ocuparnos de ello o saber cómo funciona.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;13-características-del-algoritmo-de-incrustación&quot;&gt;13. Características del algoritmo de incrustación&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;El punto es que este algoritmo de incrustación generalmente también se basa en una red neuronal.
También hay algoritmos de incrustación elementales, pero estos son prácticamente menos utilizables.
Hay sistemas de incrustación más complejos basados en redes neuronales que hacen esto, dependiendo del idioma.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;14-selección-de-piezas-de-texto-relevantes&quot;&gt;14. Selección de piezas de texto relevantes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;La base de datos vectorial nos dice qué piezas de texto de nuestra base de conocimientos están cerca de la pregunta, lo que significa que son relevantes para responder la pregunta.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;15-ensamblaje-del-prompt&quot;&gt;15. Ensamblaje del prompt&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Después de esto, le pedimos al LLM un prompt que no es el original, sino que ponemos delante de él esas piezas de texto que extrajimos de nuestra propia base de conocimientos.
No podemos encajar todo en una sola pregunta porque sería demasiado, pero podemos incluir algunas, cinco, seis, siete o incluso diez de la base de conocimientos.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Escribimos en el prompt que este es un contexto, y queremos obtener la respuesta en este contexto, luego la pregunta en sí.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;16-resumen-del-proceso-rag&quot;&gt;16. Resumen del proceso RAG&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Luego, enviamos esto al algoritmo LLM, que lo lee, hace algo con él y lo responde.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Y esto es todo.
Todo el RAG es así de simple.
Necesitas una base de datos vectorial; necesitas cortar el texto.
Si alguien entiende de programación, sabe que esto no es gran cosa.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Necesitamos poner el texto en una base de datos normal para poder restaurarlo para la generación de prompts.
Ponemos los vectores en la base de datos vectorial para poder preguntar cuáles son las piezas de texto relevantes para una pregunta dada.
Luego, necesitamos poder hacer preguntas al LLM desde un programa y programar interfaces estándar.
Finalmente, necesitamos poder enviar la respuesta de vuelta al cliente o usuario que puede leerla.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;17-resumen&quot;&gt;17. Resumen&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Con esta tecnología, producimos una aplicación con la que puedes chatear igual que con ChatGPT.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Pero sabe no solo las cosas del gran mundo hasta cierto punto en el tiempo cuando se cerró su entrenamiento, sino también las cosas en nuestra base de conocimientos especial.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">1. Introducción</summary></entry><entry><title type="html">LLM- und RAG-Technologie</title><link href="https://javax0.github.io/2024/07/22/llm-and-rag-de.html" rel="alternate" type="text/html" title="LLM- und RAG-Technologie" /><published>2024-07-22T00:00:00+02:00</published><updated>2024-07-22T00:00:00+02:00</updated><id>https://javax0.github.io/2024/07/22/llm-and-rag-de</id><content type="html" xml:base="https://javax0.github.io/2024/07/22/llm-and-rag-de.html">&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;1-einleitung&quot;&gt;1. Einleitung&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Dieser Artikel ist eine kurze Einführung in die LLM- und RAG-Technologie.
Der Artikel enthält viele Vereinfachungen, die Laien verstehen können.
Wenn Sie sich für die Technologie im Detail interessieren, wird dieser Artikel nicht ausreichen. Sie werden möglicherweise Teile finden, die nicht ganz genau sind, obwohl sie das Wesentliche gut vermitteln.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;2-das-wesen-der-rag-technologie&quot;&gt;2. Das Wesen der RAG-Technologie&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;RAG ist ein Akronym für Retrieval Augmented Generation.
Es ist ein englisches Akronym.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Diese Technologie versucht, LLM- oder Large Language Model-Anwendungen zu ergänzen.
Das Ziel ist es, Wissensdatenbanken und Informationen behandeln zu können, die sich nicht im Large Language Model selbst befinden.
Das Large Language Model ist ein neuronales Netzwerk, das irgendwie trainiert wurde.
Sie werden normalerweise mit großen Mengen an Daten trainiert, die online frei verfügbar sind.
Infolgedessen können Large Language Models auf fast menschenähnliche Weise kommunizieren.
Wenn wir ihnen eine Frage stellen, können sie diese beantworten.
Sie müssen jedoch lernen, welche Daten oder Informationen innerhalb eines Unternehmens existieren, da es sich hierbei nicht um öffentliche Daten handelt.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;3-einschränkungen-von-llms&quot;&gt;3. Einschränkungen von LLMs&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;LLMs können diese Unternehmensinformationen in ihrer aktuellen Form nicht erlernen.
Derzeit funktionieren verfügbare Anwendungen so, dass Entwickler einige Modelle erstellen.
Dann trainieren sie dieses Modell, indem sie Millionen oder Milliarden von Parametern mit Trainingsdaten festlegen.
Sie stellen Fragen, erhalten Antworten und passen dann diese Parameter basierend auf der Qualität der Antworten an.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Natürlich gibt es dafür Programme und Algorithmen, nicht von Hand.
Unter den aktuellen Bedingungen dauert dieser Prozess einige Monate und verbraucht den Energiebedarf einer kleinen Stadt.
Sie führen diesen Feinabstimmungsalgorithmus auf Tausenden von Maschinen aus.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;4-eigenschaften-von-llm-modellen&quot;&gt;4. Eigenschaften von LLM-Modellen&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wenn es fertig ist, kann das Modell heruntergeladen und auf Ihrem Rechner ausgeführt werden.
Das Modell selbst repräsentiert 1-2 GB an Daten.
Danach ändert sich dieses neuronale Netzwerk nicht mehr; es lernt keine neuen Dinge.
Es kann nur etwas Neues lernen, wenn wir eine neue Version erhalten.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;5-anwendung-der-rag-technologie&quot;&gt;5. Anwendung der RAG-Technologie&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Dennoch möchten wir diese Art von Fähigkeit innerhalb eines Unternehmens nutzen.
Wir möchten, dass dieses neuronale Netzwerk, das LLM-Modell, eine Antwort gibt, die die internen Informationen unseres Unternehmens berücksichtigt, wenn wir eine Frage stellen.
Wir können dies tun, als ob wir etwas Ähnliches mit Menschen machen würden.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wenn jemand in das Unternehmen kommt und wir ihm Fragen über das Unternehmen stellen möchten, er aber nichts über unser Unternehmen weiß, bringen wir ihm zuerst Dinge bei und geben ihm Informationen.
Sie werden diese Informationen in ihr neuronales Netzwerk einfügen.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;6-funktionsprinzip-von-rag&quot;&gt;6. Funktionsprinzip von RAG&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wir können sehen, ob sie sich auf die Arbeit konzentrieren und alles andere vergessen, wenn sie nach Hause gehen, und sie diese unternehmensspezifischen Informationen an einem separaten Ort aufbewahren.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Es ist das Modell für LLM und RAG gleichermaßen.
Wir legen die Informationen, die sich nicht in der neuronalen Netzwerkdatenbank des LLM befinden, separat in einer separaten Datenbank ab.
Wenn aus keinem anderen Grund, können wir es nicht in die Datenbank des neuronalen Netzwerks oder in sein Modell einfügen.
Diese sind privat. Wir wissen nicht, wie sie aussehen oder wie sie strukturiert sind, und sie sind nicht unbedingt in der Form, in der sie sich im Programm befinden, modifizierbar.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wir haben, könnte man sagen, nicht den &quot;Quellcode&quot; der Daten - nicht unbedingt den Quellcode des Programms, sondern die ursprüngliche Form der Daten.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;7-eigenschaften-des-llm-modells&quot;&gt;7. Eigenschaften des LLM-Modells&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Dieses Modell wird durch mehrere Schritte zu 1 GB und ist ein relativ kleiner Datensatz.
Es ist relativ, was klein ist, aber in LLM-Begriffen wird dies als klein betrachtet.
Und es ist nicht sicher, ob es sich noch in einem Zustand befindet, der modifiziert werden kann.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;8-verwendung-von-vektordatenbanken&quot;&gt;8. Verwendung von Vektordatenbanken&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wenn wir unsere eigenen Informationen in eine separate Datenbank einfügen möchten, verwenden wir normalerweise eine Vektordatenbank.
Eine Vektordatenbank ist eine spezielle Anwendung, die den Abstand zwischen zwei Textstücken bestimmen kann.
Also wie viel geht es um das Gleiche und wie viele sind die exakten Schlüsselwörter?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;9-vorbereitung-der-wissensbasis&quot;&gt;9. Vorbereitung der Wissensbasis&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wir zerschneiden die im Unternehmen verfügbare Wissensbasis in Textstücke.
Diese Textstücke sind typischerweise tausend Zeichen oder tausend Buchstaben lang und bilden einzelne Datensätze.
Es gibt eine kleine Überlappung zwischen ihnen, sodass wir den nächsten nicht dort beginnen, wo der vorherige endete, sondern etwas früher.
Dies geschieht, um Kontext und Kontinuität im Text zu haben.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;10-der-embedding-algorithmus&quot;&gt;10. Der Embedding-Algorithmus&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wir legen jedes dieser Textstücke in eine Datenbank und bitten einen Embedding-Algorithmus, ihm einen Vektor zuzuweisen.
Der Vektor ist eine Folge von Zahlen.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Es ist ähnlich wie zum Beispiel GPS-Koordinaten.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Im Wesentlichen ist dieser Vektor eine räumliche Koordinate dieses Textes, aber dieser Raum ist nicht dreidimensional, sondern sehr mehrdimensional.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;11-rag-betrieb-für-fragen&quot;&gt;11. RAG-Betrieb für Fragen&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wenn ein Benutzer eine Frage an eine mit RAG-Technologie entwickelte Anwendung richtet, vektorisieren wir auch diese Frage.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wir bitten das Embedding-System, uns mitzuteilen, wo sich diese Frage im Raum befindet.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Dann können wir die Vektordatenbank, in die wir die zu allen unseren Textstücken gehörenden Vektoren eingefügt haben, fragen, welche Textstücke aus unserer Wissensbasis im Raum der Frage am nächsten sind.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;12-distanzberechnung-zwischen-vektoren&quot;&gt;12. Distanzberechnung zwischen Vektoren&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Es handelt sich um eine Distanzberechnung und Indexierung.
Wenn Sie möchten, können Sie den Abstand mit dem Satz des Pythagoras in einem orthogonalen Vektorraum berechnen.
Obwohl es kompliziert klingt, müssen wir uns damit nicht wirklich befassen oder wissen, wie es funktioniert.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;13-eigenschaften-des-embedding-algorithmus&quot;&gt;13. Eigenschaften des Embedding-Algorithmus&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Der Punkt ist, dass dieser Embedding-Algorithmus normalerweise auch auf einem neuronalen Netzwerk basiert.
Es gibt auch elementare Embedding-Algorithmen, aber diese sind praktisch weniger nutzbar.
Es gibt komplexere Embedding-Systeme, die auf neuronalen Netzwerken basieren und dies je nach Sprache tun.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;14-auswahl-relevanter-textstücke&quot;&gt;14. Auswahl relevanter Textstücke&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Die Vektordatenbank teilt uns mit, welche Textstücke aus unserer Wissensbasis der Frage nahe sind, was bedeutet, dass sie für die Beantwortung der Frage relevant sind.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;15-zusammenstellung-des-prompts&quot;&gt;15. Zusammenstellung des Prompts&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Danach bitten wir das LLM um einen Prompt, der nicht das Original ist, sondern wir stellen ihm die Textstücke voran, die wir aus unserer eigenen Wissensbasis extrahiert haben.
Wir können nicht das Ganze in eine Frage packen, weil es zu viel wäre, aber wir können einige, fünf, sechs, sieben oder sogar zehn aus der Wissensbasis einbeziehen.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wir schreiben in den Prompt, dass dies ein Kontext ist, und wir möchten die Antwort in diesem Kontext erhalten, dann die Frage selbst.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;16-zusammenfassung-des-rag-prozesses&quot;&gt;16. Zusammenfassung des RAG-Prozesses&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Dann senden wir dies an den LLM-Algorithmus, der es liest, etwas damit macht und es beantwortet.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Und das ist es.
Der ganze RAG ist so einfach.
Man braucht eine Vektordatenbank; man muss den Text zerschneiden.
Wenn jemand Programmierung versteht, weiß er, dass dies keine große Sache ist.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wir müssen den Text in eine normale Datenbank einfügen, damit wir ihn für die Prompt-Generierung wiederherstellen können.
Wir legen die Vektoren in die Vektordatenbank, damit wir fragen können, welche die relevanten Textstücke für eine bestimmte Frage sind.
Dann müssen wir in der Lage sein, dem LLM Fragen aus einem Programm zu stellen und Standardschnittstellen zu programmieren.
Schließlich müssen wir in der Lage sein, die Antwort an den Kunden oder Benutzer zurückzusenden, der sie lesen kann.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;17-zusammenfassung&quot;&gt;17. Zusammenfassung&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Mit dieser Technologie haben wir eine Anwendung erstellt, mit der man genauso chatten kann wie mit ChatGPT.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Aber sie kennt nicht nur die Dinge der großen Welt bis zu einem bestimmten Zeitpunkt, als ihr Training abgeschlossen wurde, sondern auch die Dinge in unserer speziellen Wissensbasis.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">1. Einleitung</summary></entry><entry><title type="html">LLM and RAG technology</title><link href="https://javax0.github.io/2024/07/22/llm-and-rag.html" rel="alternate" type="text/html" title="LLM and RAG technology" /><published>2024-07-22T00:00:00+02:00</published><updated>2024-07-22T00:00:00+02:00</updated><id>https://javax0.github.io/2024/07/22/llm-and-rag</id><content type="html" xml:base="https://javax0.github.io/2024/07/22/llm-and-rag.html">&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This article is a brief introduction to LLM and RAG technology.
The article contains many simplifications that laypeople can understand.
If you&amp;#8217;re interested in the technology in more detail, this article won&amp;#8217;t be enough. You may find parts that aren&amp;#8217;t entirely accurate, although they convey the essence well.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;2-the-essence-of-rag-technology&quot;&gt;2. The essence of RAG technology&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;RAG is an acronym for Retrieval Augmented Generation.
It is an English acronym.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This technology tries to complement LLM or Large Language Model applications.
The goal is to be able to handle knowledge bases and information that are not found in the Large Language Model itself.
The Large Language Model is a neural network that has been trained somehow.
They are usually trained with large quantities of data that are freely available online.
As a result, Large Language Models can communicate in an almost human-like manner.
If we ask them a question, they can answer it.
However, they need to learn about what data or information exists within a company, as these are not public data.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;3-limitations-of-llms&quot;&gt;3. Limitations of LLMs&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;LLMs cannot be taught this corporate information in their current form.
Currently, available applications work by developers creating some models.
Then, they train this model, setting millions or billions of parameters with training data.
They ask questions, get answers, and then adjust these parameters based on the quality of the answers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Of course, there are programs and algorithms for this, not by hand.
Under current conditions, this process takes a few months to complete using the energy requirements of a small city.
They run this fine-tuning algorithm on thousands of machines.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;4-characteristics-of-llm-models&quot;&gt;4. Characteristics of LLM models&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When done, the model can be downloaded and run on your machine.
The model itself represents 1-2 GB of data.
After this, this neural network no longer changes; it doesn&amp;#8217;t learn new things.
It can only learn something new if we get a new version.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;5-application-of-rag-technology&quot;&gt;5. Application of RAG technology&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Yet we want to use this kind of capability within a company.
We want this neural network, the LLM model, to give an answer that takes into account our company&amp;#8217;s internal information when we ask a question.
We can do this as if we were doing something similar with humans.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If someone comes to the company, and we want to ask them questions about the company, but they don&amp;#8217;t know anything about our company, we first teach them things and give them information.
They will put this information into their neural network.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;6-operating-principle-of-rag&quot;&gt;6. Operating principle of RAG&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We can see if they focus on work and forget everything else when they go home, and they keep this company-specific information in a separate place.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It is the model for LLM and RAG as well.
We put the information that isn&amp;#8217;t in the LLM&amp;#8217;s neural network separately in a separate database.
If for no other reason, we can&amp;#8217;t put it into the neural network&amp;#8217;s database or into its model.
These are private. We don&amp;#8217;t know what they look like or how they&amp;#8217;re structured, and they&amp;#8217;re not necessarily modifiable in the form they&amp;#8217;re in the program.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We don&amp;#8217;t have, we might say, the &quot;source code&quot; of the data - not necessarily the program&amp;#8217;s source code, but the original form of the data.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;7-characteristics-of-the-llm-model&quot;&gt;7. Characteristics of the LLM model&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This model becomes 1 GB through several steps and is a relatively small data set.
It&amp;#8217;s relative to what&amp;#8217;s small, but in LLM terms, this is considered small.
And it&amp;#8217;s not sure it&amp;#8217;s still in a state that can be modified.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;8-use-of-vector-databases&quot;&gt;8. Use of vector databases&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If we want to put our own information into a separate database, we usually use a vector database.
A vector database is a special application that can determine the distance between two pieces of text.
So how much are they about the same thing, and how many are the exact keywords?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;9-preparing-the-knowledge-base&quot;&gt;9. Preparing the knowledge base&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We cut up the knowledge base available within the company into pieces of text.
These pieces of text are typically a thousand characters or a thousand letters long and form individual records.
There&amp;#8217;s a little overlap between them, so we don&amp;#8217;t start the next one where the previous one ended, but a little earlier.
It is to have context and continuity in the text.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;10-the-embedding-algorithm&quot;&gt;10. The embedding algorithm&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We put each of these pieces of text into a database and ask an embedding algorithm to assign it a vector.
The vector is a sequence of numbers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It is similar to, for example, GPS coordinates.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Essentially, this vector is a spatial coordinate of this text, but this space is not three-dimensional but very multi-dimensional.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;11-rag-operation-for-questions&quot;&gt;11. RAG operation for questions&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When a user addresses a question to an application developed with RAG technology, we also vectorize this question.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We ask the embedding system to tell us where this question is located in space.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Then, we can ask the vector database, into which we put the vectors belonging to all our text pieces, which text pieces from our knowledge base are closest in space to the question.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;12-distance-calculation-between-vectors&quot;&gt;12. Distance calculation between vectors&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It is a distance calculation and indexing.
If you like, you can calculate the distance with the Pythagorean theorem in an orthogonal vector space.
Although it sounds complicated, we don&amp;#8217;t really need to deal with it or know how it works.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;13-characteristics-of-the-embedding-algorithm&quot;&gt;13. Characteristics of the embedding algorithm&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The point is that this embedding algorithm is usually based on a neural network as well.
There are elementary embedding algorithms, too, but these are practically less usable.
There are more complex embedding systems based on neural networks that do this, depending on the language.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;14-selection-of-relevant-text-pieces&quot;&gt;14. Selection of relevant text pieces&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The vector database tells us which text pieces from our knowledge base are close to the question, meaning they are relevant to answering the question.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;15-assembling-the-prompt&quot;&gt;15. Assembling the prompt&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;After this, we ask the LLM for a prompt that is not the original, but we put in front of it those pieces of text we extracted from our own knowledge base.
We can&amp;#8217;t fit the whole thing into one question because it would be too much, but we can include a few, five, six, seven, or even ten from the knowledge base.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We write in the prompt that this is a context, and we want to get the answer in this context, then the question itself.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;16-summary-of-the-rag-process&quot;&gt;16. Summary of the RAG process&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Then, we send this to the LLM algorithm, which reads it, does something with it, and answers it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And this is it.
The whole RAG is that simple.
You need a vector database; you need to cut up the text.
If someone understands programming, they know this is not a big deal.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We need to put the text into a normal database so that we can restore it for prompt generation.
We put the vectors into the vector database so that we can ask which are the relevant text pieces for a given question.
Then, we need to be able to ask the LLM questions from a program and program standard interfaces.
Finally, we need to be able to send the answer back to the client or user who can read it.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;17-summary&quot;&gt;17. Summary&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With this technology, we produced an application that you can chat with just like ChatGPT.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;But it knows not only the things of the big world up to a certain point in time when its training was closed but also the things in our special knowledge base.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">1. Introduction</summary></entry><entry><title type="html">Threaded streams</title><link href="https://javax0.github.io/2024/02/29/threaded-stream.html" rel="alternate" type="text/html" title="Threaded streams" /><published>2024-02-29T00:00:00+01:00</published><updated>2024-02-29T00:00:00+01:00</updated><id>https://javax0.github.io/2024/02/29/threaded-stream</id><content type="html" xml:base="https://javax0.github.io/2024/02/29/threaded-stream.html">&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In the landscape of software development, efficiently processing large datasets has become paramount, especially with the advent of multicore processors.
The Java Stream interface provided a leap forward by enabling sequential and parallel operations on collections.
However, fully exploiting modern processors&apos; capabilities while retaining the Stream API&amp;#8217;s simplicity posed a challenge.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Responding to this, I created an open-source library aimed at experimenting with a new method of parallelizing stream operations.
This library diverges from traditional batching methods by processing each stream element in its own virtual thread, offering a more refined level of parallelism.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this article, I will talk about the library, and its design.
It is more detail than you need simply to use the library.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The library is available on GitHub at &lt;a href=&quot;https://github.com/verhas/vtstream&quot; class=&quot;bare&quot;&gt;https://github.com/verhas/vtstream&lt;/a&gt; and also as a dependency in Maven Central.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;literalblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;com.github.verhas&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;vtstream&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;1.0.1&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Check out the actual version number on the Maven Central site or on GitHub.
This article is based on the version 1.0.1 of the library.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;2-parallel-computing&quot;&gt;2. Parallel Computing&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Parallel computing is not a new thing.
It has been around for decades.
The first computers were executing tasks in batches, hence in a serial way, but soon the idea of time-sharing came into picture.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The first time-sharing computer system was installed in 1961 at the Massachusetts Institute of Technology (MIT).
This system, known as the Compatible Time-Sharing System (CTSS), allowed multiple users to log into a mainframe computer simultaneously, working in what appeared to be a private session.
CTSS was a groundbreaking development in computer science, laying the foundation for modern operating systems and computing environments that support multitasking and multi-user operations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This was not a parallel computing system, per se.
CTSS was designed to run on a single mainframe computer, the IBM 7094, at MIT.
It has one CPU, thus the code was executed in a serial way.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Today we have multicore processors and multiple processors in a single computer.
I edit this article on a computer that has 10 processor cores.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To execute tasks concurrently, there are two plus one approaches:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;define the algorithm in a concurrent way, for example, reactive programming, or&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;define the algorithm the good old sequential way and let some program decide on the concurrency, or&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;mix the two.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When we&amp;#8217;re programming some reactive algorithm, or defined streams as in Java 8 stream, we help the application to execute the tasks concurrently.
We define small parts and their interdependence so that the environment can decide which parts can be executed concurrently.
The actual execution is done by the framework and when we are using&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;virtual threads, or&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;threads (perhaps processes)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;the difference is in the scheduler.
Who makes the decision which processor should execute which task the next moment.
In the case of threads or processes, the executor is the operating system.
The difference between the thread and process execution is that threads belonging to the same process share the same memory space.
Processes have their own memory space.
Similarly, virtual threads belonging to the same operating system thread share the same stack.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Transitioning from processes to virtual threads, we encounter a reduction in shared resources and, consequently, overhead.
This makes virtual threads significantly less costly compared to traditional threads.
While a machine might support thousands of threads and processes, it can accommodate millions of virtual threads.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In defining a task with streams, you are essentially outlining a series of operations to be performed on multiple elements.
The decision to execute these operations concurrently rests with the framework, which may or may not choose to do so.
However, &lt;code&gt;Stream&lt;/code&gt; in Java serves as a high-level interface, offering us the flexibility to implement a version that facilitates concurrent execution of tasks.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;3-implementing-streams-in-threads&quot;&gt;3. Implementing Streams in Threads&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The library contains two primary classes located in the main directory, namely:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;ThreadedStream&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Command&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;code&gt;ThreadedStream&lt;/code&gt; is the class responsible for implementing the &lt;code&gt;Stream&lt;/code&gt; interface.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class ThreadedStream&amp;lt;T&amp;gt; implements Stream&amp;lt;T&amp;gt; {&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The &lt;code&gt;Command&lt;/code&gt; class encompasses nested classes that implement functionality for stream operations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    public static class Filter&amp;lt;T&amp;gt; extends Command&amp;lt;T, T&amp;gt; {
    public static class AnyMatch&amp;lt;T&amp;gt; extends Command&amp;lt;T, T&amp;gt; {
    public static class FindFirst&amp;lt;T&amp;gt; extends Command&amp;lt;T, T&amp;gt; {
    public static class FindAny&amp;lt;T&amp;gt; extends Command&amp;lt;T, T&amp;gt; {
    public static class NoOp&amp;lt;T&amp;gt; extends Command&amp;lt;T, T&amp;gt; {
    public static class Distinct&amp;lt;T&amp;gt; extends Command&amp;lt;T, T&amp;gt; {
    public static class Skip&amp;lt;T&amp;gt; extends Command&amp;lt;T, T&amp;gt; {
    public static class Peek&amp;lt;T&amp;gt; extends Command&amp;lt;T, T&amp;gt; {
    public static class Map&amp;lt;T, R&amp;gt; extends Command&amp;lt;T, R&amp;gt; {&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;All the mentioned operators are intermediary.
The terminal operators are implemented within the &lt;code&gt;ThreadedStream&lt;/code&gt; class, which converts the threaded stream into a regular stream before invoking the terminal operator on this stream.
An example of this approach is the implementation of the &lt;code&gt;collect&lt;/code&gt; method.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    @Override
    public &amp;lt;R&amp;gt; R collect(Supplier&amp;lt;R&amp;gt; supplier, BiConsumer&amp;lt;R, ? super T&amp;gt; accumulator, BiConsumer&amp;lt;R, R&amp;gt; combiner) {
        return toStream().collect(supplier, accumulator, combiner);
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The source of the elements is also a stream, which means that the threading functionality is layered atop the existing stream implementation.
This setup allows for the utilization of streams both as data sources and as destinations for processed data.
Threading occurs in the interim, facilitating the parallel execution of intermediary commands.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Therefore, the core of the implementation—and its most intriguing aspect—lies in the construction of the structure and its subsequent execution.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We will first examine the structure of the stream data and then explore how the class executes operations utilizing virtual threads.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;3-1-stream-data-structure&quot;&gt;3.1. Stream Data Structure&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The &lt;code&gt;ThreadedStream&lt;/code&gt; class maintains its data through the following member variables:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    private final Command&amp;lt;Object, T&amp;gt; command;
    private final ThreadedStream&amp;lt;?&amp;gt; downstream;
    private final Stream&amp;lt;?&amp;gt; source;
    private long limit = -1;
    private boolean chained = false;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;command&lt;/code&gt; represents the &lt;code&gt;Command&lt;/code&gt; object to be executed on the data.
It might be a no-operation (NoOp) command or &lt;code&gt;null&lt;/code&gt; if there is no specific command to execute.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;downstream&lt;/code&gt; variable points to the preceding &lt;code&gt;ThreadedStream&lt;/code&gt; in the processing chain.
A &lt;code&gt;ThreadedStream&lt;/code&gt; retrieves data either from the immediate &lt;code&gt;downstream&lt;/code&gt; stream, if available, or directly from the &lt;code&gt;source&lt;/code&gt; if it&amp;#8217;s the initial in the chain.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;source&lt;/code&gt; is the initial data stream.
It remains defined even when a &lt;code&gt;downstream&lt;/code&gt; is specified, in which scenario the &lt;code&gt;source&lt;/code&gt; for both streams remains identical.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;limit&lt;/code&gt; specifies the maximum number of elements this stream is configured to process.
Implementing a limit requires a workaround, as stream element processing starts immediately rather than being &quot;pulled&quot; by the terminal operation.
Consequently, infinite streams cannot feed into a &lt;code&gt;ThreadedStream&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;chained&lt;/code&gt; is a boolean flag indicating whether the stream is part of a processing chain.
When &lt;code&gt;true&lt;/code&gt;, it signifies that there is a subsequent stream dependent on this one&amp;#8217;s output, preventing execution in cases of processing forks.
This mechanism mirrors the approach found in JVM&amp;#8217;s standard stream implementations.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;3-2-stream-build&quot;&gt;3.2. Stream Build&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The stream data structure is constructed dynamically as intermediary operations are chained together.
The initiation of this process begins with the creation of a starting element, achieved by invoking the static method &lt;code&gt;threaded&lt;/code&gt; on the &lt;code&gt;ThreadedStream&lt;/code&gt; class.
An exemplary line from the unit tests illustrates this initiation:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        final var k = ThreadedStream.threaded(Stream.of(1, 2, 3));&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This line demonstrates the creation of a &lt;code&gt;ThreadedStream&lt;/code&gt; instance named &lt;code&gt;k&lt;/code&gt;, initialized with a source stream consisting of the elements 1, 2, and 3.
The &lt;code&gt;threaded&lt;/code&gt; method serves as the entry point for transforming a regular stream into a &lt;code&gt;ThreadedStream&lt;/code&gt;, setting the stage for further operations that can leverage virtual threads for concurrent execution.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When an intermediary operation is appended, it results in the creation of a new &lt;code&gt;ThreadedStream&lt;/code&gt; instance.
This new instance designates the preceding &lt;code&gt;ThreadedStream&lt;/code&gt; as its &lt;code&gt;downstream&lt;/code&gt;.
Moreover, the source stream for this newly formed &lt;code&gt;ThreadedStream&lt;/code&gt; remains identical to the source stream of its predecessor.
This design ensures a seamless flow of data through the chain of operations, facilitating efficient processing in a concurrent environment.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For example, when we call&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        final var t = k.map(x -&amp;gt; x * 2);&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;the &lt;code&gt;map&lt;/code&gt; method is called, which is&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    public &amp;lt;R&amp;gt; ThreadedStream&amp;lt;R&amp;gt; map(Function&amp;lt;? super T, ? extends R&amp;gt; mapper) {
        return new ThreadedStream&amp;lt;&amp;gt;(new Command.Map&amp;lt;&amp;gt;(mapper), this);
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It generates a new &lt;code&gt;ThreadedStream&lt;/code&gt; object wherein the preceding &lt;code&gt;ThreadedStream&lt;/code&gt; acts as the &lt;code&gt;downstream&lt;/code&gt;.
Additionally, the &lt;code&gt;command&lt;/code&gt; field is populated with a new instance of the &lt;code&gt;Command&lt;/code&gt; class, configured with the specified mapper function.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This process effectively constructs a linked list composed of &lt;code&gt;ThreadedStream&lt;/code&gt; objects.
This linked structure comes into play during the execution phase, triggered by invoking one of the terminal operations on the stream.
This method ensures that each &lt;code&gt;ThreadedStream&lt;/code&gt; in the sequence can process data in a manner that supports concurrent execution, leveraging the capabilities of virtual threads for efficient data processing.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It&amp;#8217;s crucial to understand that the &lt;code&gt;ThreadedStream&lt;/code&gt; class refrains from performing any operations on the data until a terminal operation is called.
Once execution commences, it proceeds concurrently.
To facilitate independent execution of these operations, &lt;code&gt;ThreadedStream&lt;/code&gt; instances are designed to be immutable.
They are instantiated during the setup phase and undergo a single mutation when they are linked together.
During execution, these instances serve as a read-only data structure, guiding the flow of operation execution.
This immutability ensures thread safety and consistency throughout concurrent processing, allowing for efficient and reliable stream handling.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;3-3-stream-execution&quot;&gt;3.3. Stream Execution&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The commencement of stream execution is triggered by invoking a terminal operation.
These terminal operations are executed by first transforming the threaded stream back into a conventional stream, upon which the terminal operation is then performed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The &lt;code&gt;collect&lt;/code&gt; method serves as a prime example of this process, as previously mentioned.
This method is emblematic of how terminal operations are seamlessly integrated within the &lt;code&gt;ThreadedStream&lt;/code&gt; framework, bridging the gap between concurrent execution facilitated by virtual threads and the conventional stream processing model of Java.
By converting the &lt;code&gt;ThreadedStream&lt;/code&gt; into a standard &lt;code&gt;Stream&lt;/code&gt;, it leverages the rich ecosystem of terminal operations already available in Java, ensuring compatibility and extending functionality with minimal overhead.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    @Override
    public &amp;lt;R&amp;gt; R collect(Supplier&amp;lt;R&amp;gt; supplier, BiConsumer&amp;lt;R, ? super T&amp;gt; accumulator, BiConsumer&amp;lt;R, R&amp;gt; combiner) {
        return toStream().collect(supplier, accumulator, combiner);
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The &lt;code&gt;toStream()&lt;/code&gt; method represents the core functionality of the library, marking the commencement of stream execution by initiating a new virtual thread for each element in the source stream.
This method differentiates between ordered and unordered execution through two distinct implementations:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;toUnorderedStream()&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;toOrderedStream()&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The choice between these methods is determined by the &lt;code&gt;isParallel()&lt;/code&gt; status of the source stream.
It&amp;#8217;s worth noting that executing an ordered stream in parallel can be advantageous.
Although the results may be produced out of order, parallel processing accelerates the operation.
Ultimately, care must be taken to collect the results in a sequential manner, despite the unordered processing potentially yielding higher efficiency by allowing elements to be passed to the resulting stream as soon as they become available, eliminating the need to wait for the preceding elements.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The implementation of &lt;code&gt;toStream()&lt;/code&gt; is designed to minimize an unnecessary collection of elements.
Elements are forwarded to the resulting stream immediately upon readiness in the case of unordered streams, and in sequence upon the readiness and previous element&amp;#8217;s forwarding in ordered streams.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In subsequent sections, we delve into the specifics of these two execution methodologies.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;3-4-unordered-stream-execution&quot;&gt;3.4. Unordered Stream Execution&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Unordered execution promptly forwards results as they become prepared.
This approach employs a concurrent list for result storage, facilitating simultaneous result deposition by threads and retrieval by the target stream, preventing excessive list growth.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The iteration over the source stream initiates the creation of a new virtual thread for each element.
When a limit is imposed, it&amp;#8217;s applied directly on the source stream, diverging from traditional stream implementations where &lt;code&gt;limit&lt;/code&gt; acts as a genuine intermediary operation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The implementation of the unordered stream execution is as follows:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    private Stream&amp;lt;T&amp;gt; toUnorderedStream() {
        final var result = Collections.synchronizedList(new LinkedList&amp;lt;Command.Result&amp;lt;T&amp;gt;&amp;gt;());
        final AtomicInteger n = new AtomicInteger(0);
        final Stream&amp;lt;?&amp;gt; limitedSource = limit &amp;gt;= 0 ? source.limit(limit) : source;
        limitedSource.forEach(
                t -&amp;gt; {
                    Thread.startVirtualThread(() -&amp;gt; result.add(calculate(t)));
                    n.incrementAndGet();
                });
        return IntStream.range(0, n.get())
                .mapToObj(i -&amp;gt; {
                    while (result.isEmpty()) {
                        Thread.yield();
                    }
                    return result.removeFirst();
                })
                .filter(f -&amp;gt; !f.isDeleted())
                .peek(r -&amp;gt; {
                    if (r.exception() != null) {
                        throw new ThreadExecutionException(r.exception());
                    }
                })
                .map(Command.Result::result);
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The counter &lt;code&gt;n&lt;/code&gt; is utilized to tally the number of threads initiated.
The resulting stream is constructed using this counter by mapping the numbers 0 to &lt;code&gt;n&lt;/code&gt;-1 to the elements of the concurrent list as they become ready.
If the list lacks elements at any point, the process pauses, awaiting the availability of the next element.
This waiting mechanism is implemented within a loop that incorporates a &lt;code&gt;yield&lt;/code&gt; call to prevent unnecessary CPU consumption by halting the loop&amp;#8217;s execution until it&amp;#8217;s necessary to proceed.
This efficient use of resources ensures that the system remains responsive and minimizes the potential for performance degradation during the execution of parallel tasks.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;3-5-ordered-stream-execution&quot;&gt;3.5. Ordered Stream Execution&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ordered stream execution introduces a more nuanced approach compared to its unordered counterpart.
It incorporates a local class named &lt;code&gt;Task&lt;/code&gt;, designed specifically to await the readiness of a particular thread.
Similar to the unordered execution, a concurrent list is utilized, but with a key distinction: the elements of this list are the tasks themselves, rather than the results.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This list is populated by the code responsible for thread creation, rather than by the threads themselves.
The presence of a fully populated list eliminates the need for a separate counter to track thread initiation.
Consequently, the process transitions to sequentially waiting on each thread as dictated by their order in the list, thereby ensuring that each thread&amp;#8217;s output is relayed to the target stream in a sequential manner.
This method meticulously maintains the ordered integrity of the stream&amp;#8217;s elements, despite the concurrent nature of their processing, by aligning the execution flow with the sequence of the original stream.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    private Stream&amp;lt;T&amp;gt; toOrderedStream() {
        class Task {
            Thread workerThread;
            volatile Command.Result&amp;lt;T&amp;gt; result;

            /**
             * Wait for the thread calculating the result of the task to be finished. This method is blocking.
             * @param task the task to wait for
             */
            static void waitForResult(Task task) {
                try {
                    task.workerThread.join();
                } catch (InterruptedException e) {
                    task.result = deleted();
                }
            }
        }
        final var tasks = Collections.synchronizedList(new LinkedList&amp;lt;Task&amp;gt;());

        final Stream&amp;lt;?&amp;gt; limitedSource = limit &amp;gt;= 0 ? source.limit(limit) : source;
        limitedSource.forEach(
                sourceItem -&amp;gt; {
                    Task task = new Task();
                    tasks.add(task);
                    task.workerThread = Thread.startVirtualThread(() -&amp;gt; task.result = calculate(sourceItem));
                }
        );

        return tasks.stream()
                .peek(Task::waitForResult)
                .map(f -&amp;gt; f.result)
                .peek(r -&amp;gt; {
                            if (r.exception() != null) {
                                throw new ThreadExecutionException(r.exception());
                            }
                        }
                )
                .filter(r -&amp;gt; !r.isDeleted()).map(Command.Result::result);
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;4-summary-and-takeaway&quot;&gt;4. Summary and Takeaway&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Having explored an implementation that facilitates the parallel execution of stream operations, it&amp;#8217;s noteworthy that this library is open source, offering you the flexibility to either utilize it as is or reference its design and implementation to craft your own version.
The detailed exposition provided here aims to shed light on both the conceptual underpinnings and practical aspects of the library&amp;#8217;s construction.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;However, it&amp;#8217;s important to acknowledge that the library has not undergone extensive testing.
It received a review from Istvan Kovacs, a figure with considerable expertise in concurrent programming.
Despite this, his review does not serve as an absolute assurance of the library&amp;#8217;s reliability and absence of bugs.
Consequently, should you decide to integrate this library into your projects, it&amp;#8217;s advised to proceed with caution and conduct thorough testing to ensure it meets your requirements and standards.
The library is provided &quot;as is,&quot; with the understanding that users adopt it at their own risk, underpinning the importance of due diligence in its deployment.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">1. Introduction</summary></entry><entry><title type="html">Cloud Solutions are Expensive, or are they?</title><link href="https://javax0.github.io/2023/11/12/cloud-price.html" rel="alternate" type="text/html" title="Cloud Solutions are Expensive, or are they?" /><published>2023-11-12T00:00:00+01:00</published><updated>2023-11-12T00:00:00+01:00</updated><id>https://javax0.github.io/2023/11/12/cloud-price</id><content type="html" xml:base="https://javax0.github.io/2023/11/12/cloud-price.html">&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Cloud solutions are becoming increasingly prevalent.
I&amp;#8217;ve observed their adoption even among companies that were traditionally very conservative.
Previously, these organizations insisted that no data leave their premises, operating all applications within data centers safeguarded by two-meter-thick, steel-reinforced concrete walls.
However, these companies are now beginning to explore and adopt cloud solutions, simultaneously becoming aware of the true costs associated with cloud computing.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this article, I will delve into the costs associated with cloud solutions.
While this is not a technical piece, a basic understanding of cloud computing might be beneficial, though I will aim to provide an overview rather than delve into technical specifics.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Additionally, those with a background in economics might find this discussion particularly insightful, as we will be exploring the costs, prices, and the underlying structures that influence them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As the author of this article, I bring a unique perspective, combining my experience as a senior software architect with my educational background, holding an MBA degree and possessing a foundational understanding of economics.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;2-the-price-of-cloud&quot;&gt;2. The price of cloud&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Companies that perceive cloud solutions as expensive have valid concerns.
Utilizing cloud services comes with a cost, and given that pricing is typically based on usage, expenses can escalate quickly.
If your company already possesses servers on-premises or hosted in a data center, maintaining these setups might be more cost-effective than transitioning to the cloud.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There are specific scenarios where the cost factor makes cloud usage less favorable.
Conversely, there are also situations where opting for a cloud solution can be highly advantageous.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Let&amp;#8217;s examine an example to illustrate this point.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;2-1-architecture-test&quot;&gt;2.1. Architecture test&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In a project we undertook, we proposed a unique solution involving a JDBC proxy for a client.
This JDBC proxy was a special application that acted like a database server.
However, instead of storing data itself, it forwarded SQL queries to multiple, different database servers.
This setup was necessary because the application required data to be inserted into different databases during a multi-year database migration.
The client requested a proof of concept, necessitating a test environment with six Linux servers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Renting these servers was not only costly but also challenging, given our location in a small country in Central Europe.
While purchasing servers was standard, acquiring them for just a few days was an unusual requirement.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Eventually, we approached a company where we knew the director and proposed a unique arrangement during a &quot;lunch&quot; meeting:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We need six servers for a few days.
I know you always ship servers to your customers.
Can we rent them for a few days?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We do not rent servers.
We sell them.
Also, our delivery line is always on pressure, as soon as the servers come in, we install them and ship them out.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do you ship them also during the weekends?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;No, of course not, our client offices are closed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;So if you have six servers that arrive on Friday, you will not ship them until Monday?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Yes.
That is correct.
To be more precise, we will ship them only on Tuesday, because we have to install them on Monday.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How about we take them for the weekend, we do the testing, and you get them back installed early Monday?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This arrangement was a win-win, but it relied heavily on our business network and negotiating skills.
Without this connection, we would have faced significant costs.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Today the solution would be much simpler and cost-effective:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You would specify the required hardware using YAML format, register with a cloud provider, start up a Kubernetes (K8s) cluster, upload the objects, and have your servers ready.
This overlooks the minor details of containers and applications, but these are relatively straightforward.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;My estimate is that the total cost for this modern setup would be around or less than $50. In contrast, the official quote we received for a weekend rental of six servers from a large company at that time was around $3,000.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This scenario clearly demonstrates the cost-effectiveness and convenience of cloud solutions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;3-the-economy-of-the-cloud&quot;&gt;3. The economy of the cloud&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There are indeed specific costs that influence the pricing of cloud solutions.
A cloud provider incurs expenses for hardware, electricity, cooling systems, network infrastructure, data center facilities, as well as salaries for personnel who install, maintain the hardware, and develop the software that operates the cloud.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The notion that &quot;all these costs are included in the price you pay for the cloud&quot; encapsulates a common perception.
This sentence between the quotes was suggested by GitHub Copilot.
This fact, the suggestion reflects what many people believe about costs.
I have encountered this mindset frequently across various social media platforms and in diverse groups.
It underscores a general misunderstanding that the fees paid depend on the underlying expenses associated with providing the services.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;quoteblock&quot;&gt;
&lt;blockquote&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The price does not come from the costs.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The pricing of products and services, including cloud solutions, is indeed influenced by costs, but it is not solely determined by them.
Costs limit the price, as we will see shortly.
The primary drivers of price are demand and supply.
Essentially, clients are willing to pay a price that they deem worthwhile for the service or product they receive.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If the price that customers are willing to pay falls below the cost of providing the service or product, suppliers typically will not offer it.
This economic principle highlights the balance that must be struck in the market: prices need to be high enough to cover costs and generate a profit for suppliers, yet remain low enough to be acceptable to consumers.
This dynamic equilibrium is a fundamental aspect of market economics and is particularly relevant in the context of cloud computing.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When you begin studying economics, you&amp;#8217;re introduced to a basic market model where price is often viewed as a function of supply and demand.
However, in practical scenarios, pricing is commonly calculated with consideration to costs.
For instance, when you have your car repaired, the bill typically itemizes the costs of parts and labor.
Yet, in economic terms, such a bill doesn&amp;#8217;t fully represent the truth.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The prices listed for parts and labor often include an &quot;uplift&quot; – a markup that covers additional expenses and profit.
This markup is a standard practice in business; it&amp;#8217;s a way of communicating and playing the game within the market.
The invoice you receive doesn&amp;#8217;t usually break down every cost component, such as office heating, electricity, or even indirect costs like a bribe paid to a security inspector.
Moreover, the profit margin, which can be seen as the cost of the money invested, is also embedded in these prices.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This practice is akin to a card game where all players understand that some level of strategy – or &quot;cheating,&quot; in this metaphor – is part of the game.
If everyone is aware of and engages in these strategies, it becomes a level playing field.
Similarly, in business, while the invoice might not explicitly list every cost or the exact profit margin, there&amp;#8217;s an understanding that these elements are inherently included in the prices charged.
This system of pricing, while not always transparent, is a fundamental aspect of how businesses operate and cover their costs while earning a profit.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When prices in a market are heavily influenced by costs, it typically indicates a highly competitive environment.
However, the fundamental economic principle of price being driven by supply and demand still holds true.
In such markets, there&amp;#8217;s often a dynamic feedback loop that affects supply.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If a particular service or product can be sold with a high profit margin, it naturally attracts more suppliers who want to capitalize on this opportunity.
This influx of suppliers increases the supply, which, over time, can lead to a decrease in prices until the profit margin aligns more closely with the cost of market entry and investment.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;However, entering a market isn&amp;#8217;t always straightforward or quick.
During the period it takes for new suppliers to establish themselves, existing suppliers may enjoy a monopolistic or oligopolistic position.
In such scenarios, these incumbent suppliers have the leverage to set prices at a level that maximizes their profits.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This is notably evident in the cloud computing industry.
In my opinion, cloud providers are in an oligopolistic situation.
The market is dominated by a few major players, and their significant presence and control allow them to influence pricing.
This oligopolistic market structure enables these providers to set prices that are not just cost-driven but also strategically aligned with maximizing their profits, considering the competitive landscape and the value they offer to their customers.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;4-is-the-price-right-for-you&quot;&gt;4. Is the price right for you?&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The crucial question regarding cloud solutions is whether the price is right for you and your organization.
The company financial situation may affect the decisions greatly.
Is the investment in cloud services worth it for your specific needs and circumstances?
If the answer is yes, then by definition, the service is not expensive for you.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When making this decision, it&amp;#8217;s important to weigh numerous factors in comparing on-premises solutions to cloud-based ones.
One key consideration is the nature of the expenditure:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Operating Expense (OPEX):&lt;/strong&gt; When you use cloud services, the costs are typically classified as operating expenses.
This means you pay for the cloud services as you use them, which can be beneficial for cash flow and can often be deducted as expenses in the fiscal year they are incurred.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Capital Expenditure (CAPEX):&lt;/strong&gt; On the other hand, investing in hardware and setting up your own data center involves capital expenditure.
This means a significant upfront investment, which is then depreciated over several years.
CAPEX can have different tax and financial implications compared to OPEX.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Your decision might also be influenced by how you want to manage your company&amp;#8217;s finances.
Are you looking to optimize your expenditures for company valuation or for tax purposes?
The financial situation of your company can greatly impact this decision.
For instance, if preserving cash is crucial, OPEX might be more attractive.
Conversely, if long-term investment and asset building are priorities, CAPEX could be the better route.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ultimately, the decision between cloud services and on-premises solutions isn&amp;#8217;t just about the technology.
It&amp;#8217;s also deeply rooted in the financial strategy and goals of your organization.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There are several other factors to consider when evaluating cloud solutions:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Flexibility:&lt;/strong&gt; Cloud solutions offer significant flexibility.
With a cloud service, you can dynamically scale your resources up or down based on demand.
In contrast, with an on-premises data center, you have to invest in hardware capable of handling peak loads, which may not always be efficient.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Operational and Personnel Cost Savings:&lt;/strong&gt; Opting for a cloud service can lead to savings in operational and personnel costs associated with running and maintaining a local setup.
These expenses are typically absorbed by the cloud service provider.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Costs vs.
Skills:&lt;/strong&gt; Paying more for a cloud service than what it would cost to set up locally isn&amp;#8217;t necessarily a reflection of your luck or skill.
It does not mean you do it better than the cloud provider.
Your price includes the additional profit margin of the cloud provider.
They probably can also do it cheaper, just do not give it to you at that price.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Resource Sharing:&lt;/strong&gt; Cloud providers utilize virtual machines and containers configured to share resources among multiple clients.
This approach is generally more cost-effective than each client maintaining their own hardware.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Expertise and Shared Costs:&lt;/strong&gt; Cloud providers employ experts to develop, maintain, and operate their software.
The cost of this expertise is distributed across all clients, making it more economical than maintaining an in-house team, even with the option of hiring less expensive developers from regions like Eastern Europe or India.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Shared Facility Costs:&lt;/strong&gt; Costs related to facility location, cooling, and physical security are shared among all clients of the cloud provider, contributing to overall cost-effectiveness.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If the cost of a cloud solution is unaffordable, and a cheaper alternative, still above the cost of the provider is available, both you and the cloud provider lose out.
It&amp;#8217;s a missed business opportunity for the provider, who chooses not to lower prices to capture this segment of the market, thereby maintaining higher profit margins from clients who can afford their services.
This situation can lead to a loss of economic welfare.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;5-can-i-get-it-cheaper&quot;&gt;5. Can I get it cheaper?&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It&amp;#8217;s important to remember that the publicly advertised price of cloud services is not always the final price you may pay.
The approach to pricing can differ significantly depending on whether you are an individual or a company.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As an individual seeking to purchase cloud services, you&amp;#8217;re likely to pay the listed price.
While you can request a discount, the response is typically a polite refusal.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;However, the situation changes if you represent a company.
Many professionals, such as consultants, senior experts, or architects, work for organizations where negotiating prices is standard practice.
If you&amp;#8217;re involved in estimating costs for a cloud project within a large company, it would be unwise to base your calculations solely on the advertised prices.
Instead, engage directly with cloud providers.
They are often willing to assist and, depending on the size and stature of your company, might offer substantial discounts.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Additionally, cloud providers have the most comprehensive understanding of their pricing structures.
It&amp;#8217;s beneficial to let them assist with the price calculations, as they can provide insights and options that you might not have considered.
This approach not only potentially reduces costs but also ensures that you&amp;#8217;re getting the most value out of your investment in their services.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;6-what-is-the-price&quot;&gt;6. What is the price?&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;After exploring how to evaluate pricing, the next step is understanding the actual cost of cloud services, which is not straightforward.
Unlike visiting a grocery store where you can simply look at price tags, the pricing structure of cloud services is composed of multiple components.
Typically, you might encounter initial setup costs, monthly fees, and various usage-based charges.
These usage fees can vary and are often categorized separately for network usage, storage, data transfer between locations, CPU usage, memory, and other resources.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The overwhelming complexity of cloud service pricing can be attributed to two main reasons.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Firstly, there&amp;#8217;s a marketing strategy at play.
Cloud providers aim to present their prices as attractively low while simultaneously maximizing their revenue.
A complex pricing structure, offering various alternatives, often leads customers to choose options that aren&amp;#8217;t the most cost-effective for their needs.
This choice is influenced by a psychological desire for security; customers tend to opt for a pricing plan that offers a perceived safety net, based on their estimation of future resource usage.
However, this estimation is often an overestimation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For example, I personally pay $100 for a GSM mobile plan that includes unlimited calls, SMS, and data, plus 40GB of roaming data, which is shared with my wife on a second device.
In the past five years, I&amp;#8217;ve only exceeded this limit twice.
Offering a range of alternatives is an effective customer engagement tool, as it caters to different needs and perceived usage patterns.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In the early 2000s, Hungarian T-Mobile offered thousands of different pricing packages.
Customers couldn&amp;#8217;t choose from all these options at any given time, but once they selected a package, they could keep it indefinitely.
During my tenure there, we conducted a project to assess the marketing value of these packages.
We randomly selected 10,000 anonymized clients and calculated the potential revenue loss if we had offered them the cheapest package that would have met their needs.
The findings indicated that such a change would result in a 30% revenue loss.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Concurrently, we surveyed 1,000 of these 10,000 clients, asking which package they would choose if they had the option to select from all available packages.
Surprisingly, the results showed that the potential revenue gain would be 30%.
This suggests that people often opt for a more expensive package because it offers a sense of security.
This tendency is also observable in the realm of cloud services, where customers frequently select higher-priced options for the perceived safety they offer.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The second reason for the complex pricing of cloud services is, on the other hand, quite rational.
The fundamental value proposition of cloud services lies in optimization.
Cloud providers continuously work on optimizing their infrastructure.
This ongoing process of optimization helps reduce their costs while still delivering the same value to their clients.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Cloud providers, while adept at optimizing their infrastructure, cannot directly optimize your application.
If you manage to reduce your application&amp;#8217;s resource consumption by 10%, they are often willing to offer a discount on a portion of your bill.
You might not receive the full extent of the cost savings they achieve, but it still creates a win-win situation.
Their revenue might decrease slightly, but their profit margin can increase.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In the current phase where cloud providers are experiencing growth and attracting more clients, they are generally open to providing discounts if your optimizations help reduce their operational costs.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Nowadays, it&amp;#8217;s typically a wise decision to analyze and optimize your cloud usage.
While there might be some exceptional cases where this isn&amp;#8217;t necessary, generally speaking, it&amp;#8217;s a beneficial practice.
Optimizing cloud usage not only can lead to direct cost savings but also ensures more efficient use of resources, which is advantageous both financially and operationally.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;7-summary-and-takeaway&quot;&gt;7. Summary and Takeaway&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The cloud is an undeniable presence in today&amp;#8217;s technology landscape.
It&amp;#8217;s important to consider cloud solutions as an alternative to your on-premises setup.
This decision shouldn&amp;#8217;t be made blindly – as is the case with most decisions.
You need to carefully evaluate the costs and benefits, taking into account your specific situation, negotiating position, potential for optimization, and other relevant factors.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;(This article was republished by &lt;a href=&quot;https://dzone.com/articles/cloud-solutions-are-expensive-or-are-they&quot;&gt;DZONE&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">1. Introduction</summary></entry><entry><title type="html">Programming with AI</title><link href="https://javax0.github.io/2023/08/28/ai-programming.html" rel="alternate" type="text/html" title="Programming with AI" /><published>2023-08-28T00:00:00+02:00</published><updated>2023-08-28T00:00:00+02:00</updated><id>https://javax0.github.io/2023/08/28/ai-programming</id><content type="html" xml:base="https://javax0.github.io/2023/08/28/ai-programming.html">&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I recently discussed how we use Co-Pilot and ChatGPT for programming with some of my senior colleagues.
We discussed our experiences, how and when it helps, and what to expect from it in the future.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this article, I will shortly write about what I imagine the future of programming with AI will be.
This is not about what AI will do in programming in the future.
I have no idea about that, and based on my mood, I either look forward amazed or in fear.
This article is more about how we, programmers, will do our work in the future.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;2-the-past&quot;&gt;2. The past&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To predict the future, we have to understand the past.
If you know only the current state, you cannot reliably extrapolate.
Extrapolation needs at least two points and knowledge about the speed of change in the future (maximum and minimum of the derivative function).
So, here we go, looking a bit at the past, focusing on the aspects that I feel are mainly important to predict how we will work in the future with AI in programming.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;2-1-machine-code&quot;&gt;2.1. Machine Code&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When computers were first introduced, we programmed them in machine code.
This sentence should read, &quot;your father/mother programmed them in machine code&quot;, for most of you.
I had the luck to program a Polish clone of the PDP-11 in machine code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To create a program, we used assembly language.
We wrote that on a piece of checkerboard paper(and then we typed it in).
No.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock note&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
As I write this article, Co-Pilot is switched on, suggesting the sentences&apos; ends.
In 10% of the cases, I accept the suggestion.
Co-Pilot suggested the part between ( and ) in the last sentence.
It&amp;#8217;s funny that even Co-Pilot cannot imagine a system where we did not have an assembler.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We wrote the assembly on the left side of the paper and the machine code on the right.
We used printed code tables to look up the machine codes, and we had to calculate the addresses.
After that, we entered the code.
This was also a cumbersome process.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There were switches on the front panel of the computer.
There were 11 switches for the address (as far as I remember) and eight switches for the data.
A switch flipped up meant a bit with a value of 1, and a switch flipped down meant a bit with a value of 0.
We set the address and the desired value, and then we had to push a button to write the value into the memory.
The memory consisted of ferrite rings that kept their value even after the power was switched off.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;2-2-assembly&quot;&gt;2.2. Assembly&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It was a relief when we got the assembler.
It was already on a different machine and a different processor.
We looked at the machine code that the assembler generated a few times, but not many times.
The mapping between the assembly and the machine code was strictly one-to-one mapping.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The next step was higher-level languages, like C.
I wrote a lot of C code as a hobby before I started my second professional career as a programmer at 40.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;2-3-close-to-the-metal&quot;&gt;2.3. Close to the Metal&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The mapping from C to machine code is not one-to-one.
There is room for optimization, and different compiler versions may create different code.
Still, the functionality of the generated code is very much guaranteed.
You do not need to look at the machine code to understand what the program does.
I can recall that I only did it a few times.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of those times, we found a bug in the Sun C compiler (1987, while I was on a summer program at TU Delft).
It was my mistake the other time, and I had to modify my C code.
The compiler knew better than I did what the C construct I wrote meant.
I do not have a recollection of the specifics.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We do not need to look at the generated code; we write on a high level and debug on a high level.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;2-4-high-level&quot;&gt;2.4. High Level&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As we advance in time, we have Java.
Java uses a two-level compilation.
It compiles the Java code to byte code, which the Java Virtual Machine, JIT technology interprets.
I looked at the generated byte code only once to learn the intricacies of the ternary operator type casting rules, and never the machine code generated.
The first case could be avoided by reading the language spec, but who reads manuals?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The same is true here: we step to higher levels of abstraction and do not need to look at the generated code.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;2-5-dsl-and-generated-code&quot;&gt;2.5. DSL and Generated Code&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Even as we advance towards higher levels, we can have Domain Specific Languages (DSLs).
DSLs are&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;interpreted,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;generate high-level code, or&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;generate byte code and machine code.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The third case is rare because generating low-level code is expensive, requires much work, and is not worth the effort.
Generating high-level code is more common.
As an example, we can take Java::Geci fluent API generator.
It reads a regular expression like the definition of the fluent API, creates a finite state machine from it, and generates the Java code containing all the interfaces and classes that implement the fluent API.
The Java compiler then compiles the generated code, and the JVM interprets the resulting byte code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Should we look at the generated code?
Usually not.
I actually did a lot because I wrote the generator, and so I had to debug it, but that is an exception.
The generated code should perform as the definition says.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;3-the-present-and-the-future&quot;&gt;3. The Present and the Future&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The next step is AI languages.
This is where we are now, and it starts now.
We use AI to write code based on some natural language description.
The code is generated, and we have to look at it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This is different from any earlier steps in the evolution of programming languages.
The reason is that the language AI interprets is not definite the same way as Java, C, or any DSL.
It can be ambiguous.
It is a human language, usually English.
Or something resembling English when non-native speakers like me write it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;3-1-syntax-free&quot;&gt;3.1. Syntax-free&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This is the advantage of AI programming.
I do not need to remember the actual syntax.
I can program in a language I rarely use and forget the exact syntax.
I vaguely remember it, but it is not in my muscle memory.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;3-2-library-free&quot;&gt;3.2. Library-free&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It can also help me with my usual programming tasks.
Something that was written by other people many times before.
It has it in its memory, and it can help me.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The conventional programming languages have it, but with a limited scope.
There are language constructs for the usual data structures and algorithms.
There are libraries for the usual tasks.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The problem is that you have to remember the one to use it.
Sometimes, writing a few lines is easier than finding the library and the function that does it.
It is the same philosophy as the Unix command line versus VMS.
(You may not know VMS. It was the OS of the VAX VMS and Alpha machines from DEC.)
If you needed to do something in VMS, there was a command for it.
In Unix, you had simpler commands, but you could combine them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With AI programming, you can write down what you want using natural language, and the AI will find the code fragments in its memory that fit the best and adapt it.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;3-3-ai-language&quot;&gt;3.3. AI Language&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Today, AI is generating and helping to write the code.
In the future, we will tell the AI what to do, and it will execute it for us.
We may not need to care about the data structure it stores the data or algorithms it applies to manage those.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Today, we think of databases when we talk about structured data.
That is because databases are the tools to support the limited functionality a computer can manage.
Before the computers, we just told the accountant to calculate the last year, whatever profit, balance sheet, whatnot, and they did.
The data was on paper, and the managers did not care how they were organized.
It was expensive because accountants are expensive.
The intelligence they applied, extracting data from the different paper-based documents, was their strong point; calculation was just a mechanical task.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Computers came, and they were strong doing the calculations.
They were weak in extracting data from the documents.
The solution was to organize the data into databases.
It needed more processing on the input, but it was still cheaper than having accountants do the calculations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With AI, computers can do calculations and extract data from documents.
If it can be done cheaply, there is no reason any more to keep the data in a structured way.
It can get structured when we need them for a calculation on the fly.
The advantage is that we can do any calculation, and we may not face the issue that the data structure is unsuitable for the calculation we need.
We just tell the AI program using natural language.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Is there a new patient coming to the practice?
Just tell the program all the data, and it will remember like an assistant with unlimited memory who never forgets.
Do you want to know when a patient last visited?
Just ask the program.
You do not need to care how the artificial simulated neurons store the information.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It certainly will use more computing power and energy than a well-tuned database, but on the other hand, it will have higher flexibility, and the development cost will be significantly lower.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This is when we will talk to the computers, which will help us universally.
I am not shy about predicting this future because it will come when I will not be around anymore.
But what should we expect in the near future?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;3-4-the-near-future&quot;&gt;3.4. The near future&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now, AI tools are interactive.
We write some comments or code, and the AI generates the code for us, which is the story&amp;#8217;s end.
From that point on, our &quot;source code&quot; is the generated code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You can feel from the previous sentence the contradiction.
It is like if we would write the code in Java once, then compile it into byte code, and then use the byte code to maintain it.
We do not do that.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Source code is what we write.
Generated code is never source code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I expect meta-programming tools for various existing languages to extend them.
You insert some meta-code (presumably into comments) into your application, and the tool will generate the code for you.
However, the generated code is generated and not the source.
You do not touch it.
If you need to maintain the application, modify the comment, and the tool will generate the code again.
It will be similar to what Java::Geci is doing.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You insert some comments into your code, and the code generator inserts the generated code into the editor-fold block following the comment.
Java::Geci currently does not have an AI-based code generator, or at least I do not know about any.
It is an open-source framework for code generators; anyone could write a code generator utilizing AI tools.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Later languages will include the possibility from the start.
These languages will be some kind of hybrid solution.
There will be some code described by human language, probably describing business logic, and some technical parts more like a conventional programming language.
It is similar to how we apply DSL today, with the difference that the DSL will be AI-processed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As time goes forward, the AI part will grow, and the conventional programming part will shrink to the point when it will disappear from the application code.
However, it will remain in the frameworks and AI tools, just like today&amp;#8217;s machine code and assembly.
Nobody codes in assembly anymore, but wait?
There are still people who do.
Those who write the code generators.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And those who will still maintain 200 years from now in the future the IBM mainframe assembly and COBOL programs.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;4-conclusion-and-takeaway&quot;&gt;4. Conclusion and Takeaway&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I usually write a conclusion and a takeaway at the end of the article.
So I do it now.
That is all, folks.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">1. Introduction</summary></entry><entry><title type="html">Virtual and Augmented Reality is Here</title><link href="https://javax0.github.io/2023/08/27/vr-future.html" rel="alternate" type="text/html" title="Virtual and Augmented Reality is Here" /><published>2023-08-27T00:00:00+02:00</published><updated>2023-08-27T00:00:00+02:00</updated><id>https://javax0.github.io/2023/08/27/vr-future</id><content type="html" xml:base="https://javax0.github.io/2023/08/27/vr-future.html">&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Virtual reality is a technology when you wear some device projecting a non-existent world into your senses.
This way, you partially or completely lose the connection to the real world and are immersed in the virtual world.
Current technology does not allow a complete loss of connection to the real world, and the senses are mainly limited to vision and hearing.
Usually, two LCD devices with special optics are mounted on your head, and different sensors track your head movement.
The computers display pictures on the LCDs that change as you move your head, showing a static or dynamic virtual reality around you.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this article, I will write about the history of virtual reality and how I got my fingers wet.
I will also write about what I experienced recently with my newly bought Meta Quest Pro and how I see the future of virtual reality.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;2-history&quot;&gt;2. History&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The first virtual reality device was the first loudspeaker headset limited to audio senses, but the term was not used for that.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The first virtual reality device, called virtual reality, was the Sensorama, built by Morton Heilig in 1962.
I had a set on my head in 1995 at an exhibition IFABO in Budapest.
I worked for Digital Equipment Corporation then, and we had a stand there.
My task was to show the visitors the virtual reality headset that DEC created in cooperation with Kubota.
If you Google the term &lt;em&gt;&quot;Kubota Denali VR&quot;&lt;/em&gt; you may find interesting traces of history.
I had little time to try and play with it, but I was impressed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I was convinced that VR is the future and will be here as soon as 2000 in five years.
I remember this because I was young and &quot;brave&quot; enough to express this prediction publicly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;2-1-derail-prediction-and-braveness&quot;&gt;2.1. Derail: Prediction and Braveness&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When you are an expert, you can predict the future with a certain precision.
You are a visionary if you tell others how you see the future and are correct.
If you are wrong, then you are a fool.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When you are young and at an early stage of your Dunnig-Kruger curve, you are brave enough to express your predictions.
So, I was brave enough to say that VR will be here in five years.
I stated it in a forum not smaller than the main central state-running radio stating Kossuth Radio in Hungary.
Nobody remembered it after five years, so it was not a big shame, but in 2015, twenty years later, the same guy invited me again to the radio to review my predictions.
It was interesting.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I had some good predictions, like saying that mobile phones will be ubiquitous and be a personal computing device connected to the internet.
But my VR prediction was off the rails.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Why is it important to mention this other than it gives you credibility when you admit your past mistakes in an article?
Now I see what I did not see then and why VR did not sweep the board.
In this article, I will repeat the mistake I made almost thirty years ago and predict VR&amp;#8217;s future again.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Why am I so &lt;em&gt;&quot;brave&quot;&lt;/em&gt; to do that?
Because I am old enough to be brave again.
Young people are brave enough to predict the future because they do not understand that their predictions may bite back.
Old people know that when the prediction bites back, they will not be there to be bitten.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sidebarblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Never trust the prediction of a young or an old expert.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;3-current-experiences&quot;&gt;3. Current Experiences&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I bought my first VR headset in 2017.
It was a Sony Playstation VR.
It was a birthday present from me.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;At that time, I saw the state of VR as mainly a plaything.
Gaming and entertainment.
I had some play with Fruit Ninja and Beat Saber.
I tried some other games but got dizzy very soon, and I realized why I was wrong in 1995.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The technology for the VR headset was not good enough.
It lacked resolution, was too expensive, and needed improvement in tracking the head movement and lag of screen refresh.
Lag is very important.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When, for example, you tilt your head and the world you see tilts with your head for a moment and then gets back to its state to make the horizon horizontal again, you get dizzy.
The lag is the time between your head&amp;#8217;s movement and the picture on the screen.
The lag does not need to be large enough to be consciously recognizable, and it may still make you dizzy.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When the virtual world is dynamic, like car racing, your balance organ, the vestibular system, gets confused.
You see the car and the world around you running, but you are stationary.
That is what makes you really vomit.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Parts of these problems can be solved, others not.
In 1995, even in a static environment, I got easily dizzy.
Today, it is much better, and (jumping a bit ahead) I can spend hours working in VR, watching virtual screens in a virtual café.
As a matter of fact, I write this article with a Meta Quest Pro on my head, and I am sitting in a virtual café in Immersed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I knew this was not my last VR set, and I will have a next one suitable for work.
I was following the news about the vast investments of Meta and Facebook into VR.
However, I was waiting for Apple to come up with the next generation of VR.
I use a lot of Apple products.
They have superb usability and a hefty price tag.
On the other hand, if a senior engineer living in Switzerland who has paid off (never had) all the mortgages raised cannot afford the overpriced products, then who can?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When the Apple Vision Pro was introduced with the price tag of 3.5k USD, I realized I would not wait for Apple.
I could, but I do not want to pay that amount for something 1.0 and experimental.
I could also read between the marketing videos&apos; lines to know that this headset may be better than the competition, but it is still experimental.
It is not Apple&amp;#8217;s fault.
Although I expected a working version, I can see that this expectation was unrealistic.
It is not Apple Vision Pro that is experimental; it is the whole VR field, even after 30 years.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The reason, as I see now after experimenting with the Meta Quest Pro, is not technology.
Technology has developed enough during the last three decades so that companies can produce VR with good enough LCD, tracking, and optics.
It is the software that is immature, and it is in a unique way.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When you think about immature software, you usually think of software that has bugs.
Although the Meta Quest Pro certainly has bugs, that is not why I say it is immature.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Currently, there is no best practice on how we can and will use VR for work.
To develop that knowledge will need much work.
It includes those early experimenters willing to invest their time and effort in working with this immature technology.
It also needs a lot of money from companies like Facebook to develop the software.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Many software developed today will be thrown away in a few years.
Not because they are buggy or low quality but because they implement unusable use-case scenarios.
Nobody knows what is usable.
Do we want to navigate in a three-dimensional space with boxes and spheres representing different files?
Should we represent directories as boxes and zoom into them to see the files, or will they be lined up behind them?
Should we imitate the kinematics of natural objects in a gravitational field like in our everyday earthly environment?
Should we float in space without specific directions when we move between some abstract objects representing files, folders, programming elements, and relationships between these objects?
We will try; some people will like the first, some will be best fitting with the second, and others will prefer something developed we cannot even imagine today.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When I ordered my Meta Quest Pro, I was unsure what I would use it for.
I did not expect it to be ready for work.
I was hoping, but I realized that it may not be.
I imagined different use cases.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Work in a virtual environment with virtual screens, using Immersed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Play games.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Play some games, which are a workout.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;4-meta-quest-pro-first-steps&quot;&gt;4. Meta Quest Pro First Steps&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I had mixed feelings when I got the Meta Quest Pro.
First of all, I had to wait a month till it arrived.
While waiting, I watched many YouTube videos about the device and the programs, so I was hiked.
Clearly, it was a mistake.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;After I started, it froze, and I had to restart it.
But it did not happen ever again.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I had to install an app on my iPad/iPhone to use the headset.
It is okay, but I had to Google it because the QR code on the printed users&apos; manual led to a 404 page.
I deserve a seamless start for a 1000$.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It does not have a good tutorial.
It has a tutorial, but it is like someone had to write one to tick it off from the to-do list rather than one written for the user.
The usability and the guidance of Apple products spoiled me.
For example, there is a mirror in the virtual environment, which shows your avatar.
I did not get any information from the tutorial or documentation that it has a use.
I saw my avatar&amp;#8217;s reflection, but nobody told me that I could customize my avatar if I clicked there with the virtual laser beam.
Later, I also found the menu system to set up the avatar.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;After five hours of use, I still could not figure out the different uses of the buttons.
After a few weeks, I know why: there is no convention.
Different applications use the different buttons differently.
There are X  and Y and A  and B buttons, but they have no unified meaning or use.
The only more or less fixed convention is that the shooting button for your index finger is shooting, and the trigger button for your thumb is grabbing.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I had some early bad experiences with the power and speaker loudness buttons.
As I was moving the headset on and off a few times, I accidentally pressed these buttons.
I had to learn muscle memory to grab the headset, a different way from what I first felt natural.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The hand-tracking feature is amazing but not usable.
It is amazing because it works, but I had to switch it off when working in a virtual environment.
When I type, the controllers are not in my hand.
The headset recognizes this, and all my typing movements it tries to interpret as hand gestures.
Bizarre results.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The screen resolution for the virtual screens is usable, but they cannot compete with my two displays, 5k each setup.
I can see the pixels and the difference between the virtual and the actual screens.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The keyboard use is also a pain point.
There are two ways to use the keyboard.
One is a so-called portal.
It is a shape fixed in the virtual space that shows the real world behind the shape.
It is like a window to the real world from the virtual world.
You can open a portal for the keyboard and see your keyboard blurry.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The problem probably comes from the fact that the cameras were designed for tracking, not showing the real world.
I can see my keyboard but must adjust the light, and the picture waves slightly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The other possibility is to use a so-called tracked keyboard.
In this case, the software identifies the keyboard by its shape and draws a virtual keyboard where the actual keyboard is.
At the same time, it draws your hands in real-time, so you see your hands and keys in a virtual environment.
It works as a labor experiment.
Only a few keyboards are supported: some Logitech models, Apple Magic keyboards, and Macbook Pro and Air keyboards.
Luckily, I have a magic keyboard, but I use a Windows native Hungarian keyboard layout.
Virtual keyboards support only US layout.
Not even Y and Z swapped for many European keyboards.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You must have a high-speed connection between the PC/MacBook and the headset to use virtual displays.
To have that, I configured my MacBook to use my iPhone interned via a tethered connection.
The Wi-Fi uses the 5GHz band and provides a dedicated hotspot for the headset.
With this setup, the lag between the computer and the headset is 6m; that should be enough.
Because I still could feel a little lag in the mouse movement, I ordered a USB-C to USB-C Oculus cable.
I feel ashamed to admit how much I paid for it, but it moved the latency to 2ms.
The mouse is still lagging.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I also had to switch to dark mode with IntelliJ for better visibility on the virtual screens.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Watching movies is impressive.
And I did not mean the &lt;a href=&quot;https://www.youtube.com/watch?v=h8srG_iKh5Y&quot;&gt;special movies&lt;/a&gt;.
Just a good old boring Netflix, Disney, Amazon, etc. movies.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;5-apps-i-used&quot;&gt;5. Apps I Used&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I tried a few applications, and other than a few games I already used before, I categorize each application as experimental.
The most mature application is Immersed.
There are a lot of problems with it, but I use it every day for a few hours.
It proves it is usable, but to be honest, I am not absolutely sure if I use it because&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I really like it despite the drawbacks or&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I have buyer&amp;#8217;s remorse and must convince myself that I did not waste my money.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;What I have experienced, though, is that meeting people in a virtual environment is much more natural than I expected.
When I do a video conference, I see the faces of the people I talk to.
When I do a virtual meeting, I can only see the avatars.
I expected it to be less natural, but somehow, it felt more in the present.
You are visually in the same space as the other people&amp;#8217;s avatars; you talk to them, and your hands are tracked and shown, as well as your facial expression.
I also experienced that we needed less &quot;who talks when&quot; protocol than in a video conference.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I also tried a mind-mapping application called Noda.
I do not use mind mapping often, but I wanted to see how it works.
I was surprised.
Using spatial representation of the mind map is much more natural than the flat one.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I also tried some 3D drawing, and I am still behind my plans with CAD for 3D printing.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;6-future-apps&quot;&gt;6. Future Apps&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And this is the chapter where I will make a fool of myself.
Let&amp;#8217;s hope that I live long enough to see it.
I will not give exact year numbers when something will come.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There will be a lot of technical development in the next few years, but that is something out of my experience.
I expect many steps forward regarding the software, applications, and development.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Right now, we have different applications that present virtual worlds and something in it.
Immersed does two things: 1. provides a space where people and their avatars are visible and can interact, and 2. provides virtual screens.
Noda, the mind mapping application, also provides 1. a virtual space and 2. a virtual mind map.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It is somehow analogous to the MS-DOS times when you could run only one application on the screen simultaneously.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I expect the virtual space to become the desktop.
It has to be provided by the operating system, and the different applications will be able to use it, placing and moving different virtual objects in it.
I have not read articles that envision this model, but I am sure this is how VR architects at big companies envision the future.
What do we miss there?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We miss the copy/paste and the drag-and-drop functionality.
I do not mean literally.
I do not think we should have a virtual clipboard and drag-and-drop virtual objects.
But we need a way to use different applications in the same virtual space and make them interact.
What we miss is the act, which is the most natural way of interaction between applications like drag and drop and copy/paste on the desktop.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With that, I am sure we will soon forget the desktop and the windows and virtual windows.
Tethering a MacBook to a headset is like tethering a horse to a railway car.
It was needed briefly to provide the continuity of cultural development, but we will forget it.
We will have a VR version of programming IDEs; we will have 3D CAD, mind mapping, 3D UML diagrams, ORM representation, and so on.
These will run on the headset, and we will not need to embed the 2D desktop into our 3D virtual world.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;7-conclusion&quot;&gt;7. Conclusion&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This article is not about software development, but since most of my articles are about that, I expect that most of my readers are.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;What should you do as a developer?
What is the message?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;First of all, you must not ignore VR technology anymore.
The headsets become better and cheaper, and the software will develop.
Immerse, for one, can be a good excuse to buy a headset if you need an excuse.
You should get acquainted with the technology, what is available, and what can be developed.
Expect new operating system features supporting VR and new APIs and tools.
There will be many opportunities in the coming years around this technology.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">1. Introduction</summary></entry></feed>