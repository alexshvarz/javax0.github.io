<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="https://javax0.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://javax0.github.io/" rel="alternate" type="text/html" /><updated>2022-12-12T17:45:08+01:00</updated><id>https://javax0.github.io/feed.xml</id><title type="html">Java Deep, mostly Java</title><subtitle>javax0 is a technical Java oriented blog. Whenever I find something interesting, in the mood and feel the power to publish it, you will get it here. Publications are usually released on Wednesday 15:00am GMT. Earlier posts of the blog were published on Javax0 Wordpress Site at https://javax0.wordpress.com</subtitle><entry><title type="html">Technology behind this post</title><link href="https://javax0.github.io/2022/12/07/blog-posting.html" rel="alternate" type="text/html" title="Technology behind this post" /><published>2022-12-07T00:00:00+01:00</published><updated>2022-12-07T00:00:00+01:00</updated><id>https://javax0.github.io/2022/12/07/blog-posting</id><content type="html" xml:base="https://javax0.github.io/2022/12/07/blog-posting.html">== 1. Introduction

This blog is the continuation of the blog post at the WordPress-hosted javax0 blog that was at https://javax0.wordpress.com[javax0.wordpress.com].
The technology, the hosting, and all were okay by that time, but times changed.
This blog post describes why I changed the blog technology and what technology I use here to write these blog posts.

== 2. Problems with WordPress

First, I have to state that I am not saying or implying that WordPress would not be an excellent platform.
It is a well-established and a kind of one of its kind, de-facto number-one blogging forum.
The problems are specific to my particular needs for this blog.
These needs may not be specific to my person, but a bit more general: technical blogging.

It is like Opel, Toyota, VW, or any other average, workhorse car type.
Opel is a good car; it runs, is reliable, and is reasonably priced.
However, if I am a farmer and need to plow my fields, I will probably choose a tractor instead.
In this analogy, the farmer is a __technical__ blogger.
Emphasis is on __technical__.
For anybody else: WordPress is an excellent choice.

Let&apos;s have a look at the issues that I had.

=== 2.1. Markup

When I write anything, I like to edit some markup.
I can use Word or LibreOffice.
I was using DEC Write in the early 1990-is if you are old enough to know what that is but not too old to forget things and still remember.
Even at that time, I preferred markups, which at that time were TeX and LaTeX.

[NOTE]
====
I even wrote a hyphenation preprocessor for Tex for the Hungarian language, and it became a standard part of some Linux distributions.
Since they installed Linux on  Mars Rovers, sometimes I entertain myself with the idea that some of my code got as far as planet Mars.
Please let me have this fantasy, and do not correct me if I am wrong.
====

We could use other markups, like APT, Markdown, Asciidoc, and many others over the years.
These days two of those are used mainly, Markdown and Asciidoc.
WordPress hosted site supported or still supports Markdown, but I started to prefer Asciidoc for these blogs.
The only problem was that I could not.

=== 2.2. Code Samples

When I write some technical blogs, I include code samples.
I develop the code first, and then I write the article.
That is the principle.

However, the practice is that after I started to write the article, I realized that the code was not perfect.
So I changed the code and copied the relevant part to the article sample displays.
Unless I forget to update some of those after a few iterations.

It was also the case when I wrote my first book, and I have sworn that it will never happen again.

=== 2.3. Version Control

Editing on WordPress works, and you can look at the different versions.
But it is not comparable with the possibilities provided by a Git repository.

== 3. The New Blog Technology

=== 3.1. Github Pages and Jekyll

The new technology stack for blogging is based on GitHub pages.
It is not unique, and it has support for Jekyll, which is a static blogging engine.
Setting up a Jekyll-based blog is pretty straightforward.
I already had the organization name `javax0` on GitHub.
It only seemed logical to use this as `javax0.github.io` for blogging.
Later I may use the `javax0.com` domain that I also keep.

Installing Jekyll on my MacBook was a bit tricky.
First, I had to install the newest Ruby.
An old version of Ruby comes preinstalled on every macOS.
This old version is not suitable for running Jekyll.
I used brew, but it failed, complaining that I was not on the sudoer list.
It took a while until I realized that, for some reason, two `sudo` programs were installed on my machine.
The brew installer used a different one than what I reached from the command line.
I had to add myself to the other sudoer&apos;s list as well.
The last trick was to tweak the `PATH` so Jekyll would use the newest Ruby version.
After that, there was still some problem when I configured Jekyll to run locally and on GitHub.
It was executing some commands following some StackOverflow page suggestions.

Sometimes I had no idea what I was doing.
I can only hope that I did not install malware during the process.
You, AsciiDoc, Jekyll, and other tool developers have all my trust.

I integrated JRuby into Jamal, but I do not program in Ruby.

=== 3.2. Jekyll Asciidoc Plugin

In addition to Jekyll, I also installed the Asciidoc plugin for Jekyll.
Since both Asciidoctor and Jekyll are written in Ruby, it was nothing more than issuing a few commands.

=== 3.3. Jamal

The extra part, which is not a standard Asciidoc-boosted Jekyll installation, is my use of Jamal.
The main reason to use Jamal is to include the code samples in the blog posts, but it does much more than that.

I wrote above that I struggled with maintaining the code samples when writing my books.
I created the pyama tool in Python for the second book I wrote.
It copies the code snippets into the text file that I edited.
Later I developed the snippet module for Jamal, which revolves around this concept.
Keep the source in the code files, have only a reference in the document, and copy it in the CI/CD process.
I hesitated to use Jamal and the snipped module myself for a long time.
It is easier to edit a file showing some code when the code is there a few lines above.
Pyama was copying the code into the edited file.
Jamal does not do that.
Jamal can also do that, but I do not recommend using that feature.
A source file is a source file.

When I created the Asciidoctor Jamal plugin that can plug Jamal functionality into Asciidoctor and delivers Jamal WYSIWYG editing in IntelliJ, the situation changed drastically.
There was no reason more to use something like pyama.

NOTE: Pyama is still available in my GitHub, but there are much better tools for the purpose.

Using Jamal, I can include code snippets and delete or keep some lines by selecting regular expressions or line numbers.
I can number the lines, and I can still use all the Asciidoctor formatting features at the same time.

=== 3.4. Installing Jamal

Installing Jamal to use in IntelliJ is very simple.
All it takes to download a ZIP file and extract the content into the projects `.asciidoctor/lib` directory.
You should open IntelliJ settings and associate the `.jam` extension with the Asciidoctor plugin (in addition to the other default extensions already there).
Restart IntelliJ, and you can start editing your first Jamal-enabled Asciidoc file.

As you edit the file on the left pane, you see the formatted text on the right pane.
It is how the plugin works, but you can also use Jamal macros now.

image::https://javax0.github.io/assets/images/image-2022-12-09-16-47-43-394.png[width=500]

=== 3.5. Blogging Macros

There are not too many specific macros that differ from other documentation macros.
Most of the macros I use in Jamal are snippet macros and built-in core ones.
Some macros help scan the snippets following the directory naming conventions of the site.
There are some macros to reference one article from another easily.

=== 3.6. Deploying the Site

Deployment of the site is simply a git push.
Almost.
The site has to be built before.
There is a simple build script:


[source,bash]
----
#!/bin/sh
./build
git add --all docs
git commit -m &quot;deploy&quot;
git push
open https://javax0.github.ioq
----

This script builds the site, adds all the new and modified generated files, and then pushes it to the git server.
It also opens the web page, so I can immediately see the blog&apos;s opening page after it is deployed.

I tried to let GitHub pages do the building of the Jekyll site.
After all, it supports Jekyll.
The problem is that GitHub does not support the Jekyll Asciidoc plugin.
It is a bit strange: Asciidoc is natively supported by GitHub, and any readme or other files can be Asciidoc.
Still, GitHub Sites cannot be, except if they are built and deployed elsewhere.

== 4. What will be Missing

WordPress very neatly showed the statistics of the site.
I do not know if I can get such statistics here.
Probably not.

On the other hand, most of the readers for my articles came from the republishing sites DZone and Java Code Geeks.
I will keep them.
(Note to myself: I have to inform them about the blog&apos;s new location officially.)
They automatically fetch the blog posts.
So I do not need to do anything.
They select from the published articles.
They only repost the good ones.

If you know any other aggregator I should contact, give me some advice. I am open.

== 5. Summary

I hope blogging using this toolset will be much more fun than the old technology.
At least, I am less likely to end up in some articles with `&amp;amp;lt;` and `&amp;amp;gt;` infested source codes.
(I had to apply a unique trick to get them here.)

This type of blogging using Asciidoc, Jekyll, and Jamal is more a Doc as a Code that I advocate heavily.
We will see how it will work.</content><author><name></name></author><summary type="html">1. Introduction</summary></entry><entry><title type="html">Docs as Code</title><link href="https://javax0.github.io/2022/05/24/docs-as-code.html" rel="alternate" type="text/html" title="Docs as Code" /><published>2022-05-24T00:00:00+02:00</published><updated>2022-05-24T00:00:00+02:00</updated><id>https://javax0.github.io/2022/05/24/docs-as-code</id><content type="html" xml:base="https://javax0.github.io/2022/05/24/docs-as-code.html">== 1. Docs as Code


=== 1.1. it is the first step to the right direction

The approach to treating your documentation the same way as program code is a step in the right direction, but it is far from state-of-the-art. The practice is detailed on many websites that advocate the use of docs-as-code (DAC). For example the link:https://www.writethedocs.org/guide/docs-as-code/[Write the Docs] community has a great article on docs-as-code. The article lists

    * Issue Trackers
    * Version Control (Git)
    * Plain Text Markup (Markdown, reStructuredText, Asciidoc)
    * Code Reviews
    * Automated Tests

as required tools to this approach. Another example is link:https://docs-as-co.de/[docs-as-code], which is a toolset for documentation maintenance. They write
[quote]
____

With docs-as-code, you treat your documentation the same way as your code.

You use…

your IDE to write it
your version control system to store and version it
your test-runner to test it
your build system to build and deploy it&quot;
____

This is very much the same as the approach of link:https://www.writethedocs.org/guide/docs-as-code/[Write the Docs].

image::https://raw.githubusercontent.com/verhas/jamal/master/jamal-snippet/articleimages/docs-as-code-3.svg[]

You have to have your documents in a format supported by the DAC tools. Use version control, document review, automated build, issue tracker, and automated tests. It is very much the same approach we use in code development.

Essentially it is a copy of the professional software development process&apos; coding part. Documentation, however, is not coding. While it is a good idea to reuse some parts of the coding methodology technics, there is more to it.

image::https://raw.githubusercontent.com/verhas/jamal/master/jamal-snippet/articleimages/docs-as-code-4.svg[]

== 2. What docs-as-code Ignores

Coding is a transformation process converting documentation, namely the requirement documentation, into code. The requirement documentation may not be documentation in the classical sense. It may be some note, a list of wishes on a jot of paper. Still, the essence is to convert some human affine into machine affine. Some techniques try to support this process, but most of these techniques die when in production. For example, creating the documentation as UML and making it so precise that the code generation is automatic afterward is not feasible. You could do it in principle, but the cost of the effort is too high. It is cheaper to create the code than documentation that defines the functionality with mathematical precision.

Documenting an application is precisely the opposite direction.

image::https://raw.githubusercontent.com/verhas/jamal/master/jamal-snippet/articleimages/docs-as-code-5.svg[]

Something that failed in one direction does not necessarily fail when we try to go the other direction. You may not be able to jump from the river to the bridge, but the other way is very much possible.

When creating the program documentation, our source is precisely describing the functionality we want to document. After all, the code is the most precise documentation of the application functionality. We already have the precision, which was not feasible to have for the other way around.

The docs-as-code approach, as described by most articles, ignores it. However, it can be amended, and it should be. We can look at it as the next step in the docs-as-code evolution.

=== 2.1. The next step

We can categorize documentation into two categories.

    * Explanatory, and
    * Reference

Sometimes a document belongs to one of the categories, but documents are a mix of the two most of the time. It may even happen that you cannot even tell if a sentence in a document belongs to one category or the other.

Creating an explanatory style text cannot be automated. It needs human effort to create sentences that are clear and easily understandable. The importance is demonstrated by the lack of them in this article, as you may have noticed.

However, creating the reference text is more or less a mechanical task. The documentarian (a term from write-the-docs) copies the key&apos;s name to explain how to configure the system and writes a sentence around it. Copies some sample code from the unit tests into a code segment into the Asciidoc documentation and adds explanation. The reference is taken from the code verbatim in these examples, and the explanatory part is added.

image::https://raw.githubusercontent.com/verhas/jamal/master/jamal-snippet/articleimages/docs-as-code-1.svg[]

You can automate the copy of the reference information. Most of the time, it is not automated.

The catch is that automation, just as in the case of tests, is more expensive than doing manual work once. It pays back when the actual operation (copy and paste) happens many times.

And it usually does. To be more precise, it is supposed to happen. However, the documentation maintenance misses the task in practice, and the document becomes stale. It is where the docs-as-code automated test may help. In principle, it is possible to create a test checking the documentation and find discrepancies between the names in the code and the documentation. It can be heuristic, or it can be exact. To do it the exact way, the documentation and/or the code needs meta-information helping the test to perform the consistency check.

Such a test can signal that the documentation may be outdated and need change. For example, it may give a warning, like
[quote]
____
&quot;The name of the field XYZ is not the same as in the documentation ZZZ. Change ZZZ in the documentation to XYZ&quot;.
____

It is a foolish and outrageous error message. I immediately know that the program architecture is messed up when I see such an error message. If the test can tell me what to do with such precision, it could fix the problem with the same effort.

It is much better if we let the automated build copy the actual name instead of checking that the human did it correctly. To do that, the documentarian should put the meta-information into the documentation instead of the copied value. The meta-information is read by the automated build tool, and using that; it copies the actual value or values.

If the value changes, the build process will automatically change it.

Another advantage is the lesser possibility for error. If the documentarian makes a mistake copying the field&apos;s name, the text will not complain. If he writes XXY instead of XYZ, the documentation will contain the wrong name unless some human review process discovers and fixes the bug. If the documentarian inserts the meta information and makes a mistake, the build process will likely fail. If instead of XYZ, I have to write `{java:field com.javax0.jamal.api#XYZ}` any simple typo will be detected. If there is a field  `com.javax0.jamal.api#XYZ` it is unlikely to have also `com.javax0.jamal.api#XXY`.

image::https://raw.githubusercontent.com/verhas/jamal/master/jamal-snippet/articleimages/docs-as-code-2.svg[]

With this approach, the docs-as-code workflow is extended. The documentation&apos;s &quot; source code &quot; starts behaving as a source code. The automated build is no longer simply formatting and executing language checks. The goal is to automate everything that you can automate. It may not be cheaper than doing the work manually, but certainly less error-prone.

== 3. Tools

All the above theory is pleasant and attractive but worth nothing unless there are tools to implement them. My motivation writing this article is partly to advocate the use of the open-source tool link:https://github.com/verhas/jamal[Jamal]. Although Jamal is a general-purpose macro language and can be used in many areas, its primary purpose is document maintenance support. It is a simple to write, non-intrusive macro language. Using it, you can insert meta-information into the documentation to be processed by the automated build. You can use it with any plain text document format, like Asciidoc, markdown, apt, etc. The latest releases also support the DOCX format to use it even with Microsoft Word.

The set of the macros is quite extensive, and it is easy to add your own. The documentation support module can gather information from the application&apos;s source code as snippets. Snippets can then be transformed, extracted, and inserted into the documentation. Information from the code can be extracted using text tools using the source code text. However, in the case of Java applications, the document transformation may also collect information using reflection. It can be done because Jamal itself is a Java application.

It can be started on the command line as a maven plugin and a maven extension. It is also embedded as a doclet and a taglet to allow Jamal macros in the JavaDoc documentation.

You can use macros to check the consistency of the documentation and the code. You can mark some part of the code as a snippet, and the documentation related to the specific region may contain the hash code of the piece. When the part changes in the source code, the macro evaluation will automatically signal an error.

The application of Jamal is independent of build automation. It can be antora, jBake, or simply a maven project with different plugins. The application of Jamal is also independent of the documentation format. It can be Asciidoc, markdown, apt, etc., as long as the documentation format is text. Using the Word extension included in the command line version, it can even be Microsoft DOCX Word format.

== 4. Conclusion

Treating documentation as source code is a good idea and a good start. It can, and should, however, be extended to include more features. When you treat your documentation as a source code, you should not stop simply using built automation, automated testing, review processes, and versioning. You should also apply techniques like Don&apos;t Repeat Yourself (DRY). Extra tools exist and seamlessly integrate with the already existing build and formatting tools to do that.</content><author><name></name></author><summary type="html">1. Docs as Code</summary></entry><entry><title type="html">Docs as Code is not enough</title><link href="https://javax0.github.io/2022/03/24/2626.html" rel="alternate" type="text/html" title="Docs as Code is not enough" /><published>2022-03-24T00:00:00+01:00</published><updated>2022-03-24T00:00:00+01:00</updated><id>https://javax0.github.io/2022/03/24/2626</id><content type="html" xml:base="https://javax0.github.io/2022/03/24/2626.html">== 1. Docs as Code


=== 1.1. it is the first step to the right direction

The approach to treating your documentation the same way as program code is a step in the right direction, but it is far from state-of-the-art. The practice is detailed on many websites that advocate the use of docs-as-code (DAC). For example the link:https://www.writethedocs.org/guide/docs-as-code/[Write the Docs] community has a great article on docs-as-code. The article lists

 	* Issue Trackers
 	* Version Control (Git)
 	* Plain Text Markup (Markdown, reStructuredText, Asciidoc)
 	* Code Reviews
 	* Automated Tests

as required tools to this approach. Another example is link:https://docs-as-co.de/[docs-as-code], which is a toolset for documentation maintenance. They write
[quote]
____

With docs-as-code, you treat your documentation the same way as your code.

You use…

your IDE to write it
your version control system to store and version it
your test-runner to test it
your build system to build and deploy it&quot;
____

This is very much the same as the approach of link:https://www.writethedocs.org/guide/docs-as-code/[Write the Docs].

image::https://raw.githubusercontent.com/verhas/jamal/master/jamal-snippet/articleimages/docs-as-code-3.svg[]

You have to have your documents in a format supported by the DAC tools. Use version control, document review, automated build, issue tracker, and automated tests. It is very much the same approach we use in code development.

Essentially it is a copy of the professional software development process&apos; coding part. Documentation, however, is not coding. While it is a good idea to reuse some parts of the coding methodology technics, there is more to it.

image::https://raw.githubusercontent.com/verhas/jamal/master/jamal-snippet/articleimages/docs-as-code-4.svg[]

== 2. What docs-as-code Ignores

Coding is a transformation process converting documentation, namely the requirement documentation, into code. The requirement documentation may not be documentation in the classical sense. It may be some note, a list of wishes on a jot of paper. Still, the essence is to convert some human affine into machine affine. Some techniques try to support this process, but most of these techniques die when in production. For example, creating the documentation as UML and making it so precise that the code generation is automatic afterward is not feasible. You could do it in principle, but the cost of the effort is too high. It is cheaper to create the code than documentation that defines the functionality with mathematical precision.

Documenting an application is precisely the opposite direction.

image::https://raw.githubusercontent.com/verhas/jamal/master/jamal-snippet/articleimages/docs-as-code-5.svg[]

Something that failed in one direction does not necessarily fail when we try to go the other direction. You may not be able to jump from the river to the bridge, but the other way is very much possible.

When creating the program documentation, our source is precisely describing the functionality we want to document. After all, the code is the most precise documentation of the application functionality. We already have the precision, which was not feasible to have for the other way around.

The docs-as-code approach, as described by most articles, ignores it. However, it can be amended, and it should be. We can look at it as the next step in the docs-as-code evolution.

=== 2.1. The next step

We can categorize documentation into two categories.

 	* Explanatory, and
 	* Reference

Sometimes a document belongs to one of the categories, but documents are a mix of the two most of the time. It may even happen that you cannot even tell if a sentence in a document belongs to one category or the other.

Creating an explanatory style text cannot be automated. It needs human effort to create sentences that are clear and easily understandable. The importance is demonstrated by the lack of them in this article, as you may have noticed.

However, creating the reference text is more or less a mechanical task. The documentarian (a term from write-the-docs) copies the key&apos;s name to explain how to configure the system and writes a sentence around it. Copies some sample code from the unit tests into a code segment into the Asciidoc documentation and adds explanation. The reference is taken from the code verbatim in these examples, and the explanatory part is added.

image::https://raw.githubusercontent.com/verhas/jamal/master/jamal-snippet/articleimages/docs-as-code-1.svg[]

You can automate the copy of the reference information. Most of the time, it is not automated.

The catch is that automation, just as in the case of tests, is more expensive than doing manual work once. It pays back when the actual operation (copy and paste) happens many times.

And it usually does. To be more precise, it is supposed to happen. However, the documentation maintenance misses the task in practice, and the document becomes stale. It is where the docs-as-code automated test may help. In principle, it is possible to create a test checking the documentation and find discrepancies between the names in the code and the documentation. It can be heuristic, or it can be exact. To do it the exact way, the documentation and/or the code needs meta-information helping the test to perform the consistency check.

Such a test can signal that the documentation may be outdated and need change. For example, it may give a warning, like
[quote]
____
&quot;The name of the field XYZ is not the same as in the documentation ZZZ. Change ZZZ in the documentation to XYZ&quot;.
____

It is a foolish and outrageous error message. I immediately know that the program architecture is messed up when I see such an error message. If the test can tell me what to do with such precision, it could fix the problem with the same effort.

It is much better if we let the automated build copy the actual name instead of checking that the human did it correctly. To do that, the documentarian should put the meta-information into the documentation instead of the copied value. The meta-information is read by the automated build tool, and using that; it copies the actual value or values.

If the value changes, the build process will automatically change it.

Another advantage is the lesser possibility for error. If the documentarian makes a mistake copying the field&apos;s name, the text will not complain. If he writes XXY instead of XYZ, the documentation will contain the wrong name unless some human review process discovers and fixes the bug. If the documentarian inserts the meta information and makes a mistake, the build process will likely fail. If instead of XYZ, I have to write `{java:field com.javax0.jamal.api#XYZ}` any simple typo will be detected. If there is a field  `com.javax0.jamal.api#XYZ` it is unlikely to have also `com.javax0.jamal.api#XXY`.

image::https://raw.githubusercontent.com/verhas/jamal/master/jamal-snippet/articleimages/docs-as-code-2.svg[]

With this approach, the docs-as-code workflow is extended. The documentation&apos;s &quot; source code &quot; starts behaving as a source code. The automated build is no longer simply formatting and executing language checks. The goal is to automate everything that you can automate. It may not be cheaper than doing the work manually, but certainly less error-prone.

== 3. Tools

All the above theory is pleasant and attractive but worth nothing unless there are tools to implement them. My motivation writing this article is partly to advocate the use of the open-source tool link:https://github.com/verhas/jamal[Jamal]. Although Jamal is a general-purpose macro language and can be used in many areas, its primary purpose is document maintenance support. It is a simple to write, non-intrusive macro language. Using it, you can insert meta-information into the documentation to be processed by the automated build. You can use it with any plain text document format, like Asciidoc, markdown, apt, etc. The latest releases also support the DOCX format to use it even with Microsoft Word.

The set of the macros is quite extensive, and it is easy to add your own. The documentation support module can gather information from the application&apos;s source code as snippets. Snippets can then be transformed, extracted, and inserted into the documentation. Information from the code can be extracted using text tools using the source code text. However, in the case of Java applications, the document transformation may also collect information using reflection. It can be done because Jamal itself is a Java application.

It can be started on the command line as a maven plugin and a maven extension. It is also embedded as a doclet and a taglet to allow Jamal macros in the JavaDoc documentation.

You can use macros to check the consistency of the documentation and the code. You can mark some part of the code as a snippet, and the documentation related to the specific region may contain the hash code of the piece. When the part changes in the source code, the macro evaluation will automatically signal an error.

The application of Jamal is independent of build automation. It can be antora, jBake, or simply a maven project with different plugins. The application of Jamal is also independent of the documentation format. It can be Asciidoc, markdown, apt, etc., as long as the documentation format is text. Using the Word extension included in the command line version, it can even be Microsoft DOCX Word format.

== 4. Conclusion

Treating documentation as source code is a good idea and a good start. It can, and should, however, be extended to include more features. When you treat your documentation as a source code, you should not stop simply using built automation, automated testing, review processes, and versioning. You should also apply techniques like Don&apos;t Repeat Yourself (DRY). Extra tools exist and seamlessly integrate with the already existing build and formatting tools to do that.

=== Comments imported from Wordpress


*Docs as Code is not enough - Java Code Geeks - R4 News* 2022-04-04 05:02:00





[quote]
____
[&amp;#8230;] Published on Java Code Geeks with permission by Peter Verhas, partner at our JCG program. See the original article here: Docs as Code is not enough [&amp;#8230;]
____</content><author><name></name></author><summary type="html">1. Docs as Code</summary></entry><entry><title type="html">Lambda and Final Parameters</title><link href="https://javax0.github.io/2021/12/08/lambda-and-final-parameters.html" rel="alternate" type="text/html" title="Lambda and Final Parameters" /><published>2021-12-08T00:00:00+01:00</published><updated>2021-12-08T00:00:00+01:00</updated><id>https://javax0.github.io/2021/12/08/lambda-and-final-parameters</id><content type="html" xml:base="https://javax0.github.io/2021/12/08/lambda-and-final-parameters.html">== 1. Introduction




Lambda expressions can use the variables in the scope of the lambda expression, but only if they are final or effectively final. What is the reason for that? Why is that? It is an interesting question because the answer is not apparent and opinionated.



There is only one ultimate answer, though: because that is what the Java Language Specification says. But saying that is boring. True, but boring. I prefer the answer that says lambdas can only use final and effectively final local variables because lambdas are not closures.



In the following, I will discuss what final and effectively final mean, the differences between closures and lambdas, and finally, how we can create closures in Java using lambda expressions. I am not advocating the creation of lambda expression-based closures in Java, nor the abandonment of the idea.




== 2. `final` and effectively final




When declaring it, a local variable is final if we use the `final` keyword. The compiler will also require that the variable get a value only once. This value assignment may happen at the location of the declaration but can be a bit later. There can be multiple lines that assign value to the final variable so long as long only one of them can execute for each method invocation. The typical case is when you declare a final variable without assigning value to it, and then you have an `if` statement giving different values in the &quot;then&quot; and the &quot;else&quot; branch.



Needless to say that the variable has to be initialized before the lambda expression is created.



A variable is effectively final if not final, but it could be. It gets an assigned value at the declaration or can get a given value only once.




== 3. Life of a Lambda




A lambda expression is a kind of anonymous class. The JVM handles it differently, and it is more efficient than an anonymous class, not to mention that it is more readable. However, from our point of view, we can think of it as an inner class.



[source]
----
public class Anon {

    public static Function&amp;lt;Integer, Integer&amp;gt; incrementer(final int step) {
        return (Integer i) -&amp;gt; i + step;
    }
    public static Function&amp;lt;Integer, Integer&amp;gt; anonIncrementer(final int step) {
        return new Function&amp;lt;Integer, Integer&amp;gt;() {
            @Override
            public Integer apply(Integer i) {
                return i + step;
            }
        };
    }
}
----




When the lambda expression is created, the JVM makes an instance of the lambda class that implements the `Function` interface.



[source]
----
var inc = Anon.incrementer(5);
assertThat(inc.getClass().getName()).startsWith(&quot;javax0.blog.lambdas.Anon$$Lambda$&quot;);
assertThat(inc.getClass().getSuperclass().getName()).isEqualTo(&quot;java.lang.Object&quot;);
assertThat(inc.getClass().getInterfaces()).hasSize(1);
assertThat(inc.getClass().getInterfaces()[0]).isEqualTo(java.util.function.Function.class);
----




The JVM will place this object on the heap. In some cases, the compiler may realize that the object cannot get out of the method&apos;s scope, and in this case, it may store it in the stack. It is called local variable escape analysis, which can just put any object on the stack, which cannot escape from the method and may die together with the method return. However, for our discussion, we can forget this advanced feature of the Java environment.



The lambda is created in the method and stored in the heap. It is alive so long as long there is a hard reference to this object and is not collected. If a lambda expression could reference and use a local variable, which lives in the stack, it would need access to something gone after the method returns. It is not possible.



There are two solutions to overcome this discrepancy. One is what Java follows, creating a copy of the variable&apos;s value. The other one is creating a closure.




== 4. Closure and Groovy




We will look at Groovy examples when talking about closures. The reason to select Groovy is that it is very close to Java. We will look at some Groovy examples, and for the matter of demonstration, we will use Java-style as much as possible. Groovy is more or less compatible with Java; any Java code can be compiled as a Groovy source. The actual semantic may, however, be different slightly.



Groovy solved the issue of local variable accessibility creating closures. The closure closes the functionality and the environment into a single object. For example, the following Groovy code:



[source]
----
class MyClosure {
    static incrementer() {
        Integer z = 0
        return { Integer x -&amp;gt; z++; x + z }
    }
}
----




creates a closure, similar to our lambda expression, but it also uses the local variable `z`. This local variable is not final and not effectively final. What happens here is that the compiler creates a new class that contains a field for each local variable used in the closure. A new local variable references an instance of this new class, and the local variable uses all references to this object and its fields. This object, along with the &quot;lambda expression&quot; code, is the closure.



Since the object is on the heap, it stays alive as long as there is a hard reference. The object, which holds the described function has one, so this object will be available so long as long the closure is alive.



[source]
----
def inc = MyClosure.incrementer();
assert inc(1) == 2
assert inc(1) == 3
assert inc(1) == 4
----




It is clearly shown in the test execution where the closure increases the `z` amount at each execution.



Closures are lambdas with state.




== 5. Lambda in Java




Java approaches this problem differently. Instead of creating a new synthetic object to hold the referenced local variables, it simply uses the values of the variables. Lambdas seem to use the variables, but they don&apos;t. They use only constants copying the value of the variables.



When designing lambdas, there were two options. I was not part of the team making the decisions, so what I write here is only my opinion, guessing, but it may help you understand why the decision was made. One option could be to copy the variable&apos;s value when the lambda is created, not caring about the later value change of the local variable. Could it work? Inevitably. Would it be readable? In many cases, it would not be. What if the variable changes later? Will the lambda use the changed value? No, it will use the copied, frozen value. It is different from how variables work usually.



Java requires the variable to be final or effectively final to solve this discrepancy. The disturbing case having the different variable value when the lambda is used is avoided.



When designing language elements, there are always tradeoffs. On one end, some constructs provide great power to the hands of the developers. However, great power requires great responsibility. Most of the developers are not mature enough to take on the responsibility.



On the other side of the scale are the simple constructs providing less functionality. It may not solve some problems so elegantly, but you also cannot create unreadable code so easily. Java is usually going this way. There has been an obfuscated C contest almost since the language C started. Who can write less readable code in that programming language? Since then, almost all languages started the contest, except two. Java and Perl. In the case of Java, the contest would be dull, as you cannot write obfuscated code in Java. In the case of Perl, the contest is pointless.




== 6. Closure in Java




If you want to have a closure in Java, you can create one yourself. The good old way is to use anonymous, or for that matter, regular classes. The other is to mimic the behavior of the Groovy compiler and create a class that encapsulates the closure data.



The Groovy compiler creates the class for you to enclose the local variables, but nothing stops you from making it manually if you want it in Java. You have to do the same thing. Move every local variable that the closure uses into a class as an instance field.



[source]
----
public static Function&amp;lt;Integer, Integer&amp;gt; incrementer() {
    AtomicInteger z = new AtomicInteger(0);
    return x -&amp;gt; {
        z.set(z.get() + 1);
        return x + z.get();
    };
}
----




We only had one local variable, `int z`, in our example. We need a class that can hold an int. The class for that is `AtomicInteger`. It does many other things, and it is usually used when concurrent execution is an issue. Because of that, some overhead may slightly affect the performance, which I abjectly ignore for now.



If there are more than one local variables, we need to craft a class for them.



[source]
----
public static Function&amp;lt;Integer, Integer&amp;gt; incrementer() {
    class DataHolder{int z; int m;}
    final var dh = new DataHolder();
    return x -&amp;gt; {
        dh.z++;
        dh.m++;
        return x + dh.z*dh.m;
    };
}
----




As you can see in this example, we can declare a class even inside the method, and for the cohesion of the code, it is the right place. Eventually, it is easy to see that this approach is working.



[source]
----
final var inc = LambdaComplexClosure.incrementer();
assertThat(inc.apply(1)).isEqualTo(2);
assertThat(inc.apply(1)).isEqualTo(5);
assertThat(inc.apply(1)).isEqualTo(10);
----




It is, however, questionable if you want to use this approach. Lambdas generally should be stateless. When you need a state that a lambda uses, in other words, when you need a closure, which the language does not directly support, you should use a class.




== 7. Summary




* This article discussed why a lambda expression can access only final and effectively final local variables.* We also discussed the reason and how different languages approach this issue.* Finally, we looked at a Groovy example and how Java can mimic this.



Therefore, if anyone asks you the interview question, why a lambda expression can access only final and effectively final local variables, you will know the answer. Because the Java Language Specification says so. Everything else is speculation.



You an find the code for this article along with the article text source code at https://github.com/verhas/demo/tree/master/LambdaFinal</content><author><name></name></author><summary type="html">1. Introduction</summary></entry><entry><title type="html">Lambda and final variables</title><link href="https://javax0.github.io/2021/12/08/lambda-and-final-variables.html" rel="alternate" type="text/html" title="Lambda and final variables" /><published>2021-12-08T00:00:00+01:00</published><updated>2021-12-08T00:00:00+01:00</updated><id>https://javax0.github.io/2021/12/08/lambda-and-final-variables</id><content type="html" xml:base="https://javax0.github.io/2021/12/08/lambda-and-final-variables.html">== 1. Introduction




Lambda expressions can use the variables in the scope of the lambda expression, but only if they are final or effectively final. What is the reason for that? Why is that? It is an interesting question because the answer is not apparent and opinionated.



There is only one ultimate answer, though: because that is what the Java Language Specification says. But saying that is boring. True, but boring. I prefer the answer that says lambdas can only use final and effectively final local variables because lambdas are not closures.



In the following, I will discuss what final and effectively final mean, the differences between closures and lambdas, and finally, how we can create closures in Java using lambda expressions. I am not advocating the creation of lambda expression-based closures in Java, nor the abandonment of the idea.




== 2. `final` and effectively final




When declaring it, a local variable is final if we use the `final` keyword. The compiler will also require that the variable get a value only once. This value assignment may happen at the location of the declaration but can be a bit later. There can be multiple lines that assign value to the final variable so long as long only one of them can execute for each method invocation. The typical case is when you declare a final variable without assigning value to it, and then you have an `if` statement giving different values in the &quot;then&quot; and the &quot;else&quot; branch.



Needless to say that the variable has to be initialized before the lambda expression is created.



A variable is effectively final if not final, but it could be. It gets an assigned value at the declaration or can get a given value only once.




== 3. Life of a Lambda




A lambda expression is a kind of anonymous class. The JVM handles it differently, and it is more efficient than an anonymous class, not to mention that it is more readable. However, from our point of view, we can think of it as an inner class.



[source]
----
public class Anon {

    public static Function&lt;Integer, Integer&gt; incrementer(final int step) {
        return (Integer i) -&gt; i + step;
    }
    public static Function&lt;Integer, Integer&gt; anonIncrementer(final int step) {
        return new Function&lt;Integer, Integer&gt;() {
            @Override
            public Integer apply(Integer i) {
                return i + step;
            }
        };
    }
}
----




When the lambda expression is created, the JVM makes an instance of the lambda class that implements the `Function` interface.



[source]
----
var inc = Anon.incrementer(5);
assertThat(inc.getClass().getName()).startsWith(&quot;javax0.blog.lambdas.Anon$$Lambda$&quot;);
assertThat(inc.getClass().getSuperclass().getName()).isEqualTo(&quot;java.lang.Object&quot;);
assertThat(inc.getClass().getInterfaces()).hasSize(1);
assertThat(inc.getClass().getInterfaces()[0]).isEqualTo(java.util.function.Function.class);
----




The JVM will place this object on the heap. In some cases, the compiler may realize that the object cannot get out of the method&apos;s scope, and in this case, it may store it in the stack. It is called local variable escape analysis, which can just put any object on the stack, which cannot escape from the method and may die together with the method return. However, for our discussion, we can forget this advanced feature of the Java environment.



The lambda is created in the method and stored in the heap. It is alive so long as long there is a hard reference to this object and is not collected. If a lambda expression could reference and use a local variable, which lives in the stack, it would need access to something gone after the method returns. It is not possible.



There are two solutions to overcome this discrepancy. One is what Java follows, creating a copy of the variable&apos;s value. The other one is creating a closure.




== 4. Closure and Groovy




We will look at Groovy examples when talking about closures. The reason to select Groovy is that it is very close to Java. We will look at some Groovy examples, and for the matter of demonstration, we will use Java-style as much as possible. Groovy is more or less compatible with Java; any Java code can be compiled as a Groovy source. The actual semantic may, however, be different slightly.



Groovy solved the issue of local variable accessibility creating closures. The closure closes the functionality and the environment into a single object. For example, the following Groovy code:



[source]
----
class MyClosure {
    static incrementer() {
        Integer z = 0
        return { Integer x -&gt; z++; x + z }
    }
}
----




creates a closure, similar to our lambda expression, but it also uses the local variable `z`. This local variable is not final and not effectively final. What happens here is that the compiler creates a new class that contains a field for each local variable used in the closure. A new local variable references an instance of this new class, and the local variable uses all references to this object and its fields. This object, along with the &quot;lambda expression&quot; code, is the closure.



Since the object is on the heap, it stays alive as long as there is a hard reference. The object, which holds the described function has one, so this object will be available so long as long the closure is alive.



[source]
----
def inc = MyClosure.incrementer();
assert inc(1) == 2
assert inc(1) == 3
assert inc(1) == 4
----




It is clearly shown in the test execution where the closure increases the `z` amount at each execution.



Closures are lambdas with state.




== 5. Lambda in Java




Java approaches this problem differently. Instead of creating a new synthetic object to hold the referenced local variables, it simply uses the values of the variables. Lambdas seem to use the variables, but they don&apos;t. They use only constants copying the value of the variables.



When designing lambdas, there were two options. I was not part of the team making the decisions, so what I write here is only my opinion, guessing, but it may help you understand why the decision was made. One option could be to copy the variable&apos;s value when the lambda is created, not caring about the later value change of the local variable. Could it work? Inevitably. Would it be readable? In many cases, it would not be. What if the variable changes later? Will the lambda use the changed value? No, it will use the copied, frozen value. It is different from how variables work usually.



Java requires the variable to be final or effectively final to solve this discrepancy. The disturbing case having the different variable value when the lambda is used is avoided.



When designing language elements, there are always tradeoffs. On one end, some constructs provide great power to the hands of the developers. However, great power requires great responsibility. Most of the developers are not mature enough to take on the responsibility.



On the other side of the scale are the simple constructs providing less functionality. It may not solve some problems so elegantly, but you also cannot create unreadable code so easily. Java is usually going this way. There has been an obfuscated C contest almost since the language C started. Who can write less readable code in that programming language? Since then, almost all languages started the contest, except two. Java and Perl. In the case of Java, the contest would be dull, as you cannot write obfuscated code in Java. In the case of Perl, the contest is pointless.




== 6. Closure in Java




If you want to have a closure in Java, you can create one yourself. The good old way is to use anonymous, or for that matter, regular classes. The other is to mimic the behavior of the Groovy compiler and create a class that encapsulates the closure data.



The Groovy compiler creates the class for you to enclose the local variables, but nothing stops you from making it manually if you want it in Java. You have to do the same thing. Move every local variable that the closure uses into a class as an instance field.



[source]
----
public static Function&lt;Integer, Integer&gt; incrementer() {
    AtomicInteger z = new AtomicInteger(0);
    return x -&gt; {
        z.set(z.get() + 1);
        return x + z.get();
    };
}
----




We only had one local variable, `int z`, in our example. We need a class that can hold an int. The class for that is `AtomicInteger`. It does many other things, and it is usually used when concurrent execution is an issue. Because of that, some overhead may slightly affect the performance, which I abjectly ignore for now.



If there are more than one local variables, we need to craft a class for them.



[source]
----
public static Function&lt;Integer, Integer&gt; incrementer() {
    class DataHolder{int z; int m;}
    final var dh = new DataHolder();
    return x -&gt; {
        dh.z++;
        dh.m++;
        return x + dh.z*dh.m;
    };
}
----




As you can see in this example, we can declare a class even inside the method, and for the cohesion of the code, it is the right place. Eventually, it is easy to see that this approach is working.



[source]
----
final var inc = LambdaComplexClosure.incrementer();
assertThat(inc.apply(1)).isEqualTo(2);
assertThat(inc.apply(1)).isEqualTo(5);
assertThat(inc.apply(1)).isEqualTo(10);
----




It is, however, questionable if you want to use this approach. Lambdas generally should be stateless. When you need a state that a lambda uses, in other words, when you need a closure, which the language does not directly support, you should use a class.




== 7. Summary




* This article discussed why a lambda expression can access only final and effectively final local variables.* We also discussed the reason and how different languages approach this issue.* Finally, we looked at a Groovy example and how Java can mimic this.



Therefore, if anyone asks you the interview question, why a lambda expression can access only final and effectively final local variables, you will know the answer. Because the Java Language Specification says so. Everything else is speculation.



You an find the code for this article along with the article text source code at https://github.com/verhas/demo/tree/master/LambdaFinal


=== Comments imported from Wordpress


*Peter Verhas* 2021-12-30 21:49:42





[quote]
____
Good catch! I fixed that sentence. It has to be &quot;The JVM will place this object on the heap.&quot;

Thanks.
____





*Filip* 2021-12-30 20:46:14





[quote]
____
Is lambda stored on heap or on stack? In paragraph four of &quot;Life of lambda&quot; it is said that lambda is created on a stack, but description is suggesting that it is created on a heap.
____





*Lambda and final variables - Java Code Geeks - R4 News* 2021-12-19 14:24:08





[quote]
____
[&amp;#8230;] Posted on Java Code Geeks with the permission of Peter Verhas, partner of our JCG program. See the original article here: Lambda and final variables [&amp;#8230;]
____





*Lambda and final variables &amp;#8211; Java Code Geeks &amp;#8211; Munaf Sheikh* 2021-12-19 14:30:58





[quote]
____
[&amp;#8230;] Published on Java Code Geeks with permission by Peter Verhas, partner at our JCG program. See the original article here: Lambda and final variables [&amp;#8230;]
____





*Lambda and final variables – Java Code Geeks &amp;#8211; Munaf Sheikh* 2021-12-19 17:35:51





[quote]
____
[&amp;#8230;] Published on Java Code Geeks with permission by Peter Verhas, partner at our JCG program. See the original article here: Lambda and final variables [&amp;#8230;]
____</content><author><name></name></author><summary type="html">1. Introduction</summary></entry><entry><title type="html">Custom Styles</title><link href="https://javax0.github.io/2021/12/03/wp-global-styles-pub-2ftwentytwelve.html" rel="alternate" type="text/html" title="Custom Styles" /><published>2021-12-03T00:00:00+01:00</published><updated>2021-12-03T00:00:00+01:00</updated><id>https://javax0.github.io/2021/12/03/wp-global-styles-pub%2Ftwentytwelve</id><content type="html" xml:base="https://javax0.github.io/2021/12/03/wp-global-styles-pub-2ftwentytwelve.html">{&quot;version&quot;:2,&quot;isGlobalStylesUserThemeJSON&quot;:true}</content><author><name></name></author><summary type="html">{&quot;version&quot;:2,&quot;isGlobalStylesUserThemeJSON&quot;:true}</summary></entry><entry><title type="html">Why and how to do technical interviews?</title><link href="https://javax0.github.io/2021/09/22/why-and-how-do-to-do-technical-interviews.html" rel="alternate" type="text/html" title="Why and how to do technical interviews?" /><published>2021-09-22T00:00:00+02:00</published><updated>2021-09-22T00:00:00+02:00</updated><id>https://javax0.github.io/2021/09/22/why-and-how-do-to-do-technical-interviews</id><content type="html" xml:base="https://javax0.github.io/2021/09/22/why-and-how-do-to-do-technical-interviews.html">I__t is a personal blog. The views and opinions expressed in this article are those of the author. They do not represent people, institutions, or organizations that the author may or may not be associated with in a professional or a personal capacity. All information is provided on an as-is basis.__



Technology companies are growing and need new personnel. In addition, there is natural attrition in the companies. In a highly competitive market, people are leaving for various reasons, and these needs also have to be met through hiring new employees. Therefore, searching for, selecting, and hiring new co-workers are always a must - it is a standard business for every company.



Companies usually conduct interviews to assess and select their future colleagues from the pool of aspiring candidates. Even though it is the standard practice, there are a lot of controversies with this approach. You can see many social media posts about harmful practices, wrong questions, and ill-treatment of the candidate. One infamous example was when Google asked candidates in their interviews to estimate the number of golf balls that could fit in a bus.



Most of the people having a voice on social media express their opinion that this was total misuse. I tend to see some merit in using such questions, but, as often, personal opinions are irrelevant. So instead of starting a debate about this particular question or similar questionable practices, I will focus on the purpose and the practical approaches we apply when conducting interviews.



I mainly rely on the experiences I gained when completing interviews on behalf of my current employer, but I believe there is nothing company-specific in this article.



When I write &apos;we&apos;, I refer to the whole industry or at least to a large group of companies that follow good practice and not specifically to my employer.




=== 1.1. What is the purpose of conducting interviews?




Any company could hire a candidate without any prior filtering, but this could cost them a lot. Suppose the candidate does not fit the company or meet the criteria to be successful in a position. In that case, the company would have to pay the salary for the probation period, colleagues guiding the new hire during the onboarding process would invest significant time and effort, and other resources, like office space, infrastructure, heating, network, and so on, that also costs money. It is not a good practice for a company.



However, the money the company loses is not the main issue. Companies have profit and loss, and you can consider the cost of selecting the right candidate as an investment. The highest cost is not monetary, and it is not on the company side. The candidate is the one who would pay the real price for such a practice.



Most of the candidates have a safe job and solid position when looking for a new one. However, losing the place at the new job, getting sent away is a substantial personal burden. As a result, candidates may find themselves &quot;in the street&quot; looking for a new position. Not having a current job is hard to explain during the HR interviews. At the same time, the financial burden and the time pressure may also put the candidate into a hard-to-negotiate corner during the salary discussions.
No company should do this to anyone. If a company wants to hire you without proper assessment: run. Fast and far away.



The thorough assessments of the candidates&apos; skills, experience, and knowledge are at the other end of the spectrum. Some companies do that by giving out homework, completing full-day assessments filled with role plays, coding tasks, and using other similar techniques to evaluate candidates. The simplest and cheapest way to do an evaluation, however, is an interview.



A full-day assessment almost certainly gives a more reliable result, but it requires significant resources from the company. So, as usual in business, we should follow the Pareto principle and shoot for the cheapest good-enough solution. I will talk a bit later about what ‘good enough’ is.



Overcomplicated hiring processes may distract candidates. Imagine a senior developer who is looking for a new position. How many full-day assessments will they attend? To participate in such a selection, candidates may need to use a vacation day from their holiday budget, and they have to keep it secret at the actual workplace. If your competitor offers you a late afternoon interview instead, you will most probably choose that option.



There are pros and cons. We cannot tell what the best approach is, and certainly, doing interviews as a selection tool is not the imaginable best, but probably the best existing, and indeed the best we know. Nevertheless, it is the industry standard practice.




=== 1.2. What is a good interview?




We do not need to complete the best interview in the world, as I wrote above. We have to complete one that is good enough. To say that, we have to know what we consider to be a good interview. We should have a metric that can tell us which interview is &quot;better&quot;.



Candidates often tell me: &quot;This was the best interview of my life.&quot;, even when my conclusion is not to recommend them for hire. Although a happy candidate is essential in bringing your company a good image, it is not the metric we usually look for. A good interview does not need to be enjoyable for the candidate. That is just an extra, a possible byproduct of a good interview.



An interview&apos;s most crucial quality measure is to differentiate a fitting candidate from a non-fitting one. Of course, there are other criteria, like proper communication, politeness, non-disclosure, and conduct. These are all very important. Nevertheless, the primary goal of the interview is the selection.



When doing an interview, there are four possible outcomes. The candidate can be fitting or non-fitting, and at the same time, the interviewer recommends or does not recommend the candidate for hire. These are two dimensions with two values each. Each pair is possible, resulting in the four possible outcomes.



The recommended fitting candidate and the non-recommended non-fitting candidates are the most uncomplicated cases. These are the happy paths.



The remaining two cases, false positive and false negative, are a bit more tricky. The case when the interviewer does not recommend the candidate, although they are fitting, is theoretical. Those candidates do not get employed, and none will discover their fitness. In other words, we will never know when a candidate and/or an interview fall into this category. This case is theoretical in the sense that though it certainly exists, we will never see it.



When a candidate is recommended but not fitting is the costly situation we already discussed. When it happens, it will be clear for many people in the company who will manage the consequences and deal with the problem.



The solution for the situation is often to find a better, more suitable position for the person inside the company. It is done falling into the trap of the sunk cost fallacy. The people involved subconsciously feel the relative cost and burden of finding a new position without an existing need and actual vacancy. This cost is born to the candidate. Feeling responsible for the situation, they do not want to put that on them.



When the company has a good hiring and interviewing practice, it rarely happens. We cannot avoid such situations, however. It is not because of the unique nature of the interviews. It is a general measurement theory. Any decision can have four outcomes: true-positive, true-negative, false-positive, and false-negative. No decision system could avoid the false parts. They exist by principle. The only thing we can tune is to push the scale between the false outcomes. What do we want to have less? Is it the false positive or the false negative result which is less desirable?



At this point, you can tell that I am advocating against the false positive cases, which means that we have to design the interview decisions to avoid those even if we get more false-negative results.



This advocation is not general, though. It is only for the interview decisions. For example, a cancer screening system should be scaled towards favoring false-positive cases. I would rather choose a few days of panic until the repeated test annuls the false-positive result than die because of a false-negative result not detecting the tumor at an early stage.



The fact that we should favor the false-negative cases means that the technical interviewers should recommend hiring only those candidates they are absolutely sure about. When there is any doubt that the candidate is bad, they are better not to be hired.



Note that by doing so, you will filter out some candidates who are good enough but are not very good. You have your doubts not without reason. The potential loss is insignificant in sending away some of the candidates who would fit but are not &quot;really good&quot;.




=== 1.3. Do we judge the candidate?




Avoid judging the candidate is extremely important. In the previous section, I deliberately used &quot;good candidate&quot; and &quot;bad candidate&quot;. In addition, I used an example (medical screening) that subconsciously compared candidates to cancer. If you felt inappropriate when you first read that, you are on the right track. If not, you have to think about why you did not.



We must respect the candidates.



Technical interviewers have to be humble. Maybe non-trivial at first, but we also must not evaluate the person, and we should not use expressions that may even unintentionally imply that. You cannot do that if you look down on candidates and you do not respect them. The respect has to be authentic. If it is not, you cannot hide it. So the first thing is that you should feel and show genuine care and then work on your communication.



It is why I prefer to use the word &quot;assess&quot; instead of &quot;judge&quot;. We assess the knowledge, skills, and experience of the candidate. We do not &quot;judge&quot; these, even though linguistically, it would mean the same. For the same reason, I usually talk about the position fitting the candidate and not the candidate fitting the position. Thus, when I say that a position is not good for a specific candidate, nobody will think that it is generally bad, even less that it is stupid or dumb.



On the other hand, the sentence &quot;The candidate is not good for the position.&quot; is heard and interpreted as &quot;The candidate is not good…&quot; The end of the sentence often gets lost in the communication or during the interpretation. It has to be carefully avoided.



Sometimes, I meet lead developers, senior, or even architect candidates who lack even basic skills in their current employment. Even though I feel the temptation to doubt whether their current status is well justified, I don&apos;t. If a candidate’s current position seems to be a lie in the CV, it does not matter. Companies are different, and they need different types of people. There is no such person who is generally not fitting a role. To assess a person&apos;s fitness for a position, you have to compare the person&apos;s qualities to the role. Otherwise, you could plainly say that the candidate is ok but can not tell us for what.




=== 1.4. Work with the Candidate




When conducting the interview, you work with the candidate. The candidate helps you, and you help the candidate. To get a clear picture and understand whether the position is really the dream position for the candidate is in your mutual interest.



It means that you can be absolutely honest with the candidate. You can tell them all the things that I wrote in this article. You can explain the aim of the interview, what the possible outcomes are, the recommended and not recommended decisions, and so on.



I usually devote 7 minutes at the start of the interview explaining the above. Of course, it is a bit boring after several hundreds of interviews, but every job has its downsides and upsides, and it is crucial for each candidate.



You can even explain that when candidates are lying or cheating candidates, it might be harmful. It helps when a candidate gets a coding exercise that is too familiar to them. A few times, the candidate proactively warned me that they had already met the task beforehand. So we chose a different one.




=== 1.5. Coding Exercise




The above paragraphs are generally valid for all types of interviews and not specific for software development. For example, doing a coding exercise is specific to technical software developer interviews. However, most of the debates on social media are related to this practice. The reason for that is simple. It is very easy to do it wrong.



I would never recommend a candidate who cannot demonstrate the coding skills in an interview. After all, what is the value a developer can deliver who cannot code? It is more questionable if a solution architect needs to code, and I would not get into that this time. I have my personal opinion about it, but it is irrelevant. Maybe I will discuss it in a different article.



I have met some developers hired from different vendors working in the same team for our clients who could not code. We never complained, and we did the extra work instead of them. The client personnel could see who did what and came to their conclusions most of the time. I will also not name the vendor ever. Let&apos;s just say that these developers stay afloat in the industry until they find a different job and become BAs, PMs, or car salesmen. I accept them as a fact of life, but I do not accept hiring one in my workplace. In conclusion, we should agree that some performance measures are needed to assess the coding skills as a work theory.



An excellent coding exercise helps assess three things:



* The algorithmic thinking of the candidate.* Coding skills and the muscle memory of the language we test. In my case, it is Java.* Communication skills.



Each of these can easily go wrong, and hence negative stories quickly get to social media.



It is challenging to assess algorithmic thinking. It is much easier to test if the candidate can solve one specific problem or complete a task. That way, the assessment quickly degrades to testing if the candidate knows the particular algorithm. Even though I believe that learning and understanding the most important algorithms and data structures (quick sort, balanced trees, graph traversing) is vital for a developer, many developers do not possess even the fundamental computer science theory. I can also accept that there is no value in knowing many algorithms by heart. It is better to have the skillset to create the algorithm when needed.



To avoid testing the candidate knowing the task instead of solving it, I have several of them you cannot find on the internet. (Fun story about that at the end of the article.) We also discuss the solution while the candidate forges the code step by step. I realize if the candidate has known the algorithm beforehand.



You can test the coding skills easily. Many typical coding practices show off an inexperienced coder.



You can spot old coding constructs that we are not using anymore as the language (in my case, Java) develops. I sometimes see explicit type boxing, which we do not use since Java 1.4 Junior developers tend to compare a boolean value with &apos;== true&apos; or write an &apos;if&apos; statement and return &apos;true&apos; and &apos;false&apos; literal values from the execution branches. Some developers make mistakes, like indexing a &apos;String&apos; as if it was an array.



As an interviewer, you should interpret those with a pinch of salt. The interview is not a normal coding environment. It is much more stressful, and such mistakes are many times caused by stress. The technical tools are usually less advanced than the usual IDE, with less support for code completion, syntax checking, and so on. Do not expect the candidate to know all the JDK API calls from the top of their head.



You can also check communication skills. For example, some candidates blamed me for presenting unprecise, even sloppy task descriptions. They were surprised when I told them that I was aware of that. It is to test if they clarify the task before making bold assumptions and just immediately start coding. Most of them do.



The coding exercise is the most challenging part of the interview. Not for the candidate, though. It is for the interviewer. It is a task that the candidate has to do together with you. If you, as an interviewer, see that the candidate is working on the coding task alone, you are doing it wrong. If you work together, then it is good. It may not be perfect, but most of the usual pitfalls you have already avoided.




=== 1.6. Giving Feedback




At the end of the interview, you will know whether to recommend or not to recommend the candidate. If you don&apos;t know, if you are not absolutely sure, then you should not recommend the candidate. I wrote that you must not recommend someone you are not sure about.



The recommendation, usually along with detailed analysis, is the primary outcome of the interview. There can be, however, another valuable byproduct. You can give valuable feedback to the candidate.



Interviewers seldom give feedback about the interview to the candidates, and this is not a good practice. I do not advocate giving feedback no matter what because it is a double-edged sword. If you provide feedback in the wrong way, it may cause a lot of harm to the candidate and the company. Providing valuable, thoughtful, and relevant feedback required some special skills.



Good feedback emphasizes the candidate&apos;s strong points that they can build on and highlights the things that they can improve and that may result in enormous benefits.



The most benefit is evidently for the candidate, but it is also valuable for the company. Getting detailed feedback is always an invaluable help to better ourselves. Good feedback, however, is also beneficial for the company. Even if rejecting a candidate is the correct conclusion, a blatant and unexplained refusal may induce bad feelings towards the company. Feedback can mitigate this risk. Feedback explains the reasons so that the candidate can learn the reasons along with suggestions for improvement. Again, you can emphasize that the refusal is not a judgment; it solely recognizes the incompatibility between the candidate’s skills, experience, or knowledge and what the company requires in a specific role.



You do not know each other. Thus, you have to put a lot of emphasis on the good things that the candidate can build on. You can also explain that the feedback is limited as it is based on a 60-minute interview only.



Some candidates challenge some of my statements during the feedback. It is pointless from the feedback point of view. If I made a mistake, I misread the candidate in some aspect; they can ignore that part of the feedback. Some of the comments may likely be wrong due to the limited nature of the session. At the same time, I give feedback after the decision. It would be best if you did not change the decision based on any feedback debate. Even though I am usually lenient with candidates arguing about some points of the feedback. It reveals a lot about their personality that I can include in the subjective part of the interview record, and at the same time, it helps them vent their feelings.



I had candidates referred to our company by his friend I rejected but sent away with friendly but honest feedback.




=== 1.7. Summary and Fun Story




Navigare necesse est. Doing interviews is unavoidable. Vivere no est necesse. Doing good interviews is difficult. In this article, I wrote about some aspects of the interviewing. There are other aspects that I did not discuss. Those I may address in a later article. I also know that many aspects of this topic are opinionated. You are welcome to comment, rant, criticize and tell the truth as you feel fit.



I promised you a fun story, so here it is.



Once I interviewed a candidate who was not outstanding. He had several knowledge gaps related to basic Java. He knew a few things wrong and was a bit stubborn. His coding skills were also less than what we required. When I ended the interview, I asked him if he wanted feedback. He said no, and disconnected the communication. (We usually do remote interviews using IP communication tools, like Zoom, Teams, Skype, etc.)



He immediately wrote an eMail to the talent acquisition team claiming that I was asking him wrong; I did not accept his correct answers and stating that I did not know Java. He also wrote that I was giving him a coding task that anyone can find on the internet, and I did not accept his correct solution because I did not like him. Even though he did not agree to video recording, the coding exercise does get recorded to crosscheck. I did not doubt that the solution was wrong, but his statement that I allegedly copied the exercise from the internet bothered me. So I googled some of the sentences of the task. I could find it on a site along with a wrong solution he also provided. It was word by word the same, including a typo. So you can guess who was copying from whom.



Your coding exercise tasks leak out. So you have to replace them frequently.</content><author><name></name></author><summary type="html">It is a personal blog. The views and opinions expressed in this article are those of the author. They do not represent people, institutions, or organizations that the author may or may not be associated with in a professional or a personal capacity. All information is provided on an as-is basis.</summary></entry><entry><title type="html">Why and how to do technical interviews?</title><link href="https://javax0.github.io/2021/09/22/why-and-how-to-do-technical-interviews.html" rel="alternate" type="text/html" title="Why and how to do technical interviews?" /><published>2021-09-22T00:00:00+02:00</published><updated>2021-09-22T00:00:00+02:00</updated><id>https://javax0.github.io/2021/09/22/why-and-how-to-do-technical-interviews</id><content type="html" xml:base="https://javax0.github.io/2021/09/22/why-and-how-to-do-technical-interviews.html">== 1. Why and how to do technical interviews?

__It is a personal blog. The views and opinions expressed in this article are those of the author. They do not represent people, institutions, or organizations that the author may or may not be associated with in a professional or a personal capacity. All information is provided on an as-is basis.__



Technology companies are growing and need new personnel. In addition, there is natural attrition in the companies. In a highly competitive market, people are leaving for various reasons, and these needs also have to be met through hiring new employees. Therefore, searching for, selecting, and hiring new co-workers are always a must - it is a standard business for every company.



Companies usually conduct interviews to assess and select their future colleagues from the pool of aspiring candidates. Even though it is the standard practice, there are a lot of controversies with this approach. You can see many social media posts about harmful practices, wrong questions, and ill-treatment of the candidate. One infamous example was when Google asked candidates in their interviews to estimate the number of golf balls that could fit in a bus.



Most of the people having a voice on social media express their opinion that this was total misuse. I tend to see some merit in using such questions, but, as often, personal opinions are irrelevant. So instead of starting a debate about this particular question or similar questionable practices, I will focus on the purpose and the practical approaches we apply when conducting interviews.



I mainly rely on the experiences I gained when completing interviews on behalf of my current employer, but I believe there is nothing company-specific in this article.



When I write &apos;we&apos;, I refer to the whole industry or at least to a large group of companies that follow good practice and not specifically to my employer.




=== 1.1. What is the purpose of conducting interviews?




Any company could hire a candidate without any prior filtering, but this could cost them a lot. Suppose the candidate does not fit the company or meet the criteria to be successful in a position. In that case, the company would have to pay the salary for the probation period, colleagues guiding the new hire during the onboarding process would invest significant time and effort, and other resources, like office space, infrastructure, heating, network, and so on, that also costs money. It is not a good practice for a company.



However, the money the company loses is not the main issue. Companies have profit and loss, and you can consider the cost of selecting the right candidate as an investment. The highest cost is not monetary, and it is not on the company side. The candidate is the one who would pay the real price for such a practice.



Most of the candidates have a safe job and solid position when looking for a new one. However, losing the place at the new job, getting sent away is a substantial personal burden. As a result, candidates may find themselves &quot;in the street&quot; looking for a new position. Not having a current job is hard to explain during the HR interviews. At the same time, the financial burden and the time pressure may also put the candidate into a hard-to-negotiate corner during the salary discussions.
No company should do this to anyone. If a company wants to hire you without proper assessment: run. Fast and far away.



The thorough assessments of the candidates&apos; skills, experience, and knowledge are at the other end of the spectrum. Some companies do that by giving out homework, completing full-day assessments filled with role plays, coding tasks, and using other similar techniques to evaluate candidates. The simplest and cheapest way to do an evaluation, however, is an interview.



A full-day assessment almost certainly gives a more reliable result, but it requires significant resources from the company. So, as usual in business, we should follow the Pareto principle and shoot for the cheapest good-enough solution. I will talk a bit later about what ‘good enough’ is.



Overcomplicated hiring processes may distract candidates. Imagine a senior developer who is looking for a new position. How many full-day assessments will they attend? To participate in such a selection, candidates may need to use a vacation day from their holiday budget, and they have to keep it secret at the actual workplace. If your competitor offers you a late afternoon interview instead, you will most probably choose that option.



There are pros and cons. We cannot tell what the best approach is, and certainly, doing interviews as a selection tool is not the imaginable best, but probably the best existing, and indeed the best we know. Nevertheless, it is the industry standard practice.




=== 1.2. What is a good interview?




We do not need to complete the best interview in the world, as I wrote above. We have to complete one that is good enough. To say that, we have to know what we consider to be a good interview. We should have a metric that can tell us which interview is &quot;better&quot;.



Candidates often tell me: &quot;This was the best interview of my life.&quot;, even when my conclusion is not to recommend them for hire. Although a happy candidate is essential in bringing your company a good image, it is not the metric we usually look for. A good interview does not need to be enjoyable for the candidate. That is just an extra, a possible byproduct of a good interview.



An interview&apos;s most crucial quality measure is to differentiate a fitting candidate from a non-fitting one. Of course, there are other criteria, like proper communication, politeness, non-disclosure, and conduct. These are all very important. Nevertheless, the primary goal of the interview is the selection.



When doing an interview, there are four possible outcomes. The candidate can be fitting or non-fitting, and at the same time, the interviewer recommends or does not recommend the candidate for hire. These are two dimensions with two values each. Each pair is possible, resulting in the four possible outcomes.



The recommended fitting candidate and the non-recommended non-fitting candidates are the most uncomplicated cases. These are the happy paths.



The remaining two cases, false positive and false negative, are a bit more tricky. The case when the interviewer does not recommend the candidate, although they are fitting, is theoretical. Those candidates do not get employed, and none will discover their fitness. In other words, we will never know when a candidate and/or an interview fall into this category. This case is theoretical in the sense that though it certainly exists, we will never see it.



When a candidate is recommended but not fitting is the costly situation we already discussed. When it happens, it will be clear for many people in the company who will manage the consequences and deal with the problem.



The solution for the situation is often to find a better, more suitable position for the person inside the company. It is done falling into the trap of the sunk cost fallacy. The people involved subconsciously feel the relative cost and burden of finding a new position without an existing need and actual vacancy. This cost is born to the candidate. Feeling responsible for the situation, they do not want to put that on them.



When the company has a good hiring and interviewing practice, it rarely happens. We cannot avoid such situations, however. It is not because of the unique nature of the interviews. It is a general measurement theory. Any decision can have four outcomes: true-positive, true-negative, false-positive, and false-negative. No decision system could avoid the false parts. They exist by principle. The only thing we can tune is to push the scale between the false outcomes. What do we want to have less? Is it the false positive or the false negative result which is less desirable?



At this point, you can tell that I am advocating against the false positive cases, which means that we have to design the interview decisions to avoid those even if we get more false-negative results.



This advocation is not general, though. It is only for the interview decisions. For example, a cancer screening system should be scaled towards favoring false-positive cases. I would rather choose a few days of panic until the repeated test annuls the false-positive result than die because of a false-negative result not detecting the tumor at an early stage.



The fact that we should favor the false-negative cases means that the technical interviewers should recommend hiring only those candidates they are absolutely sure about. When there is any doubt that the candidate is bad, they are better not to be hired.



Note that by doing so, you will filter out some candidates who are good enough but are not very good. You have your doubts not without reason. The potential loss is insignificant in sending away some of the candidates who would fit but are not &quot;really good&quot;.




=== 1.3. Do we judge the candidate?




Avoid judging the candidate is extremely important. In the previous section, I deliberately used &quot;good candidate&quot; and &quot;bad candidate&quot;. In addition, I used an example (medical screening) that subconsciously compared candidates to cancer. If you felt inappropriate when you first read that, you are on the right track. If not, you have to think about why you did not.



We must respect the candidates.



Technical interviewers have to be humble. Maybe non-trivial at first, but we also must not evaluate the person, and we should not use expressions that may even unintentionally imply that. You cannot do that if you look down on candidates and you do not respect them. The respect has to be authentic. If it is not, you cannot hide it. So the first thing is that you should feel and show genuine care and then work on your communication.



It is why I prefer to use the word &quot;assess&quot; instead of &quot;judge&quot;. We assess the knowledge, skills, and experience of the candidate. We do not &quot;judge&quot; these, even though linguistically, it would mean the same. For the same reason, I usually talk about the position fitting the candidate and not the candidate fitting the position. Thus, when I say that a position is not good for a specific candidate, nobody will think that it is generally bad, even less that it is stupid or dumb.



On the other hand, the sentence &quot;The candidate is not good for the position.&quot; is heard and interpreted as &quot;The candidate is not good…&quot; The end of the sentence often gets lost in the communication or during the interpretation. It has to be carefully avoided.



Sometimes, I meet lead developers, senior, or even architect candidates who lack even basic skills in their current employment. Even though I feel the temptation to doubt whether their current status is well justified, I don&apos;t. If a candidate’s current position seems to be a lie in the CV, it does not matter. Companies are different, and they need different types of people. There is no such person who is generally not fitting a role. To assess a person&apos;s fitness for a position, you have to compare the person&apos;s qualities to the role. Otherwise, you could plainly say that the candidate is ok but can not tell us for what.




=== 1.4. Work with the Candidate




When conducting the interview, you work with the candidate. The candidate helps you, and you help the candidate. To get a clear picture and understand whether the position is really the dream position for the candidate is in your mutual interest.



It means that you can be absolutely honest with the candidate. You can tell them all the things that I wrote in this article. You can explain the aim of the interview, what the possible outcomes are, the recommended and not recommended decisions, and so on.



I usually devote 7 minutes at the start of the interview explaining the above. Of course, it is a bit boring after several hundreds of interviews, but every job has its downsides and upsides, and it is crucial for each candidate.



You can even explain that when candidates are lying or cheating candidates, it might be harmful. It helps when a candidate gets a coding exercise that is too familiar to them. A few times, the candidate proactively warned me that they had already met the task beforehand. So we chose a different one.




=== 1.5. Coding Exercise




The above paragraphs are generally valid for all types of interviews and not specific for software development. For example, doing a coding exercise is specific to technical software developer interviews. However, most of the debates on social media are related to this practice. The reason for that is simple. It is very easy to do it wrong.



I would never recommend a candidate who cannot demonstrate the coding skills in an interview. After all, what is the value a developer can deliver who cannot code? It is more questionable if a solution architect needs to code, and I would not get into that this time. I have my personal opinion about it, but it is irrelevant. Maybe I will discuss it in a different article.



I have met some developers hired from different vendors working in the same team for our clients who could not code. We never complained, and we did the extra work instead of them. The client personnel could see who did what and came to their conclusions most of the time. I will also not name the vendor ever. Let&apos;s just say that these developers stay afloat in the industry until they find a different job and become BAs, PMs, or car salesmen. I accept them as a fact of life, but I do not accept hiring one in my workplace. In conclusion, we should agree that some performance measures are needed to assess the coding skills as a work theory.



An excellent coding exercise helps assess three things:



* The algorithmic thinking of the candidate.* Coding skills and the muscle memory of the language we test. In my case, it is Java.* Communication skills.



Each of these can easily go wrong, and hence negative stories quickly get to social media.



It is challenging to assess algorithmic thinking. It is much easier to test if the candidate can solve one specific problem or complete a task. That way, the assessment quickly degrades to testing if the candidate knows the particular algorithm. Even though I believe that learning and understanding the most important algorithms and data structures (quick sort, balanced trees, graph traversing) is vital for a developer, many developers do not possess even the fundamental computer science theory. I can also accept that there is no value in knowing many algorithms by heart. It is better to have the skillset to create the algorithm when needed.



To avoid testing the candidate knowing the task instead of solving it, I have several of them you cannot find on the internet. (Fun story about that at the end of the article.) We also discuss the solution while the candidate forges the code step by step. I realize if the candidate has known the algorithm beforehand.



You can test the coding skills easily. Many typical coding practices show off an inexperienced coder.



You can spot old coding constructs that we are not using anymore as the language (in my case, Java) develops. I sometimes see explicit type boxing, which we do not use since Java 1.4 Junior developers tend to compare a boolean value with &apos;== true&apos; or write an &apos;if&apos; statement and return &apos;true&apos; and &apos;false&apos; literal values from the execution branches. Some developers make mistakes, like indexing a &apos;String&apos; as if it was an array.



As an interviewer, you should interpret those with a pinch of salt. The interview is not a normal coding environment. It is much more stressful, and such mistakes are many times caused by stress. The technical tools are usually less advanced than the usual IDE, with less support for code completion, syntax checking, and so on. Do not expect the candidate to know all the JDK API calls from the top of their head.



You can also check communication skills. For example, some candidates blamed me for presenting unprecise, even sloppy task descriptions. They were surprised when I told them that I was aware of that. It is to test if they clarify the task before making bold assumptions and just immediately start coding. Most of them do.



The coding exercise is the most challenging part of the interview. Not for the candidate, though. It is for the interviewer. It is a task that the candidate has to do together with you. If you, as an interviewer, see that the candidate is working on the coding task alone, you are doing it wrong. If you work together, then it is good. It may not be perfect, but most of the usual pitfalls you have already avoided.




=== 1.6. Giving Feedback




At the end of the interview, you will know whether to recommend or not to recommend the candidate. If you don&apos;t know, if you are not absolutely sure, then you should not recommend the candidate. I wrote that you must not recommend someone you are not sure about.



The recommendation, usually along with detailed analysis, is the primary outcome of the interview. There can be, however, another valuable byproduct. You can give valuable feedback to the candidate.



Interviewers seldom give feedback about the interview to the candidates, and this is not a good practice. I do not advocate giving feedback no matter what because it is a double-edged sword. If you provide feedback in the wrong way, it may cause a lot of harm to the candidate and the company. Providing valuable, thoughtful, and relevant feedback required some special skills.



Good feedback emphasizes the candidate&apos;s strong points that they can build on and highlights the things that they can improve and that may result in enormous benefits.



The most benefit is evidently for the candidate, but it is also valuable for the company. Getting detailed feedback is always an invaluable help to better ourselves. Good feedback, however, is also beneficial for the company. Even if rejecting a candidate is the correct conclusion, a blatant and unexplained refusal may induce bad feelings towards the company. Feedback can mitigate this risk. Feedback explains the reasons so that the candidate can learn the reasons along with suggestions for improvement. Again, you can emphasize that the refusal is not a judgment; it solely recognizes the incompatibility between the candidate’s skills, experience, or knowledge and what the company requires in a specific role.



You do not know each other. Thus, you have to put a lot of emphasis on the good things that the candidate can build on. You can also explain that the feedback is limited as it is based on a 60-minute interview only.



Some candidates challenge some of my statements during the feedback. It is pointless from the feedback point of view. If I made a mistake, I misread the candidate in some aspect; they can ignore that part of the feedback. Some of the comments may likely be wrong due to the limited nature of the session. At the same time, I give feedback after the decision. It would be best if you did not change the decision based on any feedback debate. Even though I am usually lenient with candidates arguing about some points of the feedback. It reveals a lot about their personality that I can include in the subjective part of the interview record, and at the same time, it helps them vent their feelings.



I had candidates referred to our company by his friend I rejected but sent away with friendly but honest feedback.




=== 1.7. Summary and Fun Story




Navigare necesse est. Doing interviews is unavoidable. Vivere no est necesse. Doing good interviews is difficult. In this article, I wrote about some aspects of the interviewing. There are other aspects that I did not discuss. Those I may address in a later article. I also know that many aspects of this topic are opinionated. You are welcome to comment, rant, criticize and tell the truth as you feel fit.



I promised you a fun story, so here it is.



Once I interviewed a candidate who was not outstanding. He had several knowledge gaps related to basic Java. He knew a few things wrong and was a bit stubborn. His coding skills were also less than what we required. When I ended the interview, I asked him if he wanted feedback. He said no, and disconnected the communication. (We usually do remote interviews using IP communication tools, like Zoom, Teams, Skype, etc.)



He immediately wrote an eMail to the talent acquisition team claiming that I was asking him wrong; I did not accept his correct answers and stating that I did not know Java. He also wrote that I was giving him a coding task that anyone can find on the internet, and I did not accept his correct solution because I did not like him. Even though he did not agree to video recording, the coding exercise does get recorded to crosscheck. I did not doubt that the solution was wrong, but his statement that I allegedly copied the exercise from the internet bothered me. So I googled some of the sentences of the task. I could find it on a site along with a wrong solution he also provided. It was word by word the same, including a typo. So you can guess who was copying from whom.



Your coding exercise tasks leak out. So you have to replace them frequently.</content><author><name></name></author><summary type="html">1. Why and how to do technical interviews?</summary></entry><entry><title type="html">Creating a JUnit 5 ExecutionCondition</title><link href="https://javax0.github.io/2021/05/04/creating-a-junit-5-execution-condition.html" rel="alternate" type="text/html" title="Creating a JUnit 5 ExecutionCondition" /><published>2021-05-04T00:00:00+02:00</published><updated>2021-05-04T00:00:00+02:00</updated><id>https://javax0.github.io/2021/05/04/creating-a-junit-5-execution-condition</id><content type="html" xml:base="https://javax0.github.io/2021/05/04/creating-a-junit-5-execution-condition.html"># Introduction

https://youtu.be/z9NL_Il0AQI

JUnit 5 has a lot of underutilized features. Developers have learned how to use JUnit 4, and they utilize the same feature set when using JUnit5. The sexy `DisplayName` annotation is used more and more, but the majority of the new features developers skip. In this article, I describe a particular situation I was facing and how I solved the issue by creating a custom `ExecutionCondition`.

# My Special Testing Need

I am developing Jamal, which is a general-purpose transpiler, text macro language. It converts from an input text to an output text, resolving and executing macros in the text. Sometimes macros can be overcomplicated, and it may not be trivial why the output is what we get. The first approach to this issue is not to use overcomplicated structures, but this is not how developers work. Good developers tend to use the tools they have in their hands to the total capacity.

In the case of Jamal, it needs debugging. Jamal supported debugging for a long time, dumping each atomic step into an XML file that the developer can later examine. It is, however, not as effective as interactive debugging.

To support interactive debugging, I developed a debugger interface into release 1.7.4 accompanied by a Rest.js client application. Jamal starts in debug mode if it sees an environment variable `JAMAL_DEBUG` or system property `JAMAL_DEBUG_SYS`. When this variable is defined, Jamal pauses whenever it starts processing a new input and listening on a port configured by the variable. It goes on with processing only when it gets a command through the TCP channel.

The important thing for this article is: Jamal pauses and starts to listen on a TCP port in this mode.

The big question is, how to debug the debugger? The obvious answer is: Start Jamal in debug mode in a JVM started in debug mode. The easiest way in IntelliJ is to start it from a JUnit test by clicking on the debug button. So I had the test:

```java
@Test
@DisplayName(&quot;Used to debug the debugger UI&quot;)
void testDebugger() throws Exception {
System.setProperty(Debugger.JAMAL_DEBUG_SYS, &quot;http:8081?cors=*&quot;);
TestThat.theInput(
&quot;hahóóó\n&quot;.repeat(2) +
&quot;{@define a=1}{@define b(x)=x2x}{b{a}}&quot;
).results(&quot;hahóóó\n&quot; +
&quot;hahóóó\n&quot; +
&quot;121&quot;);
System.clearProperty(Debugger.JAMAL_DEBUG_SYS);
}
```

You have to `//@Test` the code before committing to your repo. Forgetting that will break the build because when it starts, it pauses and waits. I forget to comment out the annotation because I am such a forgetful person. Maybe age, maybe something else. However, my experience is that every developer has age, and every developer forgets to comment out such a thing. I needed something that realizes that the test is started from IntelliJ and lets it run but aborts it otherwise.

# How to Recognize it is IntelliJ?

When you run a unit test from IntelliJ, IntelliJ will invoke your code from IntelliJ. Not directly. It goes through a few method calls in the stack, but there should be some class that belongs to IntelliJ towards the top of the stack. If the method and the class belong to IntelliJ, then the name of the class should undoubtedly have something specific in it we can check. Generally, this is the idea.

No specifications guarantee it. The name of the classes IntelliJ uses may change from time to time. Like Maven or Gradle, a different execution environment can also use some class names that may be similar to that of IntelliJ. But this is a solution that eventually works. No guarantee, but as for now, it works.

```java
boolean isIntelliJStarted = false;
final var st = new Exception().getStackTrace();
for (final var s : st) {
if (s.getClassName().contains(&quot;Idea&quot;)) {
isIntelliJStarted = true;
break;
}
}
```

The selection of the string `Idea` to check is more or less arbitrary. It is a string that is not likely to happen in the stack trace of some other application, and at the same time, there is only a tiny chance that it disappears from later IntelliJ versions. It is also to note that creating the stack trace this way is time-consuming. When the code runs from IntelliJ, it is not a problem at all. The time it needs is way less than a fraction of a second, and the next step I have to do after I started the application is opening a browser and the debugger web page. By the time I am finished with that, Java could have analyzed the stack trace a few million times. I, as a human, am much slower than the stack trace gathering.

When the code runs on the CI/CD or Maven on the command line, the delay is considerable. It is not tremendous or really significant, but it should be considered. It adds to the compile time.

I would not use such a solution in a performance-sensitive production code.

# Separation of Concern

I could insert this code into the test and return it from the test if it is not executed from IntelliJ. I did that as a first try, but I was aware that this is not an amicable solution. To make a decision separating the environments is not the responsibility of the test.

I was sure that JUnit 5 has a better solution for this. I asked `@RealityInUse` (Twitter handle) to help me. I was in a lucky situation because we share an office, which happens to be our living room during the pandemic. He is an active contributor of JUnit Pioneer https://junit-pioneer.org project of ``@nipafx`, he knows a lot about JUnit 5 extensions. (And he is my son.)

He told me that what I needed was an `ExecutionCondition`.

`ExecutionCondition` is an interface. It defines one single method with a direct signature:

```java
ConditionEvaluationResult evaluateExecutionCondition(ExtensionContext ctx);
```

The implementation should have a method overriding this interface method, and after doing the above stack examination, it has to

```java
return isIntelliJStarted ?
ConditionEvaluationResult.enabled(&quot;started from IntelliJ&quot;) :
ConditionEvaluationResult.disabled(&quot;not started from IntelliJ&quot;);
```

It is almost all the work to be done. There is one little thing left: tell JUnit to use this condition for this test.

To do that, we created an abjectly named annotation: `@IntelliJOnly`. With this, the class we developed was the following (without imports):

```java
@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.METHOD)
@ExtendWith(IntelliJOnly.IntelliJOnlyCondition.class)
public @interface IntelliJOnly {

class IntelliJOnlyCondition implements ExecutionCondition {
@Override
public ConditionEvaluationResult evaluateExecutionCondition(ExtensionContext context) {
final Method method = context.getRequiredTestMethod();
final var annotation = method.getDeclaredAnnotation(IntelliJOnly.class);
if (annotation == null) {
throw new ExtensionConfigurationException(&quot;Could not find @&quot; + IntelliJOnly.class + &quot; annotation on the method &quot; + method);
}
boolean isIntelliJStarted = false;
final var st = new Exception().getStackTrace();
for (final var s : st) {
if (s.getClassName().contains(&quot;Idea&quot;)) {
isIntelliJStarted = true;
break;
}
}
return isIntelliJStarted ? ConditionEvaluationResult.enabled(&quot;started from IntelliJ&quot;) : ConditionEvaluationResult.disabled(&quot;not started from IntelliJ&quot;);
}
}
}
```

The test with this annotation is the following:

```java
@Test
@DisplayName(&quot;Used to debug the debugger UI&quot;)
@IntelliJOnly
void testDebugger() throws Exception {
System.setProperty(Debugger.JAMAL_DEBUG_SYS, &quot;http:8081?cors=*&quot;);
TestThat.theInput(
&quot;hahóóó\n&quot;.repeat(2) +
&quot;{@define a=1}{@define b(x)=x2x}{b{a}}&quot;
).results(&quot;hahóóó\n&quot; +
&quot;hahóóó\n&quot; +
&quot;121&quot;);
System.clearProperty(Debugger.JAMAL_DEBUG_SYS);
}
```

# Notes

The implementation of the condition checks that the test method is annotated by `@IntelliJOnly`. The annotation may not be there if the user (developer using the annotation) makes some mistake, invokes the condition in the wrong way. This extra check may save a few surprises for the developer using this condition.

# Summary

In this article, I described a situation that needed conditional test execution with a particular condition. After that, I described how the condition could be evaluated. Finally, we created a JUnit 5 execution condition to separate the Hamletian &quot;run or not to run&quot; dilemma from the test code.

As a takeaway, you should remember that JUnit is way better than JUnit 4. Utilizing only the features, which were already available in version 4, is a waste of resources. Your tests can be much simpler, more expressive, and easier to maintain if you learn and utilize the programming features of JUnit 5. Do!</content><author><name></name></author><summary type="html">Introduction</summary></entry><entry><title type="html">Creating a JUnit 5 ExecutionCondition</title><link href="https://javax0.github.io/2021/05/04/creating-a-junit-5-executioncondition.html" rel="alternate" type="text/html" title="Creating a JUnit 5 ExecutionCondition" /><published>2021-05-04T00:00:00+02:00</published><updated>2021-05-04T00:00:00+02:00</updated><id>https://javax0.github.io/2021/05/04/creating-a-junit-5-executioncondition</id><content type="html" xml:base="https://javax0.github.io/2021/05/04/creating-a-junit-5-executioncondition.html">== 1. Introduction


https://youtu.be/z9NL_Il0AQI

JUnit 5 has a lot of underutilized features. Developers have learned how to use JUnit 4, and they utilize the same feature set when using JUnit5. The sexy `DisplayName` annotation is used more and more, but the majority of the new features developers skip. In this article, I describe a particular situation I was facing and how I solved the issue by creating a custom `ExecutionCondition`.


== 2. My Special Testing Need


I am developing Jamal, which is a general-purpose transpiler, text macro language. It converts from an input text to an output text, resolving and executing macros in the text. Sometimes macros can be overcomplicated, and it may not be trivial why the output is what we get. The first approach to this issue is not to use overcomplicated structures, but this is not how developers work. Good developers tend to use the tools they have in their hands to the total capacity.

In the case of Jamal, it needs debugging. Jamal supported debugging for a long time, dumping each atomic step into an XML file that the developer can later examine. It is, however, not as effective as interactive debugging.

To support interactive debugging, I developed a debugger interface into release 1.7.4 accompanied by a Rest.js client application. Jamal starts in debug mode if it sees an environment variable `JAMAL_DEBUG` or system property `JAMAL_DEBUG_SYS`. When this variable is defined, Jamal pauses whenever it starts processing a new input and listening on a port configured by the variable. It goes on with processing only when it gets a command through the TCP channel.

The important thing for this article is: Jamal pauses and starts to listen on a TCP port in this mode.

The big question is, how to debug the debugger? The obvious answer is: Start Jamal in debug mode in a JVM started in debug mode. The easiest way in IntelliJ is to start it from a JUnit test by clicking on the debug button. So I had the test:

[source,java]
----
@Test
@DisplayName(&quot;Used to debug the debugger UI&quot;)
void testDebugger() throws Exception {
    System.setProperty(Debugger.JAMAL_DEBUG_SYS, &quot;http:8081?cors=*&quot;);
    TestThat.theInput(
        &quot;hahóóó\n&quot;.repeat(2) +
            &quot;{@define a=1}{@define b(x)=x2x}{b{a}}&quot;
    ).results(&quot;hahóóó\n&quot; +
        &quot;hahóóó\n&quot; +
        &quot;121&quot;);
    System.clearProperty(Debugger.JAMAL_DEBUG_SYS);
}
----


You have to `//@Test` the code before committing to your repo. Forgetting that will break the build because when it starts, it pauses and waits. I forget to comment out the annotation because I am such a forgetful person. Maybe age, maybe something else. However, my experience is that every developer has age, and every developer forgets to comment out such a thing. I needed something that realizes that the test is started from IntelliJ and lets it run but aborts it otherwise.


== 3. How to Recognize it is IntelliJ?


When you run a unit test from IntelliJ, IntelliJ will invoke your code from IntelliJ. Not directly. It goes through a few method calls in the stack, but there should be some class that belongs to IntelliJ towards the top of the stack. If the method and the class belong to IntelliJ, then the name of the class should undoubtedly have something specific in it we can check. Generally, this is the idea.

No specifications guarantee it. The name of the classes IntelliJ uses may change from time to time. Like Maven or Gradle, a different execution environment can also use some class names that may be similar to that of IntelliJ. But this is a solution that eventually works. No guarantee, but as for now, it works.

[source,java]
----
boolean isIntelliJStarted = false;
final var st = new Exception().getStackTrace();
for (final var s : st) {
    if (s.getClassName().contains(&quot;Idea&quot;)) {
        isIntelliJStarted = true;
        break;
    }
}
----


The selection of the string `Idea` to check is more or less arbitrary. It is a string that is not likely to happen in the stack trace of some other application, and at the same time, there is only a tiny chance that it disappears from later IntelliJ versions. It is also to note that creating the stack trace this way is time-consuming. When the code runs from IntelliJ, it is not a problem at all. The time it needs is way less than a fraction of a second, and the next step I have to do after I started the application is opening a browser and the debugger web page. By the time I am finished with that, Java could have analyzed the stack trace a few million times. I, as a human, am much slower than the stack trace gathering.

When the code runs on the CI/CD or Maven on the command line, the delay is considerable. It is not tremendous or really significant, but it should be considered. It adds to the compile time.

I would not use such a solution in a performance-sensitive production code.


== 4. Separation of Concern


I could insert this code into the test and return it from the test if it is not executed from IntelliJ. I did that as a first try, but I was aware that this is not an amicable solution. To make a decision separating the environments is not the responsibility of the test.

I was sure that JUnit 5 has a better solution for this. I asked `@RealityInUse` (Twitter handle) to help me. I was in a lucky situation because we share an office, which happens to be our living room during the pandemic. He is an active contributor of JUnit Pioneer https://junit-pioneer.org project of ``@nipafx`, he knows a lot about JUnit 5 extensions. (And he is my son.)

He told me that what I needed was an `ExecutionCondition`.

`ExecutionCondition` is an interface. It defines one single method with a direct signature:

[source,java]
----
ConditionEvaluationResult evaluateExecutionCondition(ExtensionContext ctx);
----


The implementation should have a method overriding this interface method, and after doing the above stack examination, it has to

[source,java]
----
return isIntelliJStarted ?
    ConditionEvaluationResult.enabled(&quot;started from IntelliJ&quot;) :
    ConditionEvaluationResult.disabled(&quot;not started from IntelliJ&quot;);
----


It is almost all the work to be done. There is one little thing left: tell JUnit to use this condition for this test.

To do that, we created an abjectly named annotation: `@IntelliJOnly`. With this, the class we developed was the following (without imports):

[source,java]
----
@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.METHOD)
@ExtendWith(IntelliJOnly.IntelliJOnlyCondition.class)
public @interface IntelliJOnly {

    class IntelliJOnlyCondition implements ExecutionCondition {
        @Override
        public ConditionEvaluationResult evaluateExecutionCondition(ExtensionContext context) {
            final Method method = context.getRequiredTestMethod();
            final var annotation = method.getDeclaredAnnotation(IntelliJOnly.class);
            if (annotation == null) {
                throw new ExtensionConfigurationException(&quot;Could not find @&quot; + IntelliJOnly.class + &quot; annotation on the method &quot; + method);
            }
            boolean isIntelliJStarted = false;
            final var st = new Exception().getStackTrace();
            for (final var s : st) {
                if (s.getClassName().contains(&quot;Idea&quot;)) {
                    isIntelliJStarted = true;
                    break;
                }
            }
            return isIntelliJStarted ? ConditionEvaluationResult.enabled(&quot;started from IntelliJ&quot;) : ConditionEvaluationResult.disabled(&quot;not started from IntelliJ&quot;);
        }
    }
}
----


The test with this annotation is the following:

[source,java]
----
@Test
@DisplayName(&quot;Used to debug the debugger UI&quot;)
@IntelliJOnly
void testDebugger() throws Exception {
    System.setProperty(Debugger.JAMAL_DEBUG_SYS, &quot;http:8081?cors=*&quot;);
    TestThat.theInput(
        &quot;hahóóó\n&quot;.repeat(2) +
            &quot;{@define a=1}{@define b(x)=x2x}{b{a}}&quot;
    ).results(&quot;hahóóó\n&quot; +
        &quot;hahóóó\n&quot; +
        &quot;121&quot;);
    System.clearProperty(Debugger.JAMAL_DEBUG_SYS);
}
----



== 5. Notes


The implementation of the condition checks that the test method is annotated by `@IntelliJOnly`. The annotation may not be there if the user (developer using the annotation) makes some mistake, invokes the condition in the wrong way. This extra check may save a few surprises for the developer using this condition.


== 6. Summary


In this article, I described a situation that needed conditional test execution with a particular condition. After that, I described how the condition could be evaluated. Finally, we created a JUnit 5 execution condition to separate the Hamletian &quot;run or not to run&quot; dilemma from the test code.

As a takeaway, you should remember that JUnit is way better than JUnit 4. Utilizing only the features, which were already available in version 4, is a waste of resources. Your tests can be much simpler, more expressive, and easier to maintain if you learn and utilize the programming features of JUnit 5. Do!</content><author><name></name></author><summary type="html">1. Introduction</summary></entry></feed>