<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>LLM and RAG technology | Java Deep, mostly Java</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="LLM and RAG technology" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="1. Introduction" />
<meta property="og:description" content="1. Introduction" />
<link rel="canonical" href="https://javax0.github.io/2024/07/22/llm-and-rag.html" />
<meta property="og:url" content="https://javax0.github.io/2024/07/22/llm-and-rag.html" />
<meta property="og:site_name" content="Java Deep, mostly Java" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-07-22T00:00:00+02:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="LLM and RAG technology" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-07-22T00:00:00+02:00","datePublished":"2024-07-22T00:00:00+02:00","description":"1. Introduction","headline":"LLM and RAG technology","mainEntityOfPage":{"@type":"WebPage","@id":"https://javax0.github.io/2024/07/22/llm-and-rag.html"},"url":"https://javax0.github.io/2024/07/22/llm-and-rag.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://javax0.github.io/feed.xml" title="Java Deep, mostly Java" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Java Deep, mostly Java</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/about/">About</a><a class="page-link" href="/">Java Deep</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">LLM and RAG technology</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2024-07-22T00:00:00+02:00" itemprop="datePublished">Jul 22, 2024
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <div class="sect1">
<h2 id="1-introduction">1. Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This article is a brief introduction to LLM and RAG technology.
The article contains many simplifications that laypeople can understand.
If you&#8217;re interested in the technology in more detail, this article won&#8217;t be enough. You may find parts that aren&#8217;t entirely accurate, although they convey the essence well.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="2-the-essence-of-rag-technology">2. The essence of RAG technology</h2>
<div class="sectionbody">
<div class="paragraph">
<p>RAG is an acronym for Retrieval Augmented Generation.
It is an English acronym.</p>
</div>
<div class="paragraph">
<p>This technology tries to complement LLM or Large Language Model applications.
The goal is to be able to handle knowledge bases and information that are not found in the Large Language Model itself.
The Large Language Model is a neural network that has been trained somehow.
They are usually trained with large quantities of data that are freely available online.
As a result, Large Language Models can communicate in an almost human-like manner.
If we ask them a question, they can answer it.
However, they need to learn about what data or information exists within a company, as these are not public data.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="3-limitations-of-llms">3. Limitations of LLMs</h2>
<div class="sectionbody">
<div class="paragraph">
<p>LLMs cannot be taught this corporate information in their current form.
Currently, available applications work by developers creating some models.
Then, they train this model, setting millions or billions of parameters with training data.
They ask questions, get answers, and then adjust these parameters based on the quality of the answers.</p>
</div>
<div class="paragraph">
<p>Of course, there are programs and algorithms for this, not by hand.
Under current conditions, this process takes a few months to complete using the energy requirements of a small city.
They run this fine-tuning algorithm on thousands of machines.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="4-characteristics-of-llm-models">4. Characteristics of LLM models</h2>
<div class="sectionbody">
<div class="paragraph">
<p>When done, the model can be downloaded and run on your machine.
The model itself represents 1-2 GB of data.
After this, this neural network no longer changes; it doesn&#8217;t learn new things.
It can only learn something new if we get a new version.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="5-application-of-rag-technology">5. Application of RAG technology</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Yet we want to use this kind of capability within a company.
We want this neural network, the LLM model, to give an answer that takes into account our company&#8217;s internal information when we ask a question.
We can do this as if we were doing something similar with humans.</p>
</div>
<div class="paragraph">
<p>If someone comes to the company, and we want to ask them questions about the company, but they don&#8217;t know anything about our company, we first teach them things and give them information.
They will put this information into their neural network.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="6-operating-principle-of-rag">6. Operating principle of RAG</h2>
<div class="sectionbody">
<div class="paragraph">
<p>We can see if they focus on work and forget everything else when they go home, and they keep this company-specific information in a separate place.</p>
</div>
<div class="paragraph">
<p>It is the model for LLM and RAG as well.
We put the information that isn&#8217;t in the LLM&#8217;s neural network separately in a separate database.
If for no other reason, we can&#8217;t put it into the neural network&#8217;s database or into its model.
These are private. We don&#8217;t know what they look like or how they&#8217;re structured, and they&#8217;re not necessarily modifiable in the form they&#8217;re in the program.</p>
</div>
<div class="paragraph">
<p>We don&#8217;t have, we might say, the "source code" of the data - not necessarily the program&#8217;s source code, but the original form of the data.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="7-characteristics-of-the-llm-model">7. Characteristics of the LLM model</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This model becomes 1 GB through several steps and is a relatively small data set.
It&#8217;s relative to what&#8217;s small, but in LLM terms, this is considered small.
And it&#8217;s not sure it&#8217;s still in a state that can be modified.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="8-use-of-vector-databases">8. Use of vector databases</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If we want to put our own information into a separate database, we usually use a vector database.
A vector database is a special application that can determine the distance between two pieces of text.
So how much are they about the same thing, and how many are the exact keywords?</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="9-preparing-the-knowledge-base">9. Preparing the knowledge base</h2>
<div class="sectionbody">
<div class="paragraph">
<p>We cut up the knowledge base available within the company into pieces of text.
These pieces of text are typically a thousand characters or a thousand letters long and form individual records.
There&#8217;s a little overlap between them, so we don&#8217;t start the next one where the previous one ended, but a little earlier.
It is to have context and continuity in the text.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="10-the-embedding-algorithm">10. The embedding algorithm</h2>
<div class="sectionbody">
<div class="paragraph">
<p>We put each of these pieces of text into a database and ask an embedding algorithm to assign it a vector.
The vector is a sequence of numbers.</p>
</div>
<div class="paragraph">
<p>It is similar to, for example, GPS coordinates.</p>
</div>
<div class="paragraph">
<p>Essentially, this vector is a spatial coordinate of this text, but this space is not three-dimensional but very multi-dimensional.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="11-rag-operation-for-questions">11. RAG operation for questions</h2>
<div class="sectionbody">
<div class="paragraph">
<p>When a user addresses a question to an application developed with RAG technology, we also vectorize this question.</p>
</div>
<div class="paragraph">
<p>We ask the embedding system to tell us where this question is located in space.</p>
</div>
<div class="paragraph">
<p>Then, we can ask the vector database, into which we put the vectors belonging to all our text pieces, which text pieces from our knowledge base are closest in space to the question.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="12-distance-calculation-between-vectors">12. Distance calculation between vectors</h2>
<div class="sectionbody">
<div class="paragraph">
<p>It is a distance calculation and indexing.
If you like, you can calculate the distance with the Pythagorean theorem in an orthogonal vector space.
Although it sounds complicated, we don&#8217;t really need to deal with it or know how it works.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="13-characteristics-of-the-embedding-algorithm">13. Characteristics of the embedding algorithm</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The point is that this embedding algorithm is usually based on a neural network as well.
There are elementary embedding algorithms, too, but these are practically less usable.
There are more complex embedding systems based on neural networks that do this, depending on the language.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="14-selection-of-relevant-text-pieces">14. Selection of relevant text pieces</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The vector database tells us which text pieces from our knowledge base are close to the question, meaning they are relevant to answering the question.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="15-assembling-the-prompt">15. Assembling the prompt</h2>
<div class="sectionbody">
<div class="paragraph">
<p>After this, we ask the LLM for a prompt that is not the original, but we put in front of it those pieces of text we extracted from our own knowledge base.
We can&#8217;t fit the whole thing into one question because it would be too much, but we can include a few, five, six, seven, or even ten from the knowledge base.</p>
</div>
<div class="paragraph">
<p>We write in the prompt that this is a context, and we want to get the answer in this context, then the question itself.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="16-summary-of-the-rag-process">16. Summary of the RAG process</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Then, we send this to the LLM algorithm, which reads it, does something with it, and answers it.</p>
</div>
<div class="paragraph">
<p>And this is it.
The whole RAG is that simple.
You need a vector database; you need to cut up the text.
If someone understands programming, they know this is not a big deal.</p>
</div>
<div class="paragraph">
<p>We need to put the text into a normal database so that we can restore it for prompt generation.
We put the vectors into the vector database so that we can ask which are the relevant text pieces for a given question.
Then, we need to be able to ask the LLM questions from a program and program standard interfaces.
Finally, we need to be able to send the answer back to the client or user who can read it.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="17-summary">17. Summary</h2>
<div class="sectionbody">
<div class="paragraph">
<p>With this technology, we produced an application that you can chat with just like ChatGPT.</p>
</div>
<div class="paragraph">
<p>But it knows not only the things of the big world up to a certain point in time when its training was closed but also the things in our special knowledge base.</p>
</div>
</div>
</div>


<!-- Disqus comments section goes here (if comments are enabled) -->

<hr/>
<h1>Comments</h1>
<p>Please leave your comments using Disqus, or just press one of the happy faces.
If for any reason you do not want to leave a comment here, <a href="https://github.com/javax0/javax0.github.io/issues">you can still create a Github ticket</a>.</p>
<div class="comments">
    <div id="disqus_thread"></div>

    <script type="text/javascript">

        /* * * STOP! * * */
        /* You shouldn't need to edit ANYTHING below to get this working! */
        /* Instead, edit the key `disqus.shortname` in _config.yml */

        var disqus_config = function (){
            this.page.url = 'https://javax0.github.io/2024/07/22/llm-and-rag.html';
            this.page.identifier = '/2024/07/22/llm-and-rag.html';
        };

        (function() {
            var d = document, s = d.createElement('script');
            s.type = 'text/javascript'; s.async = true;
            s.src = 'https://javax0.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();

    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>




  </div><a class="u-url" href="/2024/07/22/llm-and-rag.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Java Deep, mostly Java</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Java Deep, mostly Java</li><li><a class="u-email" href="mailto:peter@verhas.com">peter@verhas.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/verhas"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">verhas</span></a></li><li><a href="https://www.twitter.com/verhas"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">verhas</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>javax0 is a technical Java oriented blog. Whenever I find something interesting, in the mood and feel the power to publish it, you will get it here. Publications are usually released on Wednesday 15:00am GMT. Earlier posts of the blog were published on Javax0 Wordpress Site at https://javax0.wordpress.com</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
