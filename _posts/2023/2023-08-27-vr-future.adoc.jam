---
{%@define title=Virtual and Augmented Reality is Here%}
title: {%title%}
layout: posta
comments: on
---
{%@import javax0.jim%}
{%@comment

=========================================================================================
%}
{%@sep 〔〕%}
= 〔title〕

〔section Introduction〕

Virtual reality is a technology when you wear some device projecting a non-existing world into your senses.
This way you partially or completely lose the connection to the real world, and you are immersed into the virtual world.
Current technology does not allow complete loss of connection to the real world, and the senses are mostly limited to vision and hearing.
Usually two LCD devices with special optics are mounted on your head and different sensors track your head movement.
The computers display pictures on the LCDs that change as you move your head showing a static or dynamic virtual reality around you.

In this article, I will write a bit about the history of virtual reality and how I got my fingers wet.
I will also write about what I experienced recently with the my newly bought Meta Quest Pro and how I see the future of virtual reality.

〔section History〕

The first virtual reality device was the first loudspeaker headset limited to audio senses, but the term was not used for that.

The first virtual reality device that was called virtual reality was the Sensorama built by Morton Heilig in 1962.
I personally had a set on my head in 1995 at an exhibition IFABO in Budapest.
I was working for Digital Equipment Corporation at that time, and we had a stand there.
My task was show the visitors the virtual reality headset that DEC create with cooperation with Kubota.
If you google the term __"Kubota Denali VR"__ you may find interesting traces of history.
I did not have much time to try it on and to play with it, but I was impressed.

I was convinced that VR is the future, and it is going to be here as soon as 2000, so in five years.
I remember this because I was young and "brave" enough to express this prediction publicly.

〔subsection Derail: Prediction and Braveness〕

When you are an expert, you can predict the future with a certain precision.
If you tell others how you see the future, and you are right, then you are a visionary.
If you are wrong, then you are a fool.

When you are young and at an early stage of your Dunnig-Kruger curve, you are brave enough to express your predictions.
So I was brave enough to say that VR is going to be here in five years.
I stated it in a forum not smaller than the main central state running radio stating Kossuth Radio in Hungary.
Nobody remembered it after five years, so it was not a big shame, but in the year 2015, twenty years later the same guy invited me again to the radio to review my predictions.
It was interesting.

I had some good predictions, like telling that mobile phone ill be ubiquitous and be a personal computing device connected to the internet.
But my VR prediction was off the rail.

Why is it important to mention this other than it gives you credibility when you admit your past mistakes in an article?
Because now I see what I did not see that time and why VR did not sweep the board.
In this article, I will repeat my mistake I made almost thirty years go and will predict the future of VR again.

Why am I so __"brave"__ to do that?
Because I am old enough to be brave again.
Young people are brave enough to predict the future because they do not understand that their prediction may bite back.
Old people know that when the prediction bites back, they will not be there to be bitten.

****
Never trust the prediction of a young or and old expert.
****

〔section Current Experiences〕

I bought my first VR headset in 2017.
It was a Sony Playstation VR.
It was a birthday present from myself.

At that time, I saw the state of VR as mainly a play thing.
Gaming and entertainment.
I had some play with fruit ninja, and beat saber.
I tried some other games, but I got dizzy very soon, and I realized why I was wrong in 1995.

The technology for the VR headset was not good enough.
It lacked resolution, it was too expensive and it needed improvement in the tracking of the head movement and lag of screen refresh.
Lag is very important.

When, for example, you tilt your head and the world you see tilts with your head for a moment and then gets back to its state to make the horizont horizontal again, then you get dizzy.
The lag is the time between the movement of your head and the movement of the picture on the screen.
The lag does not even need to be large enough to consciously recognizable, and it may still make you dizzy.

When the virtual word is dynamic, like car racing, your balance organ, the vestibular system, gets confused.
You see the car and the world around you running, but you are stationary.
That what makes you really vomit.

Parts of these problems can be solved, others not.
In 1995 even in a static environment I got easily dizzy.
Today it is much better, and (jumping a bit ahead) I can spend hours working in VR watching virtual screens in a virtual cafe.
As a matter of fact, I write this article with a Meta Quest Pro on my head and I am sitting i n a virtual cafe in Immersed.

I knew that this is not my last VR set, and I will have a next one suitable for work.
I was following the news about the huge investments of Meta and Facebook into VR.
However, I was waiting for Apple to come up with the next generation of VR.
I use a lot of Apple products.
They have great usability, and a hefty price tag.
On the other hand, if a senior engineer living in Switzerland who has paid off (never had) all the mortgages, kid raised cannot afford the overpriced products, then who can?

When the Apple Vision Pro was introduced with the price tag of 3.5k USD, I realized that I will not wait for Apple.
I could, but I do not want to pay that amount of money for something 1.0 and experimental.
I also could read between the lines of the marketing videos to know that this headset may be better than the competition, but it is still experimental.
It is not Apple's fault.
Although I expected a working version, I can see that this expectation was unrealistic.
It is not Apple Vision Pro that is experimental, it is the whole VR field even after 30 years.

The reason, as I see now after experimenting with the Meta Quest Pro, is not technology.
Technology developed enough during the last three decades so that companies can produce VR with good enough LCD, tracking and optics.
It is the software, which is immature, and it is in a special way.

When you think about immature software, you usually think of software that has bugs.
Although the Meta Quest Pro certainly has bugs, it is not the main reason I say it is immature.

Currently, there is no best practice on how we can and will use VR for work.
To develop that knowledge will need a lot of work.
It includes those early experimenters who are willing to invest their time an effort working with this immature technology.
It also needs a lot of money from companies like Facebook to develop the software.

There will be a lot of software developed today thrown away in a few years.
Not because they are buggy or low quality, but because they implement use case scenarios that are not usable.
Nobody knows what is usable.
Do we want to navigate in a three-dimensional space with boxes and spheres representing different files?
Should we represent directories as boxes, and we zoom into them to see the files or the files will be lined up behind them?
Should we imitate kinematics of real objects in a gravitational field like it is in our every-day earthly environment?
Should we float in space without specific directions when we move between some abstract objects representing files, folders, programming elements, relationships between these objects?
We will try, some people will like the first, some will be best fitting with the second, and others will prefer something developed we cannot even imagine today.

When I ordered my Meta Quest Pro, I was not sure what I will use it for.
I did not expect ot to be ready for work.
I was hoping, but I realized that it may not be.
I imagined different use cases.

* Work in a virtual environment with virtual screens, using Immersed.
* Play games.
* Play some games, which are workout.

〔section Meta Quest Pro First Steps〕

I had mixed feeling when I got the Meta Quest Pro.
First of all, I had to wait a month till it arrived.
While I was waiting, I watched a lot of Youtube videos about the device and the programs, so I was hiked.
Clearly a mistake.

After I started soon once it got frozen and I had to restart it.
But it did not happen ever again.

I had to install an app on my iPad/iPhone to use the headset.
It is okay, but the app I had to google, because the QR code on the printed users' manual was leading to a 404 page.
I descerve a seamless start for a 1000$.

It does not have a good tutorial.
It has a tutorial, but this is like someone had to write one to tick it off from the todo list than one written for the user.
I am spoiled by the usability and the guidance of Apple products.
For example, there is a mirror in the virtual environment which is your desktop.
I did not get any information from the tutorial, or from any documentation that it has a use.
I gave seen there the reflection of my avatar, but nobody told me that I can customize my avatar if I click there with the virtual laser beam.
Later, I also found the menu system to setup the avatar.

After five hours of use I still could not figure out the different use of the different buttons.
After a few weeks I know why: because there is no convention.
Different applications use thw different buttons differently.
There are X,Y as well as A,B buttons, but there is no unified meaning or use for them.
The only more or less fixed convention is that the shooting button for your index finger is shooting, and the trigger button for your thumb is grabbing.

I had some early bad experiences with the power and speaker loudness buttons.
A few times as I was moving the headset on and off I accidentally pressed these buttons.
I had to learn and muscle memory to grab the headset a different was from what I first felt natural.

THe hand tracking feature is amazing, but not usable.
It is amazing because it works, but I had to switch it off when working in a virtual environment.
When I type, the controllers are not in my hand.
The headset recognizes this and all my typing movement it tries to interpret as hand gestures.
Bizarre results.

The screen resolution for the virtual screens is usable, but they cannot compete with my two display 5k each setup.
I can see the pixels, and I can see the difference between the virtual and the real screens.

The keyboard use is also a pain point.
There are two ways to use the keyboard.
One is a so-called portal.
It is a shape, fixed in the virtual space that shows the real word behind the shape.
It is like a window to the real world from the virtual world.
You can open a portal for the keyboard, and see your keyboard blurry.

The problem probably comes from the fact that the cameras were designed for tracking and not for showing the real world.
I can see my keyboard, but I have to adjust the light and the picture waves a bit.

The other possibility is to use a so-called tracked keyboard.
In this case the software identifies the keyboard ny its shape and draws a virtual keyboard where the real keyboard is.
At the same time it also draws your hands in real time, so you see your hands and keys in a virtual environment.
It works as a labor experiment.
There are only a few keyboards supported: some Logitech model, Apple Magic keyboard and Macbook Pro amd Air keyboard.
Lucky I have a magic keyboard, but I use a Windows native Hungarian keyboard layout.
Virtual keyboards support only US layout.
Not even Y and Z swapped for many European keyboards.

To use virtual displays you must have a very fast connection between the PC/MacBook and the headset.
To have that I configured my MacBook to use my iPhone interned via a tethered connection.
The Wi-Fi uses the 5GHz band and provides a dedicated hotspot for the headset.
With this setup, the lag between the computer and the headset is 6m, that should be enough.
Because I still could feel a little lag in the mouse movement I ordered a USB-C to USB-C Oculus cable.
I feel ashamed to admit how much I paid for it, but it moved the latency tp 2ms.
Mouse is still lagging.

I also had to switch ot dark mode with IntelliJ to get better visibility on the virtual screens.

Watching movies is amazing.
And I did not mean the link:https://www.youtube.com/watch?v=h8srG_iKh5Y[special movies].
Just a good old boring Netflix, Disney, Amazon, etc. movies.

〔section Apps I Used〕

I tried a few applications and other than a few games, that I already used before I categorize each and every application as experimental.
The most mature application is Immersed.
There are a lot of problems with it, but I am using it every day for a few hours.
It proves it is usable, but to be honest I am not absolutely sure if I use it because

* I really like it in spite of the drawbacks, or
* I have a buyers remorse and I have to convince myself that I did not waste my money.

What I have experienced though, that meeting people in a virtual environment is much more natural than I expected.
When I do a video conference, I see the faces of the people I talk to.
When I do a virtual meeting, I can only see the avatars.
I expected it to be less natural, but somehow it felt more in presence.
You are visually in the same space as the other people's avatar, you talk to them, your hands are tracked and showed as well as your facial expression.
I also experienced that we needed less "who talks when" protocol than in a video conference.

I also tried a mind mapping application, called Noda.
I do not use mind mapping a lot, but I wanted to see how it works.
I was surprised.
Using spatial representation of the mind map is much more natural than the flat one.

I also tried some 3D drawing and I am still behind my plans with CAD for 3D printing.

〔section Future Apps〕

And this is the chapter, where I am going to make a fool of myself.
Let's hope that I live long enough to see it.
I will not give exact year numbers when will something come.

There will be a lot of technical development in the next few years, but that is something out of my experience.
Regarding the software, applications and development, I expect a lot of steps forward.

Right now we have different applications that present virtual worlds and something in it.
Immersed does two things: 1. provides a space where people and their avatars are visible and can interact, and 2. provides virtual screens.
Noda, the mind mapping application also provides 1. a virtual space and 2. a virtual mind map.

It is somehow analogous with the MS-DOS times, when you could run only one application on the screen at a time.

I expect that the virtual space to become the desktop.
It has to be provided by the operating system, and the different applications will be able to use it placing and moving different virtual objects in it.
I have not read articles that envision this model, nut I am sure this is the way VR architects at the big companies envision the future.
What do we miss there?

We miss the copy/paste and the drag and drop functionality.
I do not mean literally.
I do not think that we should have a virtual clipboard, and we should drag and drop virtual objects.
But we need a way where we can use different applications in the same virtual space and to make them interact.
What we miss is the act, which is the most natural way of interaction between applications like drag and drop and copy/paste on the desktop.

With that, I am sure that we soon will forget the desktop and the windows and virtual windows.
Tethering a MacBook to a headset is like tethering a horse to a railway car.
It was needed for a short time to provide the continuity of the culture development, but we will forget it.
We will have a VR version of programming IDEs, we will have 3D CAD, mind mapping, 3D UML diagrams, ORM representation and so on.
These will run on the headset, and we will not need to embed the 2D desktop into our 3D virtual world.

〔section Conclusion〕

This article is not about software development, but sine most of my articles are about that, I expect that most of my readers are.

What should you do as a developer?
What is the message?

First of all, you must not ignore VR technology anymore.
The headsets become better and cheaper and the software will develop.
Immerse, for one, can be a good excuse to buy a headset, if you need an excuse.
You should get acquainted with the technology, what is available, what can be developed.
Expect new operating system features supporting VR and new APIs and tools.
There will be a lot of opportunities in the coming years around this technology.












